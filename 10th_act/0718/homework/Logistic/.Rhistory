rm(list=ls())
library(mlbench)
data(BreastCancer)
str(BreastCancer) #Class benign=1 양성, malignant=2 악성
#?BreastCancer
BreastCancer = BreastCancer[,-1] #ID 제거
BreastCancer$Cl.thickness = as.numeric(BreastCancer$Cl.thickness)
BreastCancer$Cell.size = as.numeric(BreastCancer$Cell.size)
BreastCancer$Cell.shape = as.numeric(BreastCancer$Cell.shape)
BreastCancer$Marg.adhesion = as.numeric(BreastCancer$Marg.adhesion)
BreastCancer$Epith.c.size = as.numeric(BreastCancer$Epith.c.size)
#BreastCancer$Bare.nuclei = as.numeric(BreastCancer$Bare.nuclei)
#BreastCancer$Bl.cromatin = as.numeric(BreastCancer$Bl.cromatin)
#BreastCancer$Normal.nucleoli = as.numeric(BreastCancer$Normal.nucleoli)
#BreastCancer$Mitoses = as.numeric(BreastCancer$Mitoses)
BreastCancer$Class = as.factor(ifelse(BreastCancer$Class == "benign",0,1))
str(BreastCancer)
summary(BreastCancer)
table(BreastCancer$Class)
library(caret)
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
#0.938011
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
rm(list=ls())
load("psub.RData")
str(psub)
names(psub)
summary(psub$SCHL)
psub$bachdeg=as.numeric(psub$SCHL)
n=length(psub$bachdeg)
for(i in 1:n){
if(psub$bachdeg[i]==3||psub$bachdeg[i]==4||psub$bachdeg[i]==6||psub$bachdeg[i]==7){
psub$bachdeg[i]=1
}else{
psub$bachdeg[i]=0
}
}
psub$bachdeg=as.factor(psub$bachdeg)
str(psub$bachdeg)
select1 = colnames(psub)[c(12,15,73,108,290)]
select2 = colnames(psub)[c(12,15,73,108)]
formula1 = formula(paste("bachdeg~",paste(select2, collapse=" + ")))
psub=psub[select1]
str(psub)
library(caret)
idx = createDataPartition(psub$bachdeg, p=0.7, list=F)
psub_train = psub[idx,]
psub_test = psub[-idx,]
model.glm1 = glm(formula1, psub_train, family = binomial)
rm(list=ls())
load("psub.RData")
setwd("~/Tobigs/homework_0718/Logistic")
rm(list=ls())
load("psub.RData")
str(psub)
names(psub)
summary(psub$SCHL)
psub$bachdeg=as.numeric(psub$SCHL)
n=length(psub$bachdeg)
for(i in 1:n){
if(psub$bachdeg[i]==3||psub$bachdeg[i]==4||psub$bachdeg[i]==6||psub$bachdeg[i]==7){
psub$bachdeg[i]=1
}else{
psub$bachdeg[i]=0
}
}
psub$bachdeg=as.factor(psub$bachdeg)
str(psub$bachdeg)
select1 = colnames(psub)[c(12,15,73,108,290)]
select2 = colnames(psub)[c(12,15,73,108)]
formula1 = formula(paste("bachdeg~",paste(select2, collapse=" + ")))
psub=psub[select1]
str(psub)
library(caret)
idx = createDataPartition(psub$bachdeg, p=0.7, list=F)
psub_train = psub[idx,]
psub_test = psub[-idx,]
model.glm1 = glm(formula1, psub_train, family = binomial)
pred.glm1 = as.numeric(predict(model.glm1, psub_test, type = "response") > 0.5)
confusionMatrix(as.factor(pred.glm1),as.factor(psub_test$bachdeg))
table(pred.glm1)
psub_train_up = upSample(subset(psub_train, select=-bachdeg), psub_train$bachdeg)
formula2 = formula(paste("Class~",paste(select2, collapse=" + ")))
model.glm2 = glm(formula2, psub_train_up, family = binomial)
pred.glm2 = as.numeric(predict(model.glm2, psub_test, type = "response") > 0.5)
confusionMatrix(as.factor(pred.glm2),psub_test$bachdeg)
table(pred.glm2)
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
vif(fit1) #5~10이면 크다.
library(car)
fit.con <- lm(medv~ 1, Boston)
#fit.step = step(fit1,direction = 'both')
fit.step = step(fit.con, list(lower=fit.con, upper=fit1), direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
vif(fit.step)
outlierTest(fit.step)
influence.measures(fit.step)
influencePlot(fit.step)
#influencePlot(fit.step, id.method="identify", main="Influence Plot", sub="Circle size")
#influencePlot(fit1, id.method="identify", main="Influence Plot", sub="Circle size is proportional to Cook’s distance")
influenceIndexPlot(fit.step, id.n=3)
Boston2=Boston[-c(369,381),]
Boston3=Boston2[,-c(Boston2$rad,Boston2$tax)]
fit1=lm(medv~., Boston3)
summary(fit1)
fit.con <- lm(medv~ 1, Boston3)
fit.step = step(fit.con, list(lower=fit.con, upper=fit1), direction = 'both')
summary(fit.step)
outlierTest(fit.step)
influence.measures(fit.step)
influencePlot(fit.step)
yhat = predict(fit.step,newdata = Boston3,type = 'response')
head(yhat)
plot(fit.step$fitted.values,Boston3$medv) #medv가 50인 이상점들이 있는듯? 3개가 영향값인것같고 지워야 할 것으로 보이는데 어떻게 지우지?
abline(0,1,col='blue')
mean((Boston3$medv-yhat)^2) #이상점 영향값 지우기 전 21.89993이 나온다.
yhat = predict(fit.step,newdata = Boston3,type = 'response')
head(yhat)
plot(fit.step$fitted.values,Boston3$medv)
abline(0,1,col='blue')
mean((Boston3$medv-yhat)^2) #이상점 영향값 지우기 전 21.89993이 나온다.
rm(list=ls())
library(mlbench)
data(BreastCancer)
str(BreastCancer) #Class benign=1 양성, malignant=2 악성
#?BreastCancer
BreastCancer = BreastCancer[,-1] #ID 제거
BreastCancer$Cl.thickness = as.numeric(BreastCancer$Cl.thickness)
BreastCancer$Cell.size = as.numeric(BreastCancer$Cell.size)
BreastCancer$Cell.shape = as.numeric(BreastCancer$Cell.shape)
BreastCancer$Marg.adhesion = as.numeric(BreastCancer$Marg.adhesion)
BreastCancer$Epith.c.size = as.numeric(BreastCancer$Epith.c.size)
#BreastCancer$Bare.nuclei = as.numeric(BreastCancer$Bare.nuclei)
#BreastCancer$Bl.cromatin = as.numeric(BreastCancer$Bl.cromatin)
#BreastCancer$Normal.nucleoli = as.numeric(BreastCancer$Normal.nucleoli)
#BreastCancer$Mitoses = as.numeric(BreastCancer$Mitoses)
BreastCancer$Class = as.factor(ifelse(BreastCancer$Class == "benign",0,1))
str(BreastCancer)
summary(BreastCancer)
table(BreastCancer$Class)
library(caret)
while(1){
acc = 0
j=0
for (i in 1:50) {
idx = createDataPartition(BreastCancer$Class, p=0.7, list=F)
BreastCancer_train = BreastCancer[idx,]
BreastCancer_test = BreastCancer[-idx,]
Up_BreastCancer_train = upSample(subset(BreastCancer_train,select=-Class),BreastCancer_train$Class)
glm2=glm(Class~., data = Up_BreastCancer_train, family = binomial)
predict2=as.numeric(predict(glm2, newdata = BreastCancer_test, type = 'response') > 0.5)
result = confusionMatrix(as.factor(predict2), as.factor(BreastCancer_test$Class))
result
accuracy = as.numeric(result$overall['Accuracy'])
acc = acc + accuracy
j=j+1
}
acc_mean = acc / j
print(acc_mean)
break
}
#0.938011
#0.938011
#0.938011
#0.938011
