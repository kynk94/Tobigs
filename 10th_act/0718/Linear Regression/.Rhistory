##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~.,Boston)
summary(fit1)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~.,boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~.,Boston)
summary(fit1)
plot(Boston$medv~., Boston$medv)
plot(Boston$medv~, Boston$medv)
plot(Boston$~., Boston$medv)
plot(Boston$crim, Boston$medv)
plot(Boston$crim, Boston$medv)
plot(Boston$crim, Boston$medv)
plot(Boston$zn, Boston$medv)
plot(Boston$indus, Boston$medv)
plot(Boston$chas, Boston$medv)
plot(Boston$nox, Boston$medv)
plot(Boston$rm, Boston$medv)
plot(Boston$age, Boston$medv)
plot(Boston$dis, Boston$medv)
plot(Boston$rad, Boston$medv)
plot(Boston$chas, Boston$medv)  #어느정도?
plot(Boston$chas, Boston$medv)  #어느정도?
plot(Boston$indus, Boston$medv) #마찬가지
plot(Boston$rm, Boston$medv)    #확실
plot(Boston$age, Boston$medv)   #확실
plot(Boston$age, Boston$medv)   #확실
plot(Boston$dis, Boston$medv)   #확실
plot(Boston$rad, Boston$medv)   #애매
plot(Boston$tax, Boston$medv)
plot(Boston$ptratio, Boston$medv)#
plot(Boston$black, Boston$medv)
plot(Boston$lstat, Boston$medv)
summary(fit1)
plot(Boston$age, Boston$medv)     #T 0.052
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1) #F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#F도 P처럼 0.05보다 작아져야 유의미하다
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수?
plot(Boston$chas, Boston$medv)    #T   3.118
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$ptratio, Boston$medv) #T  -7.283
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수?
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수
summary(fit1)
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118
fit.step = step(fit1,both)
fit.step = step(fit1,'both')
fit.step = step(fit1,direction = 'both')
summary(fit.step)
plot(Boston$rad, Boston$medv)     #T   4.613
Boston$chas = factor(Boston$chas)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
str(Boston)
Boston$chas = as.factor(Boston$chas)
str(Boston)
#Boston$chas = as.factor(Boston$chas)
for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))
#Boston$chas = as.factor(Boston$chas)
for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))
str(Boston)
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
fit.step = step(fit1,direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
Boston$chas = factor(Boston$chas)
#Boston$chas = as.factor(Boston$chas)
for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))
#Boston$chas = as.factor(Boston$chas)
for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
fit.step = step(fit1,direction = 'both')
Boston$chas = factor(Boston$chas)
#Boston$chas = as.factor(Boston$chas)
for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
plot(Boston$zn, Boston$medv)      #T   3.382
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
plot(Boston$rm, Boston$medv)      #T   9.116
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
plot(Boston$lstat, Boston$medv)   #T -10.347
plot(Boston$tax, Boston$medv)     #T  -3.280
str(Boston)
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
fit.step = step(fit1,direction = 'both')
#Boston$chas = factor(Boston$chas)
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
plot(Boston$rm, Boston$medv)      #T   9.116
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$dis, Boston$medv)     #T  -7.368
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
plot(Boston$nox, Boston$medv)     #T  -4.651
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
plot(Boston$ptratio, Boston$medv) #T  -7.283지
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
fit.step = step(fit1,direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
yhat = predict(fit.step,newdata = Boston,type = 'response')
head(yhat)
plot(fit.step$fitted,Boston$medv)
abline(fit.step)
abline(0,1)
mean((Boston$medv-yhat)^2)
plot(fit.step$fit,Boston$medv)
plot(fit.step$fited,Boston$medv)
plot(fit.step$fitted,Boston$medv)
plot(fit.step$fit,Boston$medv)
plot(fit.step$fitt,Boston$medv)
plot(fit.step$fited,Boston$medv)
plot(fit.step$fiteed,Boston$medv)
plot(fit.step$fit,Boston$medv)
plot(fit.step$fitted,Boston$medv)
plot(fit.step$x,Boston$medv)
plot(fit.step$xxx,Boston$medv)
plot(fit.step$xxxx,Boston$medv)
plot(fit.step$fitted,Boston$medv)
plot(fit.step$fitted.values,Boston$medv)
plot(fit.step$fitted,Boston$medv)
plot(fit.step$fitted.values,Boston$medv)
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
str(Boston)
summary(fit1)
plot(Boston$zn, Boston$medv)      #T   3.382
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
fit.step = step(fit1,direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
#Boston$chas = factor(Boston$chas)
#for(i in 1:ncol(Boston))if(!is.numeric(Boston[,i]))Boston[,i]=as.numeric(Boston[,i])
yhat = predict(fit.step,newdata = Boston,type = 'response')
head(yhat)
plot(fit.step$fitted.values,Boston$medv)
abline(0,1)
mean((Boston$medv-yhat)^2) #
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
fit.step = step(fit1,direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
yhat = predict(fit.step,newdata = Boston,type = 'response')
head(yhat)
plot(fit.step$fitted.values,Boston$medv) #medv가 50인 이상점들이 있는듯? 3개가 영향값인것같고 지워야 할 것으로 보이는데 어떻게 지우지?
abline(0,1)
mean((Boston$medv-yhat)^2) #이상점 영향값 지우기 전 21.89993이 나온다.
fit.step
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
names(fit.step)
abline(fit.step, col='red')
abline(0,1,col='blue')
plot(fit.step$fitted.values,Boston$medv) #medv가 50인 이상점들이 있는듯? 3개가 영향값인것같고 지워야 할 것으로 보이는데 어떻게 지우지?
abline(0,1,col='blue')
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
vif(Boston$rad) #5~10이면 크다.
#install.packages("car")
#vif, outlierTest 등
library(car)
install.packages("car")
#1
library(boot)
#train/test partition
library(caret)
#ROC
library(ROCR)
vif(Boston$rad) #5~10이면 크다.
vif(fit1) #5~10이면 크다.
vif(fit.full)
install.packages("caret")
vif(fit1) #5~10이면 크다.
library(car)
vif(fit1) #5~10이면 크다.
vif(fit.step)
plot(fit.step$fitted.values,Boston$medv) #medv가 50인 이상점들이 있는듯? 3개가 영향값인것같고 지워야 할 것으로 보이는데 어떻게 지우지?
outlierTest(fit.step)
influence.measures(fit.both)
influence.measures(fit.step)
influence.measures(fit.step,id.method="identify", main="Influence Plot", sub="Circle size is proportional to Cook’s distance")
fit.step = step(fit1,direction = 'both')
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
library(car)
vif(fit1) #5~10이면 크다.
fit.step = step(fit1,direction = 'both')
fit.con <- lm(medv~ 1, Boston)
fit.step = step(fit1,direction = 'both')
fit.step = step(fit.con, list(lower=fit.con, upper=fit1), direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
#fit.step = step(fit1,direction = 'both')
fit.step = step(fit.con, list(lower=fit.con, upper=fit1), direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
vif(fit.step)
vif(fit.step)
outlierTest(fit.step)
vif(fit1) #5~10이면 크다.
library(car)
vif(fit1) #5~10이면 크다.
plot(Boston$lstat, Boston$medv)   #T -10.347
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
vif(fit.step)
vif(fit.step)
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
rm(list=ls())
# 데이터
library(MASS)
data(Boston)
str(Boston)
##### 회귀분석하기 #####
### medv(본인 소유의 주택가격(중앙값) 단위: $1,000)을 예측해주세요
#medv
fit1=lm(medv~., Boston)
summary(fit1)
#F는 연구모델의 적합성, P는 가설의 유의성 T는 변수들의 영향 * 갯수가 중요도를 의미
#분포곡선에서 x축에 T,F값이 존재하고 P는 T,F보다 큰 부분의 면적을 의미 -> 데이터연관성이 99.5%안에 들어야 유의미하다는 뜻이었네.
#T=Estimate/Std.Error 즉 Estimate에 비해 Error가 클수록 의미가 없다.
#sumary의 마지막부분인 Pr은 T이상인 부분의 면적. 면적이 작을수록 유의미.
#F는?
#R-squared가 0.7406이니까 74%를 설명한다는 것
#마지막 p-value는 모델에대한 F 검정의 P값, 이 경우 2.2e-16
plot(Boston$crim, Boston$medv)    #T  -3.287
plot(Boston$zn, Boston$medv)      #T   3.382
plot(Boston$indus, Boston$medv)   #T   0.334 -> 지워도 되는 변수, 보니까 균등하게 분포하면 지우네
plot(Boston$chas, Boston$medv)    #T   3.118 -> 근데 얘는 0,1로 나뉘는 변수, 강에서 멀수록 2.687만큼 비싸다? 상식과 반대됨
plot(Boston$nox, Boston$medv)     #T  -4.651
plot(Boston$rm, Boston$medv)      #T   9.116
plot(Boston$age, Boston$medv)     #T   0.052 -> 지워도 되는 변수
plot(Boston$dis, Boston$medv)     #T  -7.368
plot(Boston$rad, Boston$medv)     #T   4.613 -> 얘도 1단위 변수인데 어떻게 해야하지
plot(Boston$tax, Boston$medv)     #T  -3.280
plot(Boston$ptratio, Boston$medv) #T  -7.283지
plot(Boston$black, Boston$medv)   #T   3.467
plot(Boston$lstat, Boston$medv)   #T -10.347
library(car)
vif(fit1) #5~10이면 크다.
fit.con <- lm(medv~ 1, Boston)
#fit.step = step(fit1,direction = 'both')
fit.step = step(fit.con, list(lower=fit.con, upper=fit1), direction = 'both')
summary(fit.step) #indus, age가 지워졌다. chas도 지우고 따로 비교해야 하지 않을까?
vif(fit.step)
outlierTest(fit.step)
influence.measures(fit.step)
influencePlot(fit.step, id.method="identify", main="Influence Plot",
sub="Circle size is proportional to Cook’s distance")
