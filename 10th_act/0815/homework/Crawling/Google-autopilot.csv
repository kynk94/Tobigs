URL,Article
https://www.ttnews.com/articles/tesla-public-or-private-still-will-release-autopilot-safety-data,"Even as CEO Elon Musk pursues the idea of taking Tesla private, the electric automaker has confirmed that it still plans to release safety data on its Autopilot semi-autonomous driving feature.The safety of Autopilot, which can steer and adjust a car’s speed on the freeway, came under sharp scrutiny this spring after a Tesla Model X SUV running on Autopilot slammed into a freeway divider in Mountain View, killing the occupant. Musk insisted that in spite of the crash, Autopilot improves safety, and he said the Palo Alto, Calif., company would start issuing quarterly reports of its own internal data this year to prove it.Musk last week stunned Tesla investors by saying he was considering taking the company private, a move that would reduce the amount of information a business must make public each quarter. But the company confirmed Aug. 15 that it plans to issue an Autopilot safety report this quarter.950 N Glebe Road Suite 210, Arlington, VA 22203703-838-1770"
https://www.businessinsider.com/tesla-starts-offering-owners-free-autopilot-trials-2018-8,"Tesla has started offering owners a free, 14-day trial of its semi-autonomous Autopilot feature, Electrek first reported.A Tesla representative confirmed to Business Insider that the company is rolling out the trial. The company's website features additional information about the trial, though it doesn't include specific information about its start and end dates, saying only that owners who did not purchase Autopilot will receive the trial in the coming weeks.Tesla says on its website that Autopilot will automatically download to vehicles that don't have the feature shortly after they receive software update 2018.28.1 or later, at which point owners will be notified that their trial has begun. Owners will be able to decide whether or not they want to activate some Autopilot features during the trial or opt out entirely.Last week, during the company's second-quarter earnings call, CEO Elon Musk said the company will start rolling out ""breakthrough"" features to Autopilot in around four weeks. He said the update will ""certainly include some significant advancements in autonomy.""Stuart Bowers, Tesla's vice president of engineering, also said during the earnings call that the update will allow Tesla vehicles to ""automatically attempt to change lanes"" and suggested it could help drivers transition to and from highways. Bowers called the update, ""our on-ramp to off-ramp solution that's going to automatically attempt to change lanes, understand what lane the car is in, understand the route the user wants to travel, and take that route for the user and ultimately hand back control to user.""In its current iteration, Autopilot can keep a car in its lane, adjust its speed based on surrounding traffic, and park without driver assistance, among other features. Recent accidents involving the feature have raised questions about whether drivers place too much trust in it and fail to pay attention to the road. Tesla has repeatedly said Autopilot is meant to be used with an attentive driver whose hands are on the wheel, but the most visible accidents involving Autopilot have included reports of distracted drivers.Tesla has received criticism for how it has promoted the feature. In May, Consumer Watchdog and the Center for Auto Safety sent a letter to the Federal Trade Commission asking the agency to investigate the strategies the company has used to sell Autopilot.Have a Tesla news tip? Contact this reporter at mmatousek@businessinsider.com.Get the latest Tesla stock price here."
https://www.forbes.com/sites/davidsilver/2018/08/15/tesla-model-3-autopilot-outperforms-model-s-competitors-in-lane-keeping-test/,"ShutterstockThis post has been updated since it was originally published to reflect that the Tesla Model S in the test was running an older version of Autopilot than the Tesla Model 3.The Insurance Institute for Highway Safety tested five advanced driver assistance systems and reported that the Tesla Model 3 experienced the fewest incidents of crossing over a lane line, touching a lane line, or disengaging. The 2018 Model 3 also stayed within its lane more often than the four other vehicles in the test: 2017 BMW 5 series with ""Drive Assistant Plus"", 2017 Mercedes-Benz E-Class with ""Drive Pilot"", 2018 Volvo S90 with ""Pilot Assist"", and a 2016 Tesla Model S running an older version of Autopilot.The results appear in the IIHS special issue on autonomous vehicles.Across a set of 36 tests run on both hills and curves, the Model 3 drove outside of its lane only once, while the E-Class drove outside of its lane 12 times, the Model S 14 times, the S90 18 times, and the 5 series 33 times.Tesla Model 3WIKIMEDIA COMMONSThe difference in performance between the Tesla Model 3 and the Model S is particularly striking, as the Model 3 performed significantly better than the Model S, even though both models come from the same manufacturer. In fact, the Model S costs approximately 50% more than the Model 3, even though the Model 3 performed better on the IIHS tests. A key difference, however, is that the Model 3 was running version 8.1 of Tesla's Autopilot software, whereas the Model S was running version 7.1.David Zuby, the institute's chief research officer, stresses that a definitive ranking of driver assistance systems is not yet ready. In particular, a formal ranking system will take into account both how much of the driving task each system handles, and also how reliable each system is at handling the tasks it does undertake.We're not ready to say yet which company has the safest implementation of Level 2 driver assistance.""Even more than relative ratings, Zuby highlights the need for drivers to stay alert. ""A production autonomous vehicle that can go anywhere, anytime isn't available at your local car dealer and won't be for quite some time. We aren't there yet.""What do you think? Tweet me @dsilver829 and learn more at Udacity!I lead the Self-Driving Car Engineer Nanodegree Program at Udacity, which has trained thousands of engineers to work on autonomous vehicles. Udacity students have joined self-driving car teams at companies like Lyft, Mercedes-Benz, and NVIDIA. Prior to Udacity, I was a resea..."
https://www.sfchronicle.com/business/article/Tesla-public-or-private-will-still-release-13159080.php,"Even as CEO Elon Musk pursues the idea of taking Tesla private, the electric automaker has confirmed that it still plans to release safety data on its Autopilot semi-autonomous driving feature.The safety of Autopilot, which can steer and adjust a car’s speed on the freeway, came under sharp scrutiny this spring after a Tesla Model X SUV running on Autopilot slammed into a freeway divider in Mountain View, killing the occupant. Musk insisted that in spite of the crash, Autopilot improves safety, and he said the Palo Alto company would start issuing quarterly reports of its own internal data this year to prove it.Musk last week stunned Tesla investors by saying he was considering taking the company private, a move that would reduce the amount of information a business must make public each quarter. But the company confirmed Wednesday that it plans to issue an Autopilot safety report this quarter.David R. Baker is a San Francisco Chronicle staff writer. Email: dbaker@sfchronicle.com Twitter: @DavidBakerSFDavid Baker covers energy, clean tech, electric vehicles and self-driving cars for the San Francisco Chronicle. He joined the paper in 2000 after spending five years in Southern California reporting for the Los Angeles Times and the Daily News of Los Angeles. He has reported from wind farms, geothermal fields, solar power plants, oil fields and an offshore drilling rig in the Gulf of Mexico. He also visited Baghdad and Basra in 2003 to write about Iraq's reconstruction. He graduated from Amherst College and the Columbia University Graduate School of Journalism. He lives in San Francisco with his wife. You must be signed in to commentABOUTCONTACTSERVICES©2018 Hearst"
https://www.theverge.com/2018/8/1/17641186/tesla-elon-musk-self-driving-coast-to-coast-delay,"Tesla’s autonomous coast-to-coast drive, originally promised in 2016, is on hold while the company’s Autopilot team stays “heads down” on improving the driver assist system’s safety features, Elon Musk said in a call with investors Wednesday. Musk also teased a new software update to Autopilot — version 9.0 — coming in September that he said would be a stark improvement over the current version.Tesla built a new version of its semi-autonomous system, known as Autopilot, in 2016 after a public breakup with the original supplier of the technology. Shortly after unveiling the replacement hardware and software, Musk claimed that the company’s new version — Autopilot 2.0 — would be good enough that a car equipped with it would complete a trip from Los Angeles to New York without a single moment of human interference. Musk also said Tesla would be able to develop the tech fast enough to pull off this demonstration by the end of 2017. Earlier this year, he said the drive would be “upcoming.”But now it seems like we’ll have to wait even longer before Musk gives the green light. That is sure to disappoint Tesla’s fans, as well as investors and analysts, who watch closely for any updates on the company’s self-driving vehicle program. But it also may come as a relief for some who want Musk to stay focused on stabilizing the Model 3’s production and building a profitable, cash-positive company.“We could do a coast-to-coast drive, especially if we pick a specific route and write code to make it work, but that would be kind of gaming the system,” Musk said on the call Wednesday. “Better for the Autopilot team to focus on safety and existing features.” He later added that if he wanted to, Tesla could execute the coast-to-coast drive by the “end of the year.”Musk also provided some details about upcoming updates to Autopilot’s software and hardware. He let the “cat out of the bag” about Tesla’s efforts to build a custom-built AI chip to help power its autonomous driving capabilities.Pete Bannon, who replaced Jim Keller earlier this year as head of Autopilot, said that the new chip will be released as part of a “hardware 3” update for Autopilot, which will take the form of a new processor that will replace the existing computer in the vehicles. Musk added that the new hardware was an “order of magnitude” better than the version of Autopilot that exists today.Autopilot’s 2.0 hardware suite is powered by Nvidia GPUs, which Musk said were capable of processing 200 frames per second. He compared that to Tesla’s upcoming version 3.0 which will be able to handle 2,000 frames per second with redundancy. Musk has said previously that he can achieve his promise of “full self-driving” capabilities without lidar sensors, which most self-driving developers view as a linchpin to full autonomy.In May, Musk vowed to begin releasing a quarterly safety report about Autopilot. That report was not released with Wednesday’s quarterly earnings report. In prior calls, Musk has claimed there is “no question” that Autopilot reduces the chance of a driver getting in an accident. He has also repeatedly criticized press coverage of the company’s driver assistance feature. Autopilot faced increased scrutiny after a driver of a Tesla Model X died while using the driver assistance feature on a California highway in March.Command Line delivers daily updates from the near-future."
https://interestingengineering.com/elon-musk-reveals-tesla-autopilot-30-will-be-free-with-5000-full-self-driving-pack,"Elon Musk tweeted the long-awaited hardware upgrade will be added at no cost to buyers ordering Tesla's autonomous driving package. A few days ago Tesla CEO Elon Musk took to Twitter to thank Tesla customers and let them know some Autopilot upgrades were due soon. That time has now come it seems!Yesterday, Musk tweeted to share MIT researcher Lex Fridman's chart tracking the Tesla vehicles with different generations of Autopilot hardware. The post prompted a question from a journalist that has been on the mind of all Tesla lovers.Editor in chief of electric transport media outlet Electreck Fred Lambert asked the CEO when Autopilot 3.0 would be introduced and whether owners with hardware 2.0 would receive the upgrade free. Musk responded with some positive news!The latest software will be available in the next four to six months and will be free for customers who purchase the ‘Full Self-Driving’ pack. Autopilot 3.0 will enable the features promised in the package.Those features include double the number of active cameras, improved automatic charge connection and, most of all, the capacity for the vehicle to drive itself. Impressive as it is, this bundle does not come cheap.For starters, in order to even add the advanced package, Tesla buyers need to already have the ‘Enhanced Autopilot’ package. This option already costs $6,000 as an upgrade after delivery.The ‘Full Self-Driving’ pack can then be installed for $5,000 as an upgrade after delivery. Musk did mention in his tweet that the new software is not needed for owners who only want the 'Enhanced Autopilot' package.In Tesla's Q2 2018 financial results webcast, Musk told investors that head of Autopilot Pete Bannon and his team were on the path to ""create this, the world’s most advanced computer designed specifically for autonomous operation.” Bannon is currently leading the development of hardware 3.0.Bannon further confirmed Musk's claims during the call. “The chips are up and working, and we have drop-in replacements for S, X and 3, all have been driven in the field,” he added.What all this means is that Tesla may finally deliver on its promise of fully autonomous driving capability. A few hours after Musk's hardware 3.0 reply, Tesla revealed a free 14 day trial for the 'Enhanced Autopilot' option.The trial provides Tesla drivers two weeks of access to the pack's many features, including Autosteer, Traffic Aware Cruise Control, Auto Lane Change, Summon and Autopark, at no cost. Once completed, customers may purchase the option through the car’s touchscreen or their Tesla accounts.Via: Elon Musk/Twitter SPONSORED BY StackCommerceOffering both loop recording of G-sensor start-stop functionality, this dash cam keeps you safe while delivering stunning captures of your surroundings."
https://electrek.co/2018/07/28/tesla-model-3-autopilot-avoid-crash-nearmiss-dashcam/,"JULY 28Fred Lambert- Jul. 28th 2018 12:27 pm ET@FredericLambertAccidents involving Tesla vehicles on Autopilot often get reported in the media, but we don’t hear a lot about the accidents that didn’t happen because of Autopilot since it’s not as exciting when virtually nothing happened – though it’s arguably just as important.Now we have a good example with a Tesla Model 3 on Autopilot avoiding a crash in near-miss caught on a dashcam.Tesla’s Autopilot technology comes with a suite of crash avoidance features including side collision avoidance, which can alert the driver of a collision risk and even brake and steer away from a crash if it believes it to be safe to do so.That’s exactly what a Model 3 owner believes happened in a near-miss caught on camera.He wrote on Youtube:“Close call while cruising on the highway along with traffic when an idiot who was speeding and cutting everyone off almost sideswiped us with kid inside. Autopilot was engaged and started to brake and moved us to the right lane to avoid a collision. I guess it detected no vehicles on the right of us and I took over and powered out to steer us back into the original lane in front of that idiot. Be safe out there and always be alert even with Autopilot engaged and watch out for idiot drivers.”Here’s the dashcam video of the near-miss (Youtube TeslaExposed):The driver added that he took control of the steering when you hear the horn and then controlled the Model 3 as it went back into the lane.The near miss is reminiscent of another incident back in April of 2016. A Tesla Model S narrowly avoided a side collision when a boom-lift truck merged in the right lane without looking. The whole thing was also caught on camera and the driver, Joshua Brown, the same Tesla owner who died in a car crash on Autopilot a month later, credited the system for saving him.As the Model 3 owner said, it is still important to always be alert on Autopilot because, under the current version of the autonomous driver assist system, it still not perfect and can miss some of those situations.Drivers are still responsible for their vehicles and they should always treat Autopilot as a driver assist system and not a fully autonomous driving system, even with an impressive performance like displayed in this video.Tesla is a transportation and energy company. It sells vehicles under its 'Tesla Motors' division and stationary battery pack for home, commercial and utility-scale projects under its 'Tesla Energy' division.The Tesla Model 3 is the first vehicle built on Tesla's third-generation platform. It aims to reduce the entry price for electric vehicles while not making any compromise on range and performance. The Model 3 starts at $35,000 in the US and deliveries to employees and company insiders began in mid 2017 - customer deliveries begin in late 2017.@FredericLambertFred is the Editor in Chief and Main Writer at Electrek.You can send tips on Twitter (DMs open) or via email: fred@9to5mac.comIf you want to help Fred and Electrek, you can contribute to our Patreon: https://www.patreon.com/electrekElectrek Podcast: Tesla craziness intensifies, base Mod...Tesla could make a $25,000 electric car in ‘about..."
https://insideevs.com/get-your-free-tesla-autopilot-trial-now/,"AUG 10 2018 BY VANJA KLJAIC 8Earlier this year, Elon Musk teased several Autopilot developments during the 2018 Annual Shareholder Meeting. Now, the company is starting to roll out a 14-day free trial program for the Enhanced Autopilot. Owners who have opted out of the driver-assist system when they purchased their vehicles are the first ones to receive the invitations.Even though Tesla already offered its Autopilot software as a free trial to its customers, this is the first time the company is offering free trials for Enhanced Autopilot, a driver-assist system that the company designed in-house.Currently, Tesla delivers every car with Autopilot hardware and leaves the option to activate the feature by the owner at a later date. The owner can do that either within the ordering process or as an over-the-air update later on.In the last few days, eligible owners received an e-mail that informs them that they will soon have access to the autopilot trial.In the next 24 hours, your Tesla will receive access to a 14-day Enhanced Autopilot trial at no cost.During the trial, you’ll experience our most advanced driver assistance features, including: Autosteer – Assisted steering within your lane Traffic – Aware Cruise Control – Cruise control that matches the speed to traffic – Auto Lane Change – Assisted lane changes while driving on the highway – Summon – Automatically park and retrieve your vehicle – Autopark – Parallel and perpendicular parking, with a single touch.You’ll get a notification to your touchscreen when the trial is ready. If you select ‘Enable’, all Enhanced Autopilot features, including Autosteer and Auto Lane Change, will immediately be activated and available to use.Please only enable these features if you will pay attention to the road, keep your hands on the steering wheel, and be prepared to take over at all times.Additionally, Tesla has also launched a support page for the trial on their website. Every eligible owner will have the option to purchase the Enhanced Autopilot at any time during the free trial period. Owners can do that either through the vehicle’s touchscreen or through a Tesla Account.The cost is $5,000 for Hardware 1 cars and $6,000 for vehicles equipped with Hardware 2. For owners that decide to purchase the Enhanced Autopilot from their vehicles, they will have to navigate to the free trial screen in the “Autopilot” tab in the Settings menu, and select the “Order Now” option. All Autopilot features would become permanently available after the system is purchased.Source: TeslaratiCategories: TeslaTags: tesla autopilotSubscribe to our e-mail newsletter to receive updates.By subscribing to the newsletter I agree to the Privacy Policy and Terms of Service8 Comments on ""Get Your Free Tesla Enhanced Autopilot Trial Now""No thanks on AP.First get the car.It’s for his phone, you silly. He keeps bumping into walls while it’s in his pocket.Interesting…I don’t see the word BETA anywhere in that notification. Does this mean with V9, Enhanced Auto Pilot is out of beta?Get Your Free Tesla Enhanced Autopilot Trial Now… …and DieIgor the Russian troll has spoken!Free trials and free test subjects…Already have it :-)… I just debate on whether to get full autonomous driving… decisions, decisions…"
https://electrek.co/2018/08/08/tesla-autopilot-hardware-upgrade-free-with-full-self-driving-package/,"AUGUST 8Fred Lambert- Aug. 8th 2018 6:36 pm ET@FredericLambertAfter announcing an upcoming new Autopilot 3.0 hardware upgrade last week, Elon Musk now updates us on the timing and confirms who is going to get the upgrade for “free” – or more accurately, included with an existing Autopilot package.During its second quarter conference call last week, Tesla claimed that it now has the ‘world’s most advanced computer for autonomous driving’ and that it will be released in an Autopilot 3.0 upgrade coming “next year”.It consists of a new computer based on a chip developed in-house by Tesla especially to run a computer vision neural network, which Tesla has been using to power the latest generation of the Autopilot.The company claims that this new chip increases the processing capacity by an order of magnitude and will enable Tesla to bring fully self-driving capability to its vehicles, which Tesla has been advertising as being compatible with its vehicles since October 2016 when they introduced the Autopilot 2.0. suiteToday, Musk shared a chart by Lex Fridman, an MIT researcher who has been tracking a lot of Tesla Autopilot-related data, that shows the vehicles delivered by Tesla with different generations of Autopilot hardware:It led me to ask Musk about a more precise timing for the release of the third generation hardware and details about the rollout.The CEO responded:That’s a much-appreciated clarification that wasn’t made after Tesla announced the new hardware last week.Basically, Musk is saying that Tesla can deliver the promised features under the ‘Enhanced Autopilot’ package with the current computer power inside vehicles with Autopilot 2.0+ hardware.The new computer will enable the features promised in the ‘Full Self-Driving’ package, which of course includes the capacity for the vehicle to drive itself.It means that those who bought the package will receive the computer upgrade for free and those who haven’t will need to buy the package through an over-the-air update.In order to get the package, buyers need to have the ‘Enhanced Autopilot’ package, which costs $5,000 when ordering the vehicle and $6,000 if buying later on through an over-the-air update.Once you have this package, the ‘Full Self-Driving Capability’ costs $3,000 when ordering and it used to cost $4,000 when buying over-the-air later.In June, Tesla increased the price of the package when bought through an over-the-air update after delivery to $5,000.Tesla told Electrek that they will honor the original price for existing owners who didn’t buy the package thinking that they could later upgrade over-the-air for $4,000.With Musk’s comment today, it looks like those owners who don’t have ‘Full Self-Driving’ package right now will be able to upgrade for $4,000 and get the new computer when it becomes available.Electrek’s TakeThat makes sense and it is something many Electrek readers pointed to as a likely possibility in our last article about the changes.The need to have the ‘Full Self-Driving Capability’ package, which Tesla has now been selling for $3,000 to $5,000, to get the upgrade will enable Tesla to recuperate some of the cost to retrofit what will likely end up being over 300,000 vehicles by the time the new computer goes into production.It also makes it more attractive for new Model 3, Model S and Model X buyers right now to order the car with ‘Full Self-Driving Capability’ package since it will enable them to get the upgrade for $2,000 cheaper.Of course, that is if you want fully autonomous driving capability and you believe Tesla can deliver on the promise with the upcoming new hardware.This is certainly a strange situation in the auto industry since it involves hardware retrofits, over-the-air software updates and option packages, as well as autonomous driving capability.Tesla is a transportation and energy company. It sells vehicles under its 'Tesla Motors' division and stationary battery pack for home, commercial and utility-scale projects under its 'Tesla Energy' division.The Autopilot is Tesla's advanced assisted driving program with features like Autosteer, Autopark, and Trafic-Aware Cruise Control (TACC).@FredericLambertFred is the Editor in Chief and Main Writer at Electrek.You can send tips on Twitter (DMs open) or via email: fred@9to5mac.comIf you want to help Fred and Electrek, you can contribute to our Patreon: https://www.patreon.com/electrekElectrek Podcast: Tesla craziness intensifies, base Mod...Tesla could make a $25,000 electric car in ‘about..."
https://www.techrepublic.com/article/teslas-autopilot-cheat-sheet/,"INNOVATIONEverything you need to know about Tesla's onboard computer system called Autopilot, and the company's plans for a self-driving car.By Nick Heath | August 1, 2018, 9:23 AM PSTTesla has grand plans for the Autopilot computer system in its cars, but how realistic are the firm's self-driving vehicle ambitions?SEE: Elon Musk and the cult of Tesla: How a tech startup rattled the auto industry to its core (free PDF) (TechRepublic cover story)Autopilot is an optional driver-assist system for Tesla cars that Tesla CEO Elon Musk has promised will eventually turn the electric cars into fully self-driving vehicles.When Autopilot is engaged, cars can self-steer, adjust speed, detect nearby obstacles, apply brakes, and park. The technology uses a combination of radar, cameras, ultrasonic sensors, and GPS.Tesla says the onboard computers in its Autopilot-enabled cars released since October 2016 can support full self-driving capabilities, and that this functionality will be added via firmware updates over time, subject to regulatory approval.Note: TechRepublic's first Tesla Autopilot cheat sheet was originally published in July 2016.Not yet. Currently, Autopilot is not rated as a fully self-driving system.Instead, Autopilot is currently classed as a Level 2 automated system by the US National Highway Transportation Safety Administration. Level 2 designation means Autopilot is capable of ""combined automated functions, like acceleration and steering"" but that the driver must remain engaged with driving at all times.SEE: All of TechRepublic's cheat sheets and smart person's guidesAt present, the latest version of the Autopilot software, known as Enhanced Autopilot, offers driver-assist features mainly designed to help with highway driving. These features include:Other features include Automatic Emergency Braking and Steering, Automatic High Beams, Blind Spot Detection, and Speed Assist.Those who don't want to pay for Autopilot, who chose not to pay for the Enhanced Autopilot package, can only use safety features such as lane-departure warning, automatic emergency braking, and collision warning.SEE: Tech and the future of transportation (ZDNet special report) | Download the report as a PDF (TechRepublic)Tesla says Autopilot's sensors allow the onboard computer system to build a detailed picture of its surroundings, allowing the vehicle to anticipate possible collisions with vehicles, pedestrians, cyclists, animals, debris, and other obstacles. It can also detect road markings, signs, and traffic lights.For drivers that opt for the Enhanced Autopilot and Full Self-Driving Capability, systems in cars launched since October 2016 rely on the following sensors.Forward-looking radar: The radar used by Autopilot can see up to 160m ahead of the car, through ""sand, snow, fog—almost anything,"" according to Musk. Radar is the primary sensor used to detect the vehicle's surroundings, along with the front-facing cameras.Eight cameras: The four forward-facing cameras on the windshield of the car serve as a backup to the radar. The cameras consist of a narrow camera that captures footage 250m in front, a main camera that captures 150m in front, a wide-angle camera that captures 60m in front, and a camera that captures footage 80m in front and to the side of the car. The wide-angle camera is designed to read road signs and traffic lights, allowing the car to react accordingly, however, there is debate over whether this feature is enabled in cars with Autopilot 2.0 hardware. A pair of rear cameras captures footage up to 100 meters to the rear and the rear sides of the car.Sonar: A 360-degree, ultrasonic sonar detects obstacles in an eight-meter radius around the car. The ultrasonic sensors can spot objects like a child or a dog, and work at any speed. This feature can also detect objects in blind spots and assist the car when automatically switching lanes.GPS: A satellite navigation system can detect the car's position on the road.Additional resources:Today, all Tesla vehicles—Model S, Model X, and the new Model 3—are equipped with a custom-version of the Nvidia Drive PX2 platform.The computer delivers more than 40 times the processing power of the system used in earlier cars and runs a Tesla-developed neural net that ""sees"" the world around it by interpreting data collected by the cameras, radar, and ultrasonic sensors.There have been major updates to the onboard computer and sensor array used to run Autopilot since its launch, with revisions including AutoPilot 1.0, Autopilot 2.0, and Autopilot 2.5.Tesla says since Autopilot 2.0 was introduced in October 2016 all cars that opt into Enhanced Autopilot and the Full Self-Driving Capability ""have the hardware needed for full self-driving capability at a safety level substantially greater than that of a human driver"".However, since making this claim, Tesla has still upgraded Autopilot's underlying computer hardware, and in mid-2017 it began fitting cars with Autopilot 2.5 hardware, which adds an additional system-on-a-chip (SoC) to the custom Nvidia Drive PX2 platform used in Tesla cars.Tesla hasn't confirmed which chip was added, although it is rumored to be an Nvidia Parker SoC, but has described the addition as a minor change. Tesla is also working on its own custom AI chip that Musk says will be able to analyze 10x more frames of video per second than the existing Nvidia platform, and which will feature in upcoming Autopilot 3.0 hardware. Despite these planned upgrades for future cars, Tesla has previously said that, in the ""highly unlikely"" event that Autopilot 2.0 hardware can't support fully autonomous driving, it will upgrade cars at no additional cost if owners had opted for the full self-driving package.There is also some debate among Tesla owners over whether Autopilot has lost, as well as gained, capabilities over time.A Tesla employee drives a Model S electric automobile, equipped with an early Autopilot version on a highway in Amsterdam, the Netherlands.Some automotive industry experts have questioned whether a Tesla would be capable of becoming fully autonomous driving without using a lidar, a sensor which measures distances between objects using pulses of light.Many other self-driving cars, such as those made by Waymo, rely on lidar to provide precise distance measurements and high-resolution maps of surrounding objects. Musk has argued lidar serves only as a ""crutch"", and that it's possible for driverless cars to rely solely on radar, cameras, ultrasonic sensors, and GPS, as is the case in Tesla vehicles.Additional resources:Autopilot is available for the Tesla models S, X, and 3, and will likely be used in all future cars released by Tesla.Since launch, there have been several crashes, including fatalities, involving Teslas using Autopilot.The first fatal crash involving a Tesla using Autopilot occurred in May 2016, when a Model S collided with the trailer of a truck turning left across the path of the car.At the time Tesla issued a statement indicating the accident resulted from a series of highly unlikely circumstances.""Neither Autopilot nor the driver noticed the white side of the tractor trailer against a brightly lit sky, so the brake was not applied,"" it stated.""The high ride height of the trailer combined with its positioning across the road and the extremely rare circumstances of the impact caused the Model S to pass under the trailer, with the bottom of the trailer impacting the windshield of the Model S. Had the Model S impacted the front or rear of the trailer, even at high speed, its advanced crash safety system would likely have prevented serious injury as it has in numerous other similar incidents.""In its report into the collision, the U.S. National Highway Traffic Safety Administration (NHTSA) Office of Defects Investigations concluded that Autopilot and other onboard safety systems were working at the time of the crash, going on to say: ""Although these technologies had limitations, the ADAS [Advanced Driver Assistance System] system did not respond to an impending crash event.More recently, a Tesla Model X using Autopilot was found by the US National Transportation Safety Board (NTSB) to have been steered into a crash barrier while traveling at just over 70mph on a US Highway 101 in Mountain View, California.The NTSB reported the vehicle didn't detect the driver's hands on the wheel for six seconds prior to the crash. It found the car was steered to the left seven seconds before impact, and, rather than braking or taking evasive maneuvers, the vehicle accelerated in those final seconds.In the wake of the crash, Tesla said it was ""working closely with investigators to understand what happened, and what we can do to prevent this from happening in the future"".It also released statistics that there is one automotive fatality every 86 million miles across all vehicles from all manufacturers, going on to state ""for Tesla, there is one fatality, including known pedestrian fatalities, every 320 million miles in vehicles equipped with Autopilot hardware. If you are driving a Tesla equipped with Autopilot hardware, you are 3.7 times less likely to be involved in a fatal accident"".Additional resources:There's a big question mark over when, given there are no fully self-driving cars certified to operate without any human assistance today.Elon Musk recently said that Tesla's plan to demonstrate Autopilot's full self-driving abilities had been put on hold to allow the Autopilot team to focus on safety and existing features.SEE: The new commute: How driverless cars, hyperloop, and drones will change our travel plans (free PDF) (TechRepublic cover story)Although the technology that enables self-driving cars—the radar, cameras, GPS, lidar, and machine-learning systems—have become much more capable and affordable in recent years, many automakers are more conservative in estimating how quickly self-driving cars will be developed, with most planning to have a semi-autonomous vehicle available no earlier than 2020.Additional resources:Even if Tesla were to develop the technology to support fully self-driving cars there would still be regulatory roadblocks. Some US states currently have specific laws that would ban autonomous driving. Without clear regulations, testing self-driving cars is a challenge.Alabama, Arkansas, California, Colorado, Connecticut, Florida, Georgia, Illinois, Indiana, Kentucky, Louisiana, Maine, Michigan, Mississippi, Nebraska, New York, Nevada, North Carolina, North Dakota, Oregon, Pennsylvania, South Carolina, Tennessee, Texas, Utah, Virginia, Vermont, Washington and Wisconsin—and Washington D.C.—have all passed legislation related to autonomous vehicles, as of July 2018.According to Jeffrey Miller, IEEE member and associate professor of engineering at the University of Southern California, that progress is partly a result of lobbying pressure from Silicon Valley and auto companies in the state.Tesla is not the only car manufacturer hoping to build self-driving cars. Several large automakers, including Ford, Volvo, and Toyota, have announced plans to develop AI systems capable of autonomous driving, and companies such as Waymo, and to a lesser extent Uber, have extensive autonomous car programs.In addition to the cost of the car, Tesla charges $6,000 for Autopilot's driver assist features—known as Enhanced Autopilot—and $5,000 for the ""full self-driving capability"" Tesla says will eventually be enabled.Additional resources:Nick Heath is chief reporter for TechRepublic. He writes about the technology that IT decision makers need to know about, and the latest happenings in the European tech scene.Training // From ZDNet AcademyLearn the Mathematics & Algorithms Behind the Next Great Tech Frontier with These 11 Instructive Hours.eBooks // From TechRepublicTraining // From TechRepublic AcademyeBooks // From TechRepubliceBooks // From TechRepublicCan Russian hackers be stopped? Here's why it might take 20 yearsThe new commute: How driverless cars, hyperloop, and drones will change our travel plansExomedicine arrives: How labs in space could pave the way for healthcare breakthroughs on EarthHow Sephora is leveraging AR and AI to transform retail and help customers buy cosmeticsWe deliver the top business tech news stories about the companies, the people, and the products revolutionizing the planet.Delivered DailyOur editors highlight the TechRepublic articles, galleries, and videos that you absolutely cannot miss to stay current on the latest IT news, innovations, and tips.Delivered FridaysmacOS Mojave: A guide for IT leadersQuick glossary: Streaming videoComparison chart: NAS devicesDigital transformation research report 2018: Strategy, returns on investment, and challenges"
https://www.thestreet.com/technology/these-vehicles-can-not-drive-on-their-own-tesla-autopilot-included-14679368,"The Insurance Institute for Highway Safety recently ran a test on which cars have the best autonomous driving capabilities.No, they didn't test robo-taxi services like Alphabet's (GOOGL - Get Report) (GOOG - Get Report) Waymo or General Motors' (GM - Get Report) Cruise unit. Instead, the IIHS tested five luxury cars that many consider to have the top autonomous driving features.They included the Tesla (TSLA - Get Report) Model 3 and Model S, the Mercedes (DDAIF) E-Class, the BMW 5-Series and Volvo S90. However, there is an important distinction to note with the Tesla vehicles. The Model 3 is equipped with Autopilot version 8.1, while the Model S was running on version 7.1 and one camera.Spoiler alert: The Model 3 did much better than the S. With Tesla's Autopilot version 9 expected to come out in the next several weeks, there's no telling what type of improvement these results will yield.In any regard, the IIHS put the five vehicles through a number of tests, which include lane-keeping ability and emergency braking. For the lane-keeping test, each car was tested six times on six different tracks -- three hilly highways and three curvy highways. The IIHS wanted to put these cars through tough tests, seeing how they do when the lane markings disappear from sight. Touching or crossing the lane was considered a fail.The Model 3 performed the best, passing on 35 of its 36 runs. Notably, the car touched its lane but did not lose the lane on its one strike. The Model S didn't fair as well, but was a mixed bag. The vehicle failed a whopping 12 out of 18 times on the hilly test, but passed on 17 of 18 runs on the curvy track (the Model 3 went 18/18 on the curve run).Interestingly, the Mercedes E-Class did better on the hills vs. curves, scoring 83% and 50%, respectively. BMW put up a goose egg on the hills, failing on each run, while only passing on 3 fail-proof runs on the hill course. Further, the BMW 5-Series disengaged a whopping 16 times out of its 36 runs.The Volvo S90 disengaged four times during its runs and only kept its lane half the time in each test.In this regard, Tesla's Model 3 was a big-time winner compared to others and a sign that Tesla really is advancing rapidly in the autonomous driving game. Adaptive cruise control allows vehicles to accelerate and slow down based on the vehicle in front of them. With only emergency braking turned on and with ACC turned off, not all cars performed the same.There was good and bad news with this test for Tesla, starting with the latter. While driving at 31 mph toward a stationary object, both the Model S and Model 3 braked too late and hit the object. The E-Class, 5-Series and S90 all stopped in time.With ACC turned on, though, neither Tesla hit the object and actually began braking before its Mercedes and BMW counterparts. All four cars decelerated gently, making for a comfortable stop, while the S90 hit the brakes forcefully with ACC engaged.Other tests included following a lead driver who decelerates and another where the lead driver abruptly changes lanes and in doing so, reveals a stationary inflatable vehicle ahead of the test car.In the first instance, all five vehicles ""decelerated smoothly,"" according to IIHS. In the second scenario all but the S90 decelerated smoothly, with none of the vehicles hitting the object.Following vehicles doesn't seem to be an issue, but encountering stopped vehicle can be. All of the vehicle except the Model 3 failed at some point in this regard when testing on public road with ACC engaged, although the Model 3 proved to be a bit overly cautious. Seven of its 12 braking incidents were for tree shadows. While we would generally want a cautious car over an aggressive one, unnecessary braking can cause accidents, along with driver frustration.The conclusion?""We're not ready to say yet which company has the safest implementation of Level 2 driver assistance, but it's important to note that none of these vehicles is capable of driving safely on its own,"" says David Zuby, IIHS chief research officer.That's a strong stance on the matter and big reality check for the autonomous driving industry. Alphabet is a holding in Jim Cramer's Action Alerts PLUS member club. Want to be alerted before Jim Cramer buys or sells GOOGL? Learn more now.Thought flying private was a billionaires-only thing? A startup wants to bring ride-sharing to the skies, making private flight as easy as hailing a car -- and nearly as affordable.Blackbird is taking ride-sharing to the skies, expanding a service called Hitch that lets anyone hop a ride on a private plane. And you don't need to be rich to afford the service, Blackbird says.Amazon's Echo is still the most popular home speaker, but Alphabet's Google Home is quickly catching up. And Alphabet is moving aggressively to own the booming global market.Valuations for chip industry firms often seem to be pricing in a full-blown cyclical downturn. That's not a given at this point.Here's what you missed on TheStreet.Sign up to get started or log in to see your watchlist.SIGN UPLOG IN"
https://www.heraldgoa.in/Edit/Editorial/Where-governance-is-autopilot-politics-is-virtual-reality/134931.html,"SUNDAY, AUGUST 19, 2018Share this story................... Advertisements ...................© M/s Herald Publications Pvt LtdAF/1-4, Campal Trade Center, Behind Military Hospital, Panjim -Goa 403001.Telephone: +91-832-2224202, +91-832-6518500     Fax: 2225622     Email: online@herald-goa.comAdvertise     |     Contact Us     |     About Us     |     Terms of Use     |     Privacy Policy     |     Disclaimer     |     Designed by Team Inertia Technologies"
https://cleantechnica.com/2018/07/19/tesla-autopilot-miles-skyrocketing-cool-graphs/,"July 19th, 2018 by Guest Contributor Originally published on EVANNEX. By Charles MorrisThe MIT Autonomous Vehicle Technology Study (MIT-AVT), which is studying human-AI interaction in driving, has collected masses of real-world driving data, and is using that data to glean all sorts of insights of interest to Tesla fans. In a previous post, we admired a set of nifty charts, prepared by study co-author Lex Fridman, that illustrate how many Tesla vehicles with each version of Autopilot hardware are on the roads.Now Mr. Fridman has aggregated various publicly available data sources to elucidate the total number of miles driven by Autopilot-equipped Tesla vehicles.Fridman has charted the number of miles driven using both Autopilot hardware versions, as well as the number of miles driven in shadow mode (in which Autopilot logs the data streams from vehicles even when they are under manual control).Fridman estimates that Tesla vehicles have driven over 7.8 billion miles in the aggregate, over 1.2 billion of those miles in Autopilot mode and over 1.6 billion in shadow mode. Even more impressive than the size of these figures is how quickly they were reached — less than 3 years. With deliveries accelerating, the number of miles and the amount of data gathered will soon go into hockey-stick mode, keeping Tesla miles ahead of any potential competitors in the vehicle autonomy race.According to Fridman’s calculations, the average number of miles driven per Tesla vehicle per day is 31.76, and the average number of Autopilot miles driven per Autopilot-enabled vehicle per day is 7.91. This means that Autopilot-capable vehicles are operating in Autopilot mode about 25% of the time.As Fridman sees it, Tesla is striving to develop AI systems that save human lives at a very large scale. “The stakes are high and the pressure on engineers to do the best work of their life couldn’t be higher. We have a lot of data in the MIT-AVT study that helps illuminate how to take on this life-critical challenge.”Fridman and his colleagues invite all Tesla owners to help with the research by taking (and sharing) his team’s detailed survey on Autopilot.Source: MIT Autonomous Vehicle Technology StudyTags: AI, artificial intelligence, human-AI interaction, MIT, MIT Autonomous Vehicle Technology Study, MIT-AVT, self driving cars, Tesla, Tesla autopilot, Tesla Autopilot hardwareGuest Contributor is many, many people. We publish a number of guest posts from experts in a large variety of fields. This is our contributor account for those special people. :DAdvertise with CleanTechnica to get your company in front of our readers.CleanTechnica's main, daily newsletterCleanTechnica's EV newsletterCleanTechnica's wind newsletterCleanTechnica's solar newsletterCleanTechnica's weekly newsletterCleanTechnica is the #1 cleantech-focused news & analysis website in the US & the world, focusing primarily on electric cars, solar energy, wind energy, & energy storage. It is part of Important Media -- a network of 20 progressive blogs working to make the world a better, greener place.The content produced by this site is for entertainment purposes only. Opinions and comments published on this site may not be sanctioned by, and do not necessarily represent the views of Sustainable Enterprises Media, Inc., its owners, sponsors, affiliates, or subsidiaries.© 2018   Sustainable Enterprises Media, Inc."
https://www.teslarati.com/tesla-model-3-robert-scoble-autopilot-roadtrip/,"Futurist Robert Scoble’s 8,910-mile road trip across 22 states and 15 major US cities with his three sons gave him an intimate look into the capabilities of his Model 3’s Autopilot system. Scoble’s early build Model 3 with VIN 7409 managed to navigate the majority of the road trip with the driver-assist system engaged — a feat that thoroughly impressed the tech veteran. Scoble gave Teslarati a few minutes of his time to discuss some of his insights during the journey, where he elaborated on some of his observations about the system’s limits, its impressive potential, and how Tesla’s hardware can ultimately usher in the company’s self-driving future.Scoble candidly stated that around 97% of the 8,910-mile road trip was done on Autopilot. The Model 3 owner remarked that Autopilot had some difficulty working on some dirt roads in Yellowstone national park, as well as in areas where other drivers did not follow speed limits. Nevertheless, Scoble is overall impressed with his Model 3’s Enhanced Autopilot feature, particularly since it was able to work in areas where he himself would have difficulty driving. When he and his children were passing through Kansas, for example, Autopilot had no problems staying in the right lane — despite the road markings being nigh-invisible. The same thing was true in instances when the sun was too bright.This is not to say that Tesla’s Autopilot is perfect in its current form, of course. Scoble noticed that the sensitivity of his Model 3’s sensors’ to markings on the road is a double-edged sword, at least in its current state. It can see markings in areas where the paint is nearly undetectable to the eye, but it is also so sensitive that it can be misled into thinking that some areas in roads are lanes when they are not. Scoble also noted that there is a particular type of underpass whose shadow gets registered as a truck by Autopilot and caused his Model 3 to brake hard, a situation that can become dangerous if there’s a vehicle tailgating.The Model 3 only prompted Scoble to take over in very specific instances, particularly when the vehicle is going on a hairpin turn at around 30 mph. Scoble remarked that his Model 3 would start navigating through the hairpin curve with initial confidence, but about a third of the way in, Autopilot would veer off course, and the vehicle would prompt him to take control. The Model 3 owner further noted that sometimes, the car gets too close to the center lane in mountain passes, which is a bit too close for incoming traffic.Midway through the trip, Scoble’s Model 3 received an over-the-air update, and from then on, Autopilot showed a massive improvement. Scoble candidly stated that the system “still failed, but it failed more gracefully.”As a tech evangelist, asking people’s perception about the bleeding edge of technology is second nature for Robert Scoble. As he crossed state lines and visited cities, he began asking around for opinions about the emergence of self-driving vehicles. Scoble noted that when he asked people if they would be open to riding in a car entirely driven by a machine, a vast majority firmly said no. When presented with Elon Musk’s vision of having cars summoned to owners even across long distances, the reaction was very different.“The real thing I learned from this trip is that people show so little trust to self-driving. But if I ask ‘If your car self-drove to you, but you take over when it arrives?’ everyone said yes. People are okay with self-driving cars on the road. They just don’t want to be in the vehicles themselves. People still want control,” he said.As he ended his 8,910-mile road trip, Scoble remains optimistic about Tesla’s Autopilot system, especially with the upcoming rollout of Tesla’s in-house developed Hardware 3. Elon Musk described Hardware 3 as a significant step forward for Autopilot, dubbing the hardware as the “world’s most advanced computer designed specifically for autonomous operation.” “It’s an incredible job by Pete (Bannon) and his team to create this, the world’s most advanced computer designed specifically for autonomous operation. And as a rough sort of whereas the current NVIDIA’s hardware can do 200 frames a second, this is able to do over 2,000 frames a second and with full redundancy and fail-over. And it costs the same as our current hardware and we anticipate that this would have to be replaced, this replacement, which is why we made it easy to switch out the computer, and that’s all that needs to be done. If we take out one computer and plug in the next. That’s it.”This is something that excites Robert Scoble. Over the course of his road trip, he noticed that his Model 3’s hardware seemed to be pushing its limits when he sets the vehicle’s speed past 90 mph, and it is only by lowering the electric car’s speed to 80 mph does the ride become smoother. Scoble expects Hardware 3 to be advanced enough to travel at Autobahn speeds in Autopilot. This, according to the futurist, gives Tesla a serious advantage in the autonomous driving industry — and for a very simple reason.“Tesla’s the only car company that is based on data,” he said.Questions: Since Tesla has not yet released any $35k M3s were not the cars that Munro and the group...dzcJohnAre you sure you have your info correct? I don't think Toyota has ever sold 1M Prius in ...I am buying my first car a moment from now. And would love to have a Tesla as my first car but can&#...Tesla news, rumors and reviews on all things Tesla. Connecting owners and enthusiasts via @TeslaratiApp available on iOS and AndroidCopyright © TESLARATI. All rights reserved."
https://www.teslarati.com/tesla-tsla-420-share-bargain-autopilot-data/,"Questions continue to swirl around the fate of Tesla stock (NASDAQ:TSLA) as the market waits for updates about Elon Musk’s initiative to make the company private. Tesla’s privatization, provided that it does go through, will be the largest one in history, amounting to around $70 billion at Musk’s target of $420 per share. While this amount is substantial, $420 is actually a pretty good deal for Tesla’s would-be funding partners, considering the volume of Autopilot data the company has gathered from its Model S, Model X and Model 3 fleet.Tesla’s possible privatization has caused wild swings in Tesla’s stock price, though not too far a departure from its usual volatility. Upon Musk’s announcement, shares climbed up 11%, before falling back as reservations emerged from critics about the plausibility of the company’s privatization. On Thursday’s after-hours, Tesla stock recovered some of its losses as the company’s board of directors issued a statement stating that they would formally review Musk’s plans.Gene Munster, Managing Partner at Loup Ventures believes that there is more than a 50% chance that Tesla would become a private company. Munster noted that while concerns about the possible repercussions of Musk’s go-private Twitter announcement might affect the stock, the effects would only be felt at the very short-term. Ultimately, the venture capital firm believes that neither Tesla nor Elon Musk is at legal risk, especially since the company stated on a 2013 Form 8-K  that social media might be used as an outlet for disseminating company information. Loup Ventures also estimates that Tesla would need around $25-$30 billion to take the electric car and energy company private.If Loup Ventures’ calculations prove accurate, the entities providing the company with the funding to go private would be getting quite a deal at $420 per share. Apart from Tesla’s electric car and energy business — both of which are growing at an immense rate — investors would also be buying into a company that holds what could very well be automotive world’s most extensive amount of real-world driving data. As of July, a report from MIT’s Lex Fridman estimated that Tesla had acquired around 1.2 billion miles on Autopilot and approximately 7.8 billion miles in Autopilot “Shadow Mode.”In comparison, Waymo’s fleet of vehicles have driven a total of 5 million real-world miles in self-driving mode and an additional 5 billion miles in simulation as of May this year. GM Cruise, another leader in self-driving technology, does not release the numbers of its fleet, but accident and disengagement reports based on autonomous miles driven provide a rough estimate of the miles Cruise’s vehicles have traveled so far. Between June 2015 and November 2017, the California Department of Motor Vehicles estimated that GM Cruise’s self-driving cars covered a total of 141,691 miles in CA. Morgan Stanley analyst Adam Jonas estimates Waymo to be worth $175 billion. GM Cruise, on the other hand, is valued at $11.5 billion after securing more funding from Softbank’s Vision Fund earlier this year.Tesla’s development of self-driving technologies has taken a backseat in the media coverage of the company, particularly during the past year as the company struggled with the Model 3 ramp. Regardless of this, Keith Wright, a professor from Villanova University, notes that Elon Musk’s decision to invest heavily in AI would likely pay off soon. Among the participants in the self-driving race, Tesla is the company with the most real-world experience. Elon Musk once noted that it would likely take around 6 billion real-world miles before regulators would approve self-driving technology. So far, Tesla is the company closest to that mark.Tesla’s focus on data gathered from real-world miles was emphasized by Nidhi Kalra, a senior information scientist for the RAND Corporation, a nonprofit research organization. According to the information scientist, simulations such as the ones used by Waymo to train its fleet of autonomous vehicles are a “simplification” of the real world.“The problem with any simulator is that it’s a simplification of the real world. Even if it stimulates the world accurately, if all you’re simulating is a sunny day in Mountain View with no traffic, then what is the value of doing a billion miles on the same cul-de-sac in Mountain View? I’m not saying that’s what anyone’s doing but without that information we can’t know what a billion miles really means. Real-world miles still really, really matter. That’s where, literally, the rubber meets the road, and there’s no substitute for it,” Kalra said.And Tesla is just getting started. In Tesla’s Q2 2018 earnings call, the company provided an update on its efforts to develop its own self-driving hardware. According to Pete Bannon, who leads the development of Hardware 3, the company’s new hardware is different from the industry standard.“We did a survey of all of the solutions that were out there for running neural networks, including GPUs. We went and talked to other people like at ARM that were building embedded solutions for running neural networks. And pretty much everywhere we looked, if somebody had a hammer, whether it was a CPU or a GPU or whatever, they were adding something to accelerate neural networks. But nobody was doing a bottoms-up design from scratch, which is what we elected to do.”“We had the benefit of having the insight into seeing what Tesla’s neural networks looked like back then and having projections of what they would look like into the future, and we were able to leverage all of that knowledge and our willingness to totally commit to that style of computing to produce a design that’s dramatically more efficient and has dramatically more performance than what you can buy today.”Tesla could very well be approaching its most significant turning point in years. Regardless of whether Tesla becomes private or not, one thing seems sure — once Tesla starts rolling out its first full self-driving features, and once Hardware 3 makes it to the company’s fleet, leaders in the self-driving industry would probably be forced to recognize the presence of a new, possibly dominant player.Disclosure: I have no ownership in shares of TSLA and have no plans to initiate any positions within 72 hours.Questions: Since Tesla has not yet released any $35k M3s were not the cars that Munro and the group...dzcJohnAre you sure you have your info correct? I don't think Toyota has ever sold 1M Prius in ...I am buying my first car a moment from now. And would love to have a Tesla as my first car but can&#...Tesla news, rumors and reviews on all things Tesla. Connecting owners and enthusiasts via @TeslaratiApp available on iOS and AndroidCopyright © TESLARATI. All rights reserved."
https://electrek.co/2018/08/07/tesla-autopilots-crash-avoidance-fewer-claims-iihs/,"AUGUST 7Fred Lambert- Aug. 7th 2018 8:56 am ET@FredericLambertTesla has long claimed that the use of its Autopilot and its active safety features resulted in fewer crashes and ultimately, should reduce insurance rates.Now Tesla gets some backing from the Insurance Institute for Highway Safety (IIHS) saying that Tesla Autopilot’s crash avoidance features result in ‘fewer physical damage, injury liability claims’.But they also found that the introduction of the features is linked to an increase in other kinds of claims.The IIHS studied the claims made on all Model S vehicles between 2012–14, which is before Tesla introduced Autopilot and all the active safety features it enables like forward collision warning, automatic emergency braking and blind spot warning, and compared them to the claims on 2014–16 Model S vehicles.Therefore, it would cover only the first generation of Autopilot since Tesla introduced Autopilot 2.0 in 2016.Furthermore, it’s important to note that Tesla gradually released and improved on the active safety features enabled by Autopilot between 2014 and 2016 and not all the features were available during the whole period.After analyzing the claims during those times, the group found significant reductions in property damage claims and injury claims:“The combined driver assistance features on the 2014–16 Model S lowered the frequency of claims filed under property damage liability (PDL) coverage by 11 percent and the frequency of claims under bodily injury (BI) liability coverage by 21 percent, compared with the 2012–14 Model S without the technology, HLDI found.”That said, IIHS didn’t find any “significant effect on the frequency of collision claims.”But they found increases in MedPay and PIP claims, which IIHS describes:“MedPay covers injuries to an at-fault driver or passengers in that driver’s vehicle, while PIP coverage is sold in states with no-fault insurance systems. This coverage pays for injuries to occupants of the insured vehicle, no matter who is at fault.”Here are the changes in each category:Matt Moore, HLDI’s senior vice president, admits that they would need more data to really understand the effect:“To get a better picture of how Autopilot is affecting claims, we need more data on how many Teslas are equipped with Autopilot and how often it is used. The reductions in the frequency of third-party physical damage and injury liability claims associated with Tesla’s version 1 hardware are in line with the benefits HLDI has documented for comparable systems from other manufacturers.”Tesla promoted the fact its crash rate was reduced by 40% after the introduction of Autopilot, according to a report from NHTSA based on data that the automaker supplied.Earlier this year, CEO Elon Musk claimed that Tesla would start releasing a quarterly Autopilot safety report, but we have yet to see the first report over a quarter later.The information would be important for general awareness about the Autopilot and its safety features, but it would also be good for Tesla owners’ insurance rates.Musk has claimed before that Autopilot should result in lower insurance rates, but it hasn’t been the case so far.Tesla started building up its in-house insurance effort as the Model S topped the list of most expensive cars to insure.Tesla is a transportation and energy company. It sells vehicles under its 'Tesla Motors' division and stationary battery pack for home, commercial and utility-scale projects under its 'Tesla Energy' division.@FredericLambertFred is the Editor in Chief and Main Writer at Electrek.You can send tips on Twitter (DMs open) or via email: fred@9to5mac.comIf you want to help Fred and Electrek, you can contribute to our Patreon: https://www.patreon.com/electrekElectrek Podcast: Tesla craziness intensifies, base Mod...Tesla could make a $25,000 electric car in ‘about..."
https://driving.ca/tesla/features/feature-story/watch-this-tesla-model-3-avoid-crash-using-autopilot,"Tesla’s Autopilot feature has endured much scrutiny after a handful of unfortunate accidents over the past year, including one fatal, but this video posted to YouTube on Friday shows that the semi-autonomous vehicle is a life saver when functioning properly.YouTube user TeslaExposed posted this video of his Model 3 with Autopilot activated avoiding a collision after an SUV sped up and cut into the lane in front of the vehicle. The Model 3 alerts the driver of the danger and quickly slides into the spare lane on the right, emerging unscathed.“We strongly believe Autopilot saved us from the collision with audible warning to get our attention, braking, and steering slightly to the right saved us from a collision and possible pileup at that speed,” TeslaExposed wrote in the video description on YouTube.Watch the video below to see Tesla’s autopilot in action.365 Bloor St East, Toronto, ON, M4W3L4, www.postmedia.com© 2018 Postmedia Network Inc. All rights reserved.Unauthorized distrbution, transmission or republication strictly prohibited."
https://www.flightglobal.com/news/articles/fatigued-cj4-pilot-likely-failed-to-engage-autopilot-450691/,"Our website uses cookies, which are small text files that are widely used in order to make websites work more effectively. To continue using our website and consent to the use of cookies, click away from this box or click 'Close'US investigators believe a fatigued Cessna CJ4 pilot failed to engage the autopilot after taking off in darkness from Cleveland, before the light business jet fatally dived into Lake Erie.The Maverick Air aircraft had departed runway 24R at Burke Lakefront airport, on a return flight to Columbus's Ohio State University, but commenced a rapid climb and overshot its cleared altitude of 2,000ft.It had been instructed to turn right after take-off but it banked excessively, reaching 62°. The aircraft passed through its assigned heading and entered a 15° nose-down attitude.While the bank subsequently reduced to 25° the aircraft descended at 300kt (556km/h), at a rate of 6,000ft/min (30m/s), disintegrating as it struck the water. None of the six occupants survived.Textron AviationThe National Transportation Safety Board points out that the pilot had been awake for nearly 17h and that he was ""likely fatigued"" before the late-night departure on 29 December 2016.He had probably attempted to engage the autopilot after take-off, as trained, but failed to confirm with an instrument scan. ""Based on the flight profile, the autopilot was not engaged,"" the inquiry says. ""A belief that the autopilot was engaged may have contributed to [the pilot’s] lack of attention.""The pilot had previously flown the Cessna 510 Citation Mustang. Not only is the Mustang’s autopilot button located slightly differently to the CJ4's, it crucially has a completely different type of attitude display – one which uses a fixed horizon, rather than the moving horizon on the CJ4.Investigators point out that the combination of a large featureless lake, in darkness and instrument weather conditions, would have been spatially disorientating. Once this disorientation set in, says the inquiry, the differences in the cockpit instruments compared with the Mustang ""may have hindered"" the pilot’s ability to make proper corrective control inputs.The pilot twice tried to reply briefly to transmissions from the tower controller but neither was received, and the inquiry suggests the pilot did not have the microphone push-to-talk button pressed.Several cues about the developing loss of control had been issued by the aircraft, including alerts that the CJ4 had passed its cleared altitude, while the enhanced ground proximity warning system sounded ""bank angle"" and ""sink rate"" warnings before ordering ""pull up"" seven times as the aircraft dived.Investigators determined that the aircraft (N614SB) was airborne for only 70s. Examination of the wreckage did not indicate any evidence of failure or malfunction before impact.  "
https://interestingengineering.com/dashcam-video-shows-tesla-model-3-on-autopilot-swiftly-avoid-an-accident,"A new video posted to YouTube shows reveals yet another example of the semi-autonomous system improving safety.Tesla's controversial semi-autonomous (aka Autopilot) mode has been making headlines for the last year and not for good reasons. From fatal crashes to almost comical run-ins with parked cars, it seems the feature has had a run of bad luck.Now, a new dashcam video posted on YouTube has offered another very visual very real example of the security benefits of Autopilot. The footage posted by a user called TeslaExposed shows a Tesla Model 3 swiftly avoiding a crash.""Close call while cruising on the highway along with traffic when an idiot who was speeding and cutting everyone off almost sideswiped us with kid inside. Autopilot was engaged and started to brake and moved us to the right lane to avoid a collision,"" explained the YouTuber in the video's description.He then explained that he presumed the system had detected that there were no vehicles on the right of the car and safely steered it out of harm's way. ""Be safe out there and always be alert even with Autopilot engaged and watch out for idiot drivers,"" he further added.The video brought up an important point often made by Tesla. The Autopilot mode is not a substitute for remaining alert on the road at all times.Tesla CEO Elon Musk has consistently defended his system by quoting road accident statistics and comparing possible outcomes of similar events without the help of Autopilot. He has also called out the media for their supposedly unfair coverage of Tesla-related accidents.Tesla has also commonly published blog posts acknowledging any reported accidents but always attempting to explain the many ways Autopilot helps avoid accidents. ""No one knows about the accidents that didn’t happen, only the ones that did,"" said Tesla's March 2018 post.""There are about 1.25 million automotive deaths worldwide. If the current safety level of a Tesla vehicle were to be applied, it would mean about 900,000 lives saved per year,"" continued the statement, insisting that Autopilot improves safety.Such remarks have always been met with resistance, with many stating the company is being insensitive to the victims of these accidents. However, Tesla has always affirmed they are simply trying to prevent more tragic events.Luckily there has been some good news to support Tesla's continued trust in Autopilot. Just last month, music producer Zedd took to Twitter to share how the system saved his life.While Zedd's testimonial might be the most high-profile support of the Autopilot's success, Tesla has made it clear they're far from finished with their popular self-driving technology.Via: TeslaExposed/ YouTube"
https://www.consumerreports.org/cars-driving/talking-cars-163-toyota-corolla-hatchback-and-convenience-vs-safety/,"Main theme: We dig into a new independent study that examines the difference between convenience features and safety features, we talk about convertibles, and we encourage couples to shop for cars together if they want to stay together.Driven this week: 2019 Toyota Corolla HatchbackAudience questions:• How do CR employees buy cars without getting recognized by dealers?• Why does the 2016 Lincoln MKX get worse reliability ratings than the similar Ford Edge?• Should I buy a fully loaded Honda Accord, Nissan Maxima, or Toyota Camry?• Are convertible tops a reliability nightmare?As with other “Talking Cars” episodes, this one is available free through Apple Podcasts. (Subscribe to the audio or video.) You’ll also find the audio on Spotify and video on YouTube.• Ram 1500, Classis Cars in Cuba, episode 162 • Subaru Ascent, Mistakes With Personal Cars, episode 161 • Lexus LS, Tax Credits, Shifters, episode 160 • Nissan Kicks, Hot Car Danger, episode 159 • Special All-Question Episode, episode 158We’d love to include it in a future show. Click here to upload your video questions to our Dropbox folder. Please send high-definition (1920x1080) MP4 video files with high-quality audio. Or send an iMessage question to our TalkingCars@icloud.com account.Keith BarryDespite my love for quirky, old European sedans like the Renault Medallion, it's my passion to help others find a safe, reliable car that still puts a smile on their face—even if they're stuck in traffic. When I'm not behind the wheel or the keyboard, you can find me exploring a new city on foot or planning my next trip."
https://mobilesyrup.com/2018/08/10/tesla-free-trial-autopilot/,"AUG 10, 20181:31 PM EDT0 COMMENTSTesla has started emailing owners of cars that support Autopilot 2.0 to offer them a free 14 day trial for the driver assistance platform.The company has mentioned a few times that it is getting ready to release a substantial update to Autopilot. This free trial could be foreshadowing the imminent release of that update.Autopilot 2.0 is the hardware that’s been built into all Teslas since October 2016. It consists of eight cameras and 12 ultrasonic sensors, as well as Nvidia’s Drive PX 2 GPU.This isn’t the first time that the company has pushed a free trial to its users. In 2016, Tesla offered users a free Autopilot trial as well.The new and old trials give users a chance to test out the Enhanced Autopilot system if they didn’t cough up an extra $6,600 CAD at the time of purchase.Tesla CEO Elon Musk announced that this update was going to happen in June and according to Electrek, users are starting to get notified.Based off of a few of Musk’s tweets, there’s been heavy speculation that the ninth version of Tesla software is arriving at the end of August. Software version nine is going to start enabling full self-driving features, according to a tweet from Musk on June 10th.This free trial could help get a few more people comfortable with semi-self-driving features like lane assistance before the full autonomous-driving update starts rolling out.Source: ElectrekFacebookTwitterGoogle+LinkedinRedditFeatured ArticlesSign-up for MobileSyrup news sent straight to your inboxRelated ArticlesAUG 17, 20182:15 PM EDTAUG 16, 20184:13 PM EDTMAR 20, 201812:41 PM EDTJUL 25, 20186:29 PM EDTCommentsCategoriesContact usSocialNewsletter Signup© 2018 MOBILESYRUP.COMPRIVACY. TERMS OF USE."
https://www.ainonline.com/aviation-news/general-aviation/2018-07-23/genesys-autopilot-gets-approval-piper-pa-32,"The S-Tec 3100 two-axis digital autopilot by Genesys has received STC approval for the Piper PA-32. It is also available on select Cessna and Beechcraft aircraft and provides automatic trim, envelope protection and alerting, one-button straight-and-level recovery, and other features. The company expects further 3100 STC approval on additional Cessna, Beechcraft, and Piper models in the coming months.“We are excited to expand the S-Tec 3100 STC approval to include the Piper PA-32. PA-32 owners have an upgrade path that can reuse those existing S-Tec servos—many came from the factory with our 55X—or the option of a new installation if our servos aren’t present,” said Jamie Luster, director of Genesys sales and marketing. Pricing for customers with an existing S-Tec system is listed at $9,995, while the full kit costs $19,995. “Our development hangar is full of airframes going through various stages of the STC process for the 3100. We plan to be earning a new STC every few weeks at our current pace,” said Luster.Genesys has also announced a partnership with Gary Reeves, Master CFI and owner of PilotSafety.org, to provide training materials for S-Tec autopilots. “In 14 years of teaching single-pilot IFR, I’ve always found S-Tec to be the most reliable and easiest to use,"" said Reeves. ""I’m proud to partner with Genesys and provide video training for the best autopilots available. I chose the Genesys S-Tec 3100 for my airplane because it has the most features, it’s the easiest to use, and it has 40 years of proven experience behind it.”Copyright ©2018 The Convention News Company, Inc. All Rights Reserved. | Terms of Use | Privacy PolicyThis website, or its third party tools, use cookies to enhance your browsing experience. By using this site you agree to this use of cookies."
https://www.cartoq.com/indias-first-tesla-model-x-100d-electric-suv-with-autopilot-is-here/,"Another Tesla Model X electric SUV has landed in India, and this time around, it’s the 100D variant. The Tesla Model X that was previously imported into India through the private route and registered to billionaire Prashant Ruia was the top of the line P 90D variant. The 100D variant, which while being very quick, is still a few steps behind the P 90D in terms of outright performance. The electric SUV, imported straight from the United States, which is currently the only country that manufactures Tesla cars and SUVs, can hit 100 Kph in a sportscar-challenging 5 seconds. In fact, this kind of performance makes the Tesla 100D virtually faster than almost all other luxury SUVs sold in India.And it has no engine. That’s because like all Tesla cars, the Model X 100D is powered by electric motors driven by lithium ion batteries. The electric SUV weighs a hefty 2.5 tons thanks to all the batteries that drive the twin electric motors, one on the front axle and the other on the rear axle.Needless to say, the Model X 100D features an all wheel drive layout. Top speed is rated at 250 Kph while the range per charge stands at 475 kilometers, which is very good indeed. What this effectively means is that the Model X can be used on a day to day basis even in a country like India where electric car charging infrastructure is at its infancy.In the United States, the Tesla Model X 100D is priced at $ 96,000, which translates to about Rs. 65 lakhs in Indian currency. However, importing such a car through the private import route costs significantly higher thanks to the hefty import duties involved.Effectively, we’re looking at a price of about Rs. 1.5 crores for this car when imported privately into India. The Tesla Model X 100D is said to be bought by someone in Mumbai, and will soon be sporting MH plates, which means that it will be registered as a private car in India. Stay tuned for more pictures of this car on Indian streets.Via AutomobiliArdentC/O Mindworks Global Media Services Pvt. Ltd. 3rd Floor, Plot 1, BGR Energy Building, Sector 16A, Film City, Noida 201301 editor@cartoq.com sales@cartoq.com© 2018 CarToq – India’s #1 auto content site | All rights reserved | Copyright Policy | Terms of Use | Privacy Policy"
https://www.cnbc.com/2018/08/16/nvidia-ceo-is-more-than-happy-to-help-if-tesla-ai-chip-plan-fails.html,"Nvidia CEO Jensen Huang said his company has chips that are ready for autonomous driving, responding to a potential threat posed by Tesla's eventual entrance into the market.During a conference call on Thursday following Nvidia's fiscal second-quarter earnings report, Huang was asked by an analyst to discuss Tesla's desire to stop relying on Nvidia's silicon in favor of its own customer artificial intelligence chip. Tesla CEO Elon Musk said earlier this month that he was ""a big fan of Nvidia"" but suggested that Tesla's chip would be able to outperform certain Nvidia graphics cards.The two companies, which have very different specialties, could be on a collision course as AI plays a bigger role in the future of autonomous driving.Huang said that Nvidia's Xavier technology for autonomous machines is in production and customers are ""super excited"" about it. If Tesla's own Autopilot chip initiative doesn't work out, Nvidia would be ""more than happy to help,"" he said.Here's the entirety of Huang's comments on its collaboration with Tesla and the electric car maker's chip project:With respect to the next generation, it is the case that when we first started working on autonomous vehicles, they needed our help. And we used the 3-year-old Pascal GPU for the current generation of Autopilot computers.  And it is very clear now that in order to have a safe Autopilot system, we need a lot more computing horsepower. In order to have safe computing, in order to have safe driving, the algorithms have to be rich. It has to be able to handle corner conditions in a lot of diverse situations.  And every time that there's more and more corner conditions or more subtle things that you have to do or you have to drive more smoothly or be able to take turns more quickly, all of those requirements require greater computing capability. And that's exactly the reason why we built Xavier. Xavier is in production now. We're seeing great success and customers are super excited about Xavier.And that's exactly the reason why we built it. And I think it's super hard to build Xavier and all the software stack on top of it. And if it doesn't turn out for whatever reason it doesn't turn out for them you can give me a call and I'd be more than happy to help.Tesla did not immediately respond to a request for comment, but Musk did talk about Nvidia in a tweet after the earnings call:Got a confidential news tip? We want to hear from you.Sign up for free newsletters and get more CNBC delivered to your inboxGet this delivered to your inbox, and more info about our products and services. Privacy Policy.© 2018 CNBC LLC. All Rights Reserved. A Division of NBCUniversalData is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.Data also provided by"
https://www.irishexaminer.com/examviral/people-are-sharing-the-dumbest-things-theyve-done-while-on-autopilot-861436.html,"Whether it’s leaving keys in the fridge, throwing food away by accident or going to the wrong destination, we’ve all done silly things when we weren’t concentrating.Reddit users have been sharing the silliest things they’ve done while on autopilot, thanks to a question from twieyes.These may make you feel a little less stupid next time you do something absentmindedly.This lot need to pay more attention while driving.A case of mistaken identityBeing absentminded is particularly upsetting when it involves wasting foodToto, we’re not at work anymoreBut this guy wins… if winning is a thing- Press AssociationReceive our lunchtime briefing straight to your inboxRELATED ARTICLESHere are the common things people would ‘un-invent’ if they had the chanceCheetahs at Oregon Zoo show off their speed chasing balls thrown from a catapultYou won’t believe how big this spider found in Dublin isA refugee with a masters in rocket science is using a novel way to find a jobMORE IN THIS SECTIONWant to improve your memory? This illustrated video will helpTerminally ill dog ticks ‘riding in a police car’ off bucket listWoman has contact lens removed from her eye after 28 yearsRose of Tralee contestant hoping lambing season experience will help her cope with festivalMORE FROM THE IRISH EXAMINERfor your new job© Irish Examiner Ltd, Linn Dubh, Assumption Road, Blackpool, Cork. Registered in Ireland: 523712."
https://autobible.euro.cz/dalsi-fatalni-nehoda-tesly-usa-ukazuje-ze-autopilot-opravdu-nefunguje/,"Počet vážných nebo dokonce smrtelných nehod automobilů Tesla, jejichž posádka používá podpůrný systém řízení nazývaný trochu nešťastně „Autopilot“, narůstá. Nedávno se stala jedna velmi vážná nehoda Tesly Model X v Kalifornii, kdy elektrické SUV řízené Autopilotem v rychlosti 71 mil za hodinu (114 km/h) narazilo do betonové zábrany rozdělující dva dálniční pruhy, aniž by projevilo snahu brzdit. Řidič vůbec do řízení nezasáhl.Nehodu popisuje například organizace IIHS, podle které řidič téměř 19 minut před nehodou nechal řídit systém částečně samočinného řízení a několikrát nereagoval na výzvu řízení převzít. Systém vyslal dvě obrazová a jedno akustické varování a výzvy pro převzetí řízení. V posledních šesti sekundách před nehodou vůbec neměl řidič ruce na volantu, takže je otázka, co vlastně dělal.Ukázalo se, že Tesla následovala jiné auto po dálnici v druhém pruhu zleva rychlostí asi 105 km/h osm sekund před nárazem. Adaptivní systém byl nastaven na rychlost 75 mil v zóně s omezením na 65 mil za hodinu. Sedm sekund před nehodou začala Tesla zatáčet doleva na pás rozdělující hlavní pruh a sjezd z dálnice. Čtyři sekundy před nárazem už Tesla nenásledovala auto vpředu. Tři sekundy před nárazem začala Tesla akcelerovat z 62 na 71 mil za hodinu a pak narazila čelně do betonové zídky rozdělující hlavní jízdní pruh a sjezd z dálnice. Vůz začal hořet a řidič utrpěl zranění neslučitelná se životem.Celý průběh nehody, respektive co jí přecházelo, popisuje ve své zprávě organizace NTSB, která se zabývá vyšetřováním nehod v dopravě. Zajímavé je, že NTSB důkladně vyšetřuje především nehody prostředků hromadné dopravy, nikoli bouračky osobních aut. Ohledně podpůrných systémů řízení ale platí výjimka.Následující video ukazuje, že na podobné situace je „autopilot“ Tesly nesmírně citlivý. Jen připomeneme, že automobilka byla nucena po několika nehodách upravit systém tak, aby vyzýval řidiče k držení volantu. Přesto se někteří nebojí používat pomůcky, které elektronický mozek auto obejdou.Když ku*va někdo nechce řídit, tak ať si najme řidiče, vezme taxi/bus/vlak atd. a nedělá takovéto pi*oviny. Naštěstí si to odnes on sám, ale příště už to tak být nemusí…Co to je ku*va za dementní nadpisek?Souhlasím.Ten nadpis je clickbait, nic jiného. Odráží kvalitu tohoto webu, nikoliv skutečný obsah článku. Je ve skutečnosti lživý.Souhlasím.Další nesmyslný clickbait poškozující jméno Tesly. Systém který Tesla nazývá autopilotem, je jasně definován a v rámci studia příručky se dozvíte, že to není “naprosto” autonomní vozidlo, za vozidlo má stále zodpovědnost řidič a pokud ho systém autopilot vyzve k převzetí řízení, má to udělat. Autor by se měl zamyslet nad tím, co píše předtím, než publikuje nějakou blbost. Bohužel se tak opět potvrdila nekompetentnost tohoto webu sdílet nezkreslené informace.Souhlasím a už sem nikdy nepřijdu! Radobynovináři. BleeeéPřesně takJedná se o několik měsíců starou zprávu. To tam nemáte nic lepšího, než vytahovat kostlivce ze skříně. Používat autopilot v dnešní době je spíše nesmysl. I přesto, že jsou určitě úseky, kde funguje, tak současná infrastruktura a přístup lidí – řidičů je aktuálně nedostačující.AHA TAKŽE DVĚ AUTONEHODY TESLY = NEFUNGUJÍ TAKŽE KDYŽ SPADNE LETADLO = NEFUNGUJÍŘekl bych, že co tu nefunguje na tomto webu, je žurnalistika.CELÝ WEB SI PŘIDÁVÁM DO ADBLOCKUZa ten manipulativní nadpis Ti Dalibore žáku vzkazuju: tento web se ocitá na seznamu blick site.* Beru na vědomí zpracování osobních údajůJménoPříjmeníE-mailová adresa *Souhlas Beru na vědomí zásady zpracování osobních údajůCopyright 2018 Mladá fronta a. s."
https://www.greencarreports.com/news/1118185_taking-tesla-private-autopilot-testing-mazda-cx-5-diesel-nissan-leaf-batteries-the-week-in-reverse,"Tesla Model S Autopilot testing with IIHS [CREDIT: IIHS]Which company got a new diesel approved for U.S. sale?What new feature did the IIHS test?This is our look back at the Week In Reverse—right here at Green Car Reports—for the week ending Aug. 10, 2018.Friday, we reported on the IIHS tests of self-driving systems, including two versions of Autopilot in two different Teslas. It found none of the systems are capable of driving safely on their own.We also covered the best state and other tax incentives for plug-in cars beyond the $7,500 federal tax credit.2017 Mazda CX-5 Grand TouringThursday, we also learned that California has issued a decree that it will stop following federal emissions and fuel economy standards if the EPA follows through with freezing the federal standards.We also learned that Mazda's CX-5 diesel has been approved by federal regulators and has received its official EPA fuel-economy ratings. Mazda hasn't said when it will put the car on sale.Sono Sion solar charged electric carWednesday, Tesla's board of directors and the SEC reacted to news that CEO Elon Musk is planning to take the company private. We also learned that the Sono Sion solar car began testing in Germany.Tesla Motors CEO Elon Musk at Tesla Store opening in Westfield Mall, London, Oct 2013Tuesday, Tesla CEO Elon Musk dropped the bombshell on Twitter that he hopes to take the automaker private and had lined up investors. We came up with a list of the seven best plug-in cars for students to take back to school.2017 Nissan Leaf showing battery pack (Source: Nissan)Monday, we checked in on Tesla's court battle for the right to sell cars in Michigan, and why it may open up the company's access to sell cars nationwide.Nissan announced that it sold its long-time in-house battery division and will purchase batteries for its future electric cars from supplier LG Chem."
https://www.caradvice.com.au/668814/teslas-autopilot-driven-1-9b-kilometres/,"New research estimates autonomous miles based on previous data releases.Tesla customers have driven over 1.2 billion miles (1.9b kilometre) with the company's semi-autonomous Autopilot systems engaged, a new report says.First covered by Electrek, a team from MIT Human-Centered AI has produced (and is still updating a report) estimating the distance covered by Tesla vehicles operating with Autopilot turned on.The report currently estimates that some 1.9 billion kilometres have been covered with the system engaged – more distance has been driven with the system in 'Shadow Mode', where Autopilot runs in the background without having any input on driving.For both measurements, the MIT team has plotted the figures based on the handful of instances where Tesla has officially released its self-driving data.The news comes after Tesla CEO, Elon Musk, tweeted 'full self-driving features' will be rolled out across the company's Autopilot-equipped models from August as part of its 'V9' software update, though he neglected to mention exactly what functions will be available.""To date, Autopilot resources have rightly focused entirely on safety,"" Musk tweeted. ""With V9, we will begin to enable full self-driving features.""While Tesla has covered nearly 2 billion kilometres with its semi-autonomous driver assistance systems, it's worth noting that its vehicles are currently limited to Level 2 driverless standards, which refers to features such as basic lane-keeping autonomous steering in combination with active cruise control.There's been a few incidents involving Autopilot recently, too, some fatal. One Model X owner was killed when his car smashed into a barrier in Mountain View, California, while another suffered a broken ankle when her Model S slammed into a stationary firetruck at around 100km/h.In the UK, a driver lost his license for 18 months after being filmed sitting in the passenger seat at around 65km/h, letting Autopilot do the driving.MORE: Tesla Autopilot coverageMORE: Everything TeslaUnless otherwise stated, all prices are shown as Manufacturer's Recommended List Price (MRLP) inclusive of GST, exclusive of options and on road costs.1534540104 - 1.0.91"
https://www.ainonline.com/aviation-news/general-aviation/2018-07-27/garmin-autopilots-approved-more-aircraft,"Garmin’s GFC 500 and 600 autopilots will soon add new installation approvals, bringing the STCs for the system to 10 popular airplane models. The latest to be added will be the Beechcraft Bonanza/Debonair (C33, E33, F33, G33), Cessna 210, and Grumman AA-5 series for the GFC 500, and the Beechcraft Baron (58P, 58TC) and Cessna 208B Caravan for the GFC 600.The GFC 500 and 600 can be installed as a standalone autopilot or integrated with Garmin G500/G600 TXi and G500/G600 displays and Garmin navigators, as well as other third-party displays, instruments, and navigation sources.Key features of the GFC autopilots include Garmin’s Electronic Stability and Protection, underspeed and overspeed protection, level mode, and flight director. These are added to “traditional autopilot capabilities,” according to Garmin, “such as altitude hold, vertical speed, and heading modes, as well as the capability to fly fully coupled GPS, ILS, VOR, LOC, and back-course approaches.” The autopilots can also fly indicated airspeed climbs/descents, and offer control wheel steering and built-in roll steering.Garmin has also added new features to the GFC 500 and 600, including a Vnav softkey for flying fully coupled Vnav profiles, although the autopilot must be paired to the GTN 650/750 navigators and the G5, G500/G600 TXi, or G500/G600 displays. Pilots can set altitude constraints for a vertical descent profile and use automatically populated step-down altitudes.The GFC 500 starts at $6,995 for a two-axis system and the GFC 600 $19,995 (with electric trim).Copyright ©2018 The Convention News Company, Inc. All Rights Reserved. | Terms of Use | Privacy PolicyThis website, or its third party tools, use cookies to enhance your browsing experience. By using this site you agree to this use of cookies."
https://www.thestar.com/news/canada/2018/08/02/fishing-boat-involved-in-deadly-june-accident-was-on-autopilot-investigators-say.html,"BEACH POINT, P.E.I.— A fishing boat that rammed into another vessel — landing on top of its deck and killing two people — was on autopilot, according to the Transportation Safety Board.The board says both the Forever Chasin’ Tail and the Joel ‘98 left Beach Point, P.E.I., to haul lobster traps on June 9.Weather conditions were good at the time with low winds, clear skies and unlimited visibility, the board’s report said.The three crew aboard Forever Chasin’ Tail set their traps and headed home. The master “set the automatic pilot to steer a westerly course toward the entrance to Beach Point harbour,” the report said.Directly in their path: The five-person crew on the Joel ‘98, who continued to haul and reset lobster traps.Read more:Nova Scotia man not wearing lifejacket found dead in water next to boatPolice dive team locates body of Toronto man from Halifax lakeHMCS St. John’s, Sea King helicopter return to Halifax port after Baltic Sea missionThe report said the Joel ‘98 crew had just recovered the marker buoy on their next set of lobster traps and were focused on the starboard side when crew saw the Forever Chasin’ Tail heading directly toward their port side.“At about the same time, the crew on board the Forever Chasin’ Tail saw the Joel ‘98 directly in front of them. With no time for either vessel to manoeuvre, the Forever Chasin’ Tail collided with the Joel ‘98,” the report states.The Forever Chasin’ Tail came to rest on the deck of the Joel ‘98. As the stern began to sink, two crew members and one passenger climbed onto the other vessel.“The remaining crew member and passenger from the Joel ‘98 were found floating at the surface on the port side of the Forever Chasin’ Tail as it floated free of the sinking vessel,” it said.The crew member was pulled on board the Forever Chasin’ Tail, while the passenger was taken on board another fishing vessel. Both were taken to Beach Point, where they were pronounced dead by first responders.Previous media reports had identified the victims as Justin MacKay, 20, and 59-year-old Chris Melanson.The board said the Joel ‘98 remained partly submerged for several hours and later sank while under tow by another fishing vessel.Prime Minister Justin Trudeau expressed his condolences on social media by saying the 80-year-old Annan made the world a better place.Thousands attended the Saturday service for constables Robb Costello and Sara Burns who were killed last week in a north-side shooting. Civilians also lined a procession route and watched as first responders marched past in memoriam.The country, already known for its vast copper deposits, is joining a search for high-demand ore after authorities discovered more than seven-million tons was mined by Germans between 1844 and 1941.With seven months until Britain officially leaves the bloc, the former UKIP leader announced Saturday that he was returning to political campaigning to derail Prime Minister Theresa May’s plan for future ties with the EU.Police say a woman in her 30s was standing near her car when she was approached by a man who demanded she give him her keys. The man then allegedly took her keys and drove off in her vehicle, a grey 2014 Toyota Camry.The Russian president’s remark, made before a bilateral meeting with the German chancellor, hinted at tension between the two leaders as they increasingly turn into reluctant allies.Several Pennsylvania priests accused of sex abuse sent to GTA facility for treatment for “sexual disorders”Crazy Rich Asians is being hailed as a chance for Asians to determine their own narrative in Hollywood. But the takeaway is that Asians are rich, crass and they’ll likely drive up your property values, writes Tony Wong.Beijing, which claims sovereignty over the island nation and overwhelms them militarily, has not discounted using force to unify the two despite being separately ruled since the 1940s.The former Trump campaign chairman is still facing allegations of conspiring to defraud the U.S., money laundering and more in the District of Columbia as a current financial fraud trial against him enters its third day of deliberations.Police located and arrested two suspects a short distance away from where the stabbing took place."
https://sputniknews.com/asia/201807301066790112-malaysia-mh370-investigation-report/,"Our website uses cookies to improve its performance and enhance your user experience. Through cookies, certain personal data is collected and may be stored temporarily. You can change your cookie settings through your browser. More info: Privacy PolicyBANGKOK (Sputnik) - The unplanned change in the course of the Malaysian Airlines' MH370 flight Kuala Lumpur-Beijing, which disappeared in 2014 over the Indian Ocean, was conducted in manual mode, with the autopilot turned off, the official report of the commission investigating the aircraft's disappearance said.The report was presented in Kuala Lumpur by the investigator-in-charge of the Malaysian Safety Investigation Team for MH370, Kok Soo Chon.""We can conclude that MH370 had turned back and the turn back was not because of anomalies in the mechanical system. The turn back was made not under autopilot but under manual control. Everyone participating in the investigation agreed that the autopilot was off at the time of the turn,"" he said during the presentation.The investigation team found several violations of the safety protocols, including a 20-minute delay in the first attempt to establish communication with the plane by the flight operation officers of Ho Chi Minh City airport, that delayed the discovery of the fact that the aircraft changed course, Kok Soo Chon said.Nevertheless, disruptions and further loss of communication might have been caused by the manual disconnection of communication systems in the pilot's cockpit, he added.READ MORE: Malaysia May Consider Resuming Searches for Missing Flight MH370 — ReportsThe commission has not yet determined the reasons of the aircraft's disappearance, and the location of the main part of the wreckage remains unknown, the head of the commission said.Flight MH370, en route from Kuala Lumpur to Beijing, disappeared from radars on March 8, 2014, less than an hour after takeoff. There were 227 passengers and 12 crew members on board the aircraft.So far, several pieces of debris believed to have come from the aircraft have been found at different locations, including Mozambique, South Africa and the French island of Reunion in the Indian Ocean.Get push notifications from Sputnik International"
https://timesofindia.indiatimes.com/india/indian-foreign-policy-should-not-be-on-autopilot-says-jaishankar/articleshow/65283135.cms,"Your Healthy WeekDaily NewsDaily NewsCopyright © 2018 Bennett, Coleman & Co. Ltd. All rights reserved. For reprint rights: Times Syndication Service"
http://positivesource24.com/2018/08/16/global-commercial-aircraft-autopilot-system-market-growth-analysis-2018-2023-avidyne/,"The research report Global Commercial Aircraft Autopilot System Market Analysis 2018 offers an estimation of the overall market size from 2013 to 2023 in terms of value (US$) and in volume (kilo tons). The commercial aircraft autopilot system research report also presents a thorough assessment of the market key segments and it’s relative market share, latest trends, and technologies used in commercial aircraft autopilot system industry, an instructive overview on vendor landscape and geographical augmentation of the market. The research study examines the commercial aircraft autopilot system market with aid of a number of criteria, such as the product type, application, and its geographical expansion. The market shares contributed by these segments are formulated to give an opportunistic roadmap to the readers of the commercial aircraft autopilot system market.Report Introduction: The report is crucial research document for its targeted audiences such as manufacturers of commercial aircraft autopilot system, raw material suppliers and buyers, industry experts and other business authorities. Firstly, the report speaks about the commercial aircraft autopilot system market overview that assists with definition, classification and statistical details of the market that reveals the commercial aircraft autopilot system market current status and future forecast. In the next consecutive part, the report describes the drivers and restraints affecting the market alongside various commercial aircraft autopilot system market trends that are shaping the market’s supply and distribution chains. The commercial aircraft autopilot system report also delves into the market dynamics that covers emerging countries and growing markets, although new openings and challenges for emerging market players, commercial aircraft autopilot system industry news, and policies according to regions.Free Sample of Global Commercial Aircraft Autopilot System Market report from https://market.biz/report/global-commercial-aircraft-autopilot-system-market-hr/239874/#requestforsampleGlobal Commercial Aircraft Autopilot System Market Competitive InsightsCompetitive Analysis serves as the bridge between manufacturers and other participants available in global commercial aircraft autopilot system market, the report comprised with a comparative study of top market players with company profile of competitive firms, commercial aircraft autopilot system product innovations, cost structure, manufacturing plants and process, revenue details of past years and technologies used by them. The commercial aircraft autopilot system report also elaborates on the key strategies competitors are using, their SWOT Analysis, and how the competition will react to changes in marketing techniques. This report used best market research techniques to provide the most recent knowledge about commercial aircraft autopilot system market competitors.Manufacturers that are listed in the reportGlobal Commercial Aircraft Autopilot System Market Segmentation InsightsThe report offers key insights on the various market segments presented to simplify the estimation of the global commercial aircraft autopilot system market. These market segments based on several relevant factors, including commercial aircraft autopilot system product type or services, end users or applications, and regions. The report also provides a detailed analysis on region-based potential held by the commercial aircraft autopilot system market, that includes diversity in production values, demand volumes, the presence of market players, the growth of each region over the given forecast period.Do Inquiry About The Report Here: https://market.biz/report/global-commercial-aircraft-autopilot-system-market-hr/239874/#inquiryWhat will you discover from global commercial aircraft autopilot system market report? Your email address will not be published. Required fields are marked *CommentName *Email *Website"
https://www.cbc.ca/news/canada/prince-edward-island/pei-marine-transportation-safety-board-investigation-1.4770092,"An investigation into the two-boat collision which resulted in two deaths in June, has revealed that one of the vessels was on autopilot at the time of the crash.The investigation into the collision off Beach Point, P.E.I., was conducted by the Transportation Safety Board of Canada.The following is the summary of the investigation from the TSB.According to the investigation summary, on June 9 the fishing vessel Forever Chasin' Tail, with three people on board, departed Beach Point to haul lobster traps about 14 nautical miles (nm) out.Later that morning, a second fishing vessel, Joel '98, with five people on board, also left Beach Point to haul traps about six nautical miles out.After hauling and setting all their traps, the master of Forever Chasin' Tail set the automatic pilot to steer a course toward the entrance to Beach Point Harbour, the summary reads. Meanwhile, the crew aboard Joel '98 continued to haul and reset traps while ""all attention was focused"" on a particular marker buoy on the starboard side of the boat.As the buoy line was being recovered, the summary reads, the master of Joel '98 and the crew aboard Forever Chasin' Tail noticed they were about to collide.""With no time for either vessel to manoeuvre, the Forever Chasin' Tail collided with the Joel '98 4.8 nm east-northeast of Murray Head, P.E.I.,"" the summary says.Forever Chasin' Tail came to rest on top of the deck of the Joel '98 and, as the Joel '98 began to sink, two of its crew members and one passenger climbed aboard Forever Chasin' Tail.According to the investigation report, ""The remaining crew member and passenger from the Joel '98 were found floating at the surface on the port side of the Forever Chasin' Tail as it floated free of the sinking vessel."" Both the crew member and passenger were recovered by Forever Chasin' Tail and another vessel that came to assist and both were pronounced dead by first responders at Beach Point.Justin MacKay, 20, from P.E.I., and 59-year-old Chris Melanson, from N.S., were previously identified as the two men that died.The Joel '98 remained partly submerged for several hours and later sank while under tow by another fishing vessel. The Forever Chasin' Tail was undamaged, the investigation said.Audience Relations, CBC P.O. Box 500 Station A Toronto, ON Canada, M5W 1E6Toll-free (Canada only): 1-866-306-4636TTY/Teletype writer: 1-866-220-6045It is a priority for CBC to create a website that is accessible to all Canadians including people with visual, hearing, motor and cognitive challenges.Closed Captioning and Described Video is available for many CBC-TV shows offered on CBC Watch."
http://www.governing.com/gov-institute/funkhouser/gov-state-budgets.html,"When I was running for mayor of Kansas City, Mo., my campaign mantra was “Clean, safe neighborhoods in a city that works for regular folks!” I admit that my slogan wasn’t all that creative or a lot different from the vision of mayoral candidates everywhere. These policy objectives are nearly universal: to create and maintain conditions that make a city a place where people want to live and work and, perhaps, raise a family.The budget is the primary tool to achieve what is promised. That’s what the public administration textbooks will tell you, and the politicians will agree. But most of the time the reality is closer to how then-Baltimore Mayor Sheila Dixon put it to Andrew Kleine in early 2008, as he recounts his interview with her to become the city’s budget director. “The budget is like a $3 billion black box to me,” she told him. “The decisions brought to me are at the margins, which means that, as far as I know, 99 percent of the budget is basically on autopilot.”When I was in Kansas City, the total budget was about $1.3 billion, but only a small fraction of it was truly discretionary. In 22 years with the city, first as auditor and then as mayor, I attended an awful lot of contentious budget hearings. The fight was almost always over something like a $5,000 grant to some nonprofit. The bulk of the budget was just as Dixon described, on autopilot.In city after city, mayors are creating an alphabet soup of new positions -- chief innovation officers, chief performance officers and so on -- focused on improving results. These are not bad things to do, but they are not by themselves going to make the birds sing. What is needed is a way to harness the budget-setting process for outcomes. A powerful argument for this was set forth in The Price of Government, the 2004 book by David Osborne and Peter Hutchinson. Their ideas struck a deep chord in Kleine. In his new book City on the Line: How Baltimore Transformed Its Budget to Beat the Great Recession and Deliver Outcomes, he tells the story of his 10 years as Baltimore’s budget director, pushing for and steadily improving outcomes-focused budgeting.Kleine’s book brings to mind the fraught relationships between the professionals and the politicians. An aggressive and muscular posture on the part of a staff person is going to be threatening to a lot of politicians, and agency heads can use that tension to undermine and eventually eliminate a staff leader who is innovating. Innovation almost always brings conflict.But it’s worth the struggle. I was mayor during the last recession and frequently heard that Kansas City was “broke.” During the budget battles I would say, “We’re not broke, we’re going to spend $1.3 billion. That’s an awful lot of money. The question is how to get the best results for it.” Kleine’s book offers a game plan for how to get that done.Presented byHealth care costs can tell officials a lot about a state's fiscal temperature.Sometimes the morally right thing to do is also the economically smart thing to do.It’s not some innate quality -- good leaders must create it.Should you really need a license to teach hair braiding?Everyone thinks they know what a mayor does, but the role of a city leader varies greatly from one place to the next.Framing is key. Empathy is not."
https://www.businessinsider.com/volvo-xc40-review-price-and-pictures-2018-7,"The Volvo XC40 is the newest addition to the Swedish automaker's SUV lineup and it joins a growing segment of compact sport-utility vehicles and crossovers currently dominating the market.Now eight years into its relaunch as a luxury brand under the Chinese automotive conglomerate, Geely Holding Group, Volvo has launched seven new models, three of which are SUVs: the XC90, XC60, and now the XC40.The 40 is built on Volvo's proprietary small-car skeleton, denoted as the Compact Modular Architecture (CMA) platform which was co-developed with Geely.As automobiles go, being the smallest and least expensive model in a lineup usually means you'll have to make some compromises — the evidence of which might manifest itself in lower-quality materials and fewer options than the pricier models.That is not the case here. The XC40 feels nearly every bit as premium as a compact luxury four-wheeler should.From the moment you pull open its hefty doors, plant yourself into the sculpted, leather and Alcantara-wrapped driver's seat, and grip the thick-rimmed steering wheel with the stoic chrome-plated Volvo badge planted dead-center, you realize you're about to pilot a very capable, exceptionally well-built machine.At the same time, it's also quaint. And comfortable.Unlike its larger siblings, the XC40 has no plug-in hybrid variant yet. It can only be had with one of two versions of the company's four-cylinder, turbocharged, gas-powered engines — available with 187-horsepower, or a more energetic 248-horsepower variant. An all-electric version is currently in development.Volvo recently loaned us a fully loaded XC40 R-Design for a weeklong drive in Los Angeles. These are our impressions:In pictures, the XC40 looks deceptively small. In reality, it's compact enough for city driving but has plenty cargo and passenger room for longer trips.The Volvo family resemblance here is unmistakable. By now, you've seen what Volvo lovingly calls the ""Thor's hammer"" effect prominently featured in the automaker's signature headlights. Up front on the XC40, it gives the car a subtle, unique flair that makes it instantly memorable.Our Crystal White metallic test-car came with several panels and trim pieces, including the front grille seen here, painted gloss black.You're probably seeing a lot of cars with this aesthetic on the road right now: side-view mirrors, roofs, rear decklid spoilers, side and hood vents — both fake and real — and, in some cases, door handles, all painted black. I have mixed opinions about it.On some cars, these pieces are black because they're made of carbon-fiber, a strong lightweight material typically reserved for high-end performance cars and race cars. But some average passenger cars have it too, for some reason.Here on our R-Design model, the black trim works.The entire roof, and a portion of the D-pillar, are also painted black. Again, it works for the R-Design, but still feels just a little bit contrived. Call me boring, but I'd prefer the entire car painted one color.Overall, this is a very handsome package, as equipped.In keeping with the current mode for modern SUVs, a striking pair of shoes are a must. These are Volvo's 20-inch, 5-double spoke matte black diamond cut alloys.Current-generation Volvos are some of the few luxury cars that boast a family resemblance from the front and the back. The upswept tail lights are instantly recognizable. Even from a distance, everyone will know you're driving Swedish.Broadly speaking, the mighty turbocharged four-cylinder engine has become a staple in the modern auto industry. You get a very capable one in the XC40. Our tester was equipped with Volvo's 248-horsepower T5 variant. It's quick, quiet, and efficient.Gas mileage was as good as I expected: 23 mpg in the city and 31 mpg on the highway, according to Volvo.During my time with the XC40, I took a weekend road trip from Los Angeles to San Francisco. Starting with a full tank on both ends of the journey, I only needed to top off once, roughly halfway between the two cities. I'm certain I could've kept driving for a while before the tank got too close to empty.The interior is really well done, and a pleasant surprise for any compact SUV starting in the $30,000 range.Granted, our test model was loaded with every option available, but that doesn't negate the consideration Volvo's designers gave to the tactile feel of nearly every interior touch point — from the seating surfaces, to the chunky metal interior door handles, and the knurled center-console knob just below the nine-inch touch screen.And for maximum practicality, there's a small rubbish bin in front of the center armrest.The XC40's sportier R-Design package equips the seats with a rather typical combination of leather and a suede-like Alcantara. Also typical of Volvo specifically: these seats are a deeply satisfying place to be.The splash of orange on the interior door panels and carpet help break up the visual monotony of what would otherwise be an all-black-everything interior.On paper, you'd think a splash of orange would turn an otherwise handsome interior into something rather undignified, but that's not the case here. It livens things up just enough, without feeling cheap or gratuitous.And, of course, there's a panoramic sunroof for good measure.Our test XC40 came with Volvo's Pilot Assist semi-autonomous-drive feature. It keeps the car within its own lane on the road, and maintains a set speed and distance from the car ahead.Unlike Tesla's Autopilot, Volvo's almost-but-not-quite-self-driving technology will not let you drive for any length of time with your hands off the steering wheel.While testing the feature in freeway traffic, we observed that it took the XC40 about a second to recognize there was no driver input on the steering wheel, and it gave visual and audio prompts to reengage.I would argue — as many automotive journalists before me have — that Tesla's Autopilot is a more advanced semi-autonomous driving system that handles steering, acceleration, braking and lane-change duties in real-world traffic far more gracefully than most other systems on the road right now.But Autopilot is not perfect. And in my personal experience, Autopilot is too tolerant of longer stretches of handsfree driving. Autopilot does deploy a set of alerts that gradually escalate if drivers go hands-off for more than 30 seconds.Sensus, Volvo's infotainment interface, is a fantastic system. One of the best vehicle UIs in the industry.It merges the car's systemwide settings and features with Apple CarPlay and Android Auto. The drawback to that is you get a screen with multiple layers of pages and tabs that require a sizable share of your brain's attention to navigate. It's a fine system nonetheless.You can see that here, with the rubberized miniature Swedish flag affixed to the front left fender.The Volvo XC40 really hits a sweet spot among the current crop compact luxury SUVs. It's large enough for cargo and crew, but remains nimble and responsive on the road. The available active safety and driver-assist features are well-executed.It's an attractive and capable vehicle that's distinctively Volvo, and comes in at a price point that positions the company to reach new customers.Coincidentally, Volvo says it has already seen such an influx with the XC40, which is available by subscription, via the Care by Volvo program.Subscribers can order an XC40 and pay a flat monthly fee that includes the car payment, insurance, and scheduled maintenance.""We're proud that 92% of subscribers are completely new to the Volvo brand,"" company spokesman Jim Nichols told Business Insider in an emailed statement. As of July 2018, the automaker has sold more than 6,600 XC40s — surpassing all other models in the Volvo lineup year-to-date.All that's missing is an electric variant, which is in development as of this writing. Given the current obsession for these compact luxury SUVs, and the growing demand for affordable electric vehicles, an all-electric XC40 could conceivably dominate the market once it hits the road."
https://www.sfchronicle.com/business/article/After-Uber-accident-fewer-people-want-13159087.php,"Public support for self-driving cars has plunged in the wake of a deadly accident this spring, according to a new survey.And young, tech-savvy consumers now express more doubts about robot vehicles.Cox Automotive, an auto-industry services and information company, surveyed 1,250 people, following up on a similar study conducted in 2016. In those two years, public awareness of self-driving cars grew substantially, but so did distrust of the technology.In 2016, 30 percent of the people surveyed said they would never buy a fully autonomous vehicle that didn’t give them the option to drive. Now, nearly half — 49 percent — say they won’t buy such a car.The March accident in which a self-driving Uber car in Arizona struck and killed a pedestrian appears to have contributed both to wider awareness of the technology as well as the public’s doubts about it.“Now they’ve got a reason to be aware, because people have actually been killed by the process of testing it,” said Karl Brauer, executive publisher of Cox’s Kelley Blue Book information service. “Adoption of new technology is always tricky. Remember that air bags were supposed to save everybody from death inside the car when there’s an accident. Then we had people killed by them.”The fatal crash of a Tesla Model X operating in Autopilot mode in Mountain View contributed to rising suspicion of robot cars among consumers, he said, but not to the same extent. Autopilot is far from self-driving — it has features like lane-keeping and automatic braking, but Tesla says drivers must pay attention and keep their hands on the wheel.The drop in support cut across every age group, even the youngest in the survey. Among Generation Z — people born starting in the mid-1990s — support for fully autonomous cars plunged 70 percent. Only Baby Boomers showed a bigger plunge in confidence in the technology: 78 percent.Members of Gen Z are digital natives, having never known a world without the internet. But Brauer said they’re also growing up at a time of negative headlines about technology in general, from hackers stealing Social Security numbers to the use of social media to interfere in elections.“I think Gen Z is as much or more aware of technology than any other generation, but they’re also more aware of the failings of technology,” Brauer said. “They’ve seen the failings from the beginning.”The survey examined how consumers feel about different levels of autonomy, and found far more comfort with systems that assist drivers rather than take total control.The autonomous vehicle industry sorts the technology into five levels, each more sophisticated than the last. Level 1 systems, for example, include adaptive cruise control. Tesla’s Autopilot and Nissan’s Propilot Assist fall into level 2, steering cars on the highway and avoiding collisions. Level 5 represents full autonomy, with the steering wheel and brake pedal no longer needed.In the 2016 version of the survey, most consumers expressed a preference for level 4 cars, which would be able to drive themselves in most circumstances but would still give humans the option of driving. This year, however, most respondents preferred level 2 — in other words, the driver-assist features already on the market.“I want assistance, but I don’t want the car driving for me,” Brauer said.That, too, may be a response to the well-publicized accidents.Similarly, survey participants expressed reluctance to host tests of self-driving vehicles in their own cities and towns. While 75 percent said the vehicles need real-world testing, 54 percent said that testing should take place somewhere else, not where they live.“Just like prisons and nuclear power plants, it’s now a NIMBY situation when it comes to autonomous car testing,” Brauer said.David R. Baker is a San Francisco Chronicle staff writer. Email: dbaker@sfchronicle.com Twitter: @DavidBakerSFDavid Baker covers energy, clean tech, electric vehicles and self-driving cars for the San Francisco Chronicle. He joined the paper in 2000 after spending five years in Southern California reporting for the Los Angeles Times and the Daily News of Los Angeles. He has reported from wind farms, geothermal fields, solar power plants, oil fields and an offshore drilling rig in the Gulf of Mexico. He also visited Baghdad and Basra in 2003 to write about Iraq's reconstruction. He graduated from Amherst College and the Columbia University Graduate School of Journalism. He lives in San Francisco with his wife. You must be signed in to commentABOUTCONTACTSERVICES©2018 Hearst"
https://www.thestreet.com/investing/tesla-s-killer-app-is-its-software-updates-14684545,"In 2017, Tesla Inc. (TSLA - Get Report) took the top spot in Consumer Reports' buyer satisfaction survey.And Tesla-watchers are wondering how long the company can keep that top spot.For years, one of the biggest arguments from Tesla shorts has been that increased competition in the electric car space will pose an insurmountable challenge for Elon Musk and company. And, without a doubt, more competition is coming soon in the luxury electric vehicle space.Jaguar plans on selling its i-Pace crossover in the second half of this year, and Porsche's hotly anticipated Mission E is supposed to hit the streets next year. There's certainly something to the idea that more high-end EVs will boost the competition in the space. But anyone who focuses just on that is missing one of the biggest drivers of Tesla's success; they're not paying attention to the company's ""killer app"".It's software.More specifically, it's over-the-air software updates.Remember, Tesla isn't a high-tech car company. It's a tech company that happens to make cars.That's why, for instance, the very first Tesla Model S sedans that rolled off the line back in 2012 can run the newest versions of the company's operating system, with new features and an updated user interface.Sit in any other 2012 model year car, and the tech will feel painfully dated. Meanwhile, the Tesla actually gets new features at no cost over the air via Wi-Fi or the car's cellular modem.That's actually a very big deal, particularly when you consider that a car is most consumers' second most expensive purchase after their home.That software update capability also means Tesla gets upsell opportunities that other carmakers don't have. For example, because the self-driving hardware on every new model is identical, Tesla has been offering 14-day trials of its Enhanced Autopilot features to customers who didn't buy that option at delivery.Of course, other carmakers are planning on introducing over-the-air updates, too. For instance, Ford and GM both say they'll include the functionality by 2020. But they will likely be hamstrung by their own dealer networks, who are likely to fight back on car manufacturers providing service directly to consumers by the way of updates.For instance, over-the-air software update capabilities equipped in some Cadillacs today are intentionally limited to maps in the car's navigation system.Free software updates are a normal thing for tech companies, but they're an alien concept for car companies (and particularly for dealers).Tesla is expected to release the hotly anticipated version 9 of its car software around the end of August.This article is commentary by an independent contributor. At the time of publication, the author held no positions in the stocks mentioned.Calling all stock market bulls: there are bearish signs all over the place in these markets. Time to get real.According to a recent study, almost half of Americans like market volatility. Where do you fall on this topic?Former U.S. Education Secretary Arne Duncan attributes the struggling U.S. school system to a lack of will from voters to fix things.The tech sector can be a volatile space, should retirees even consider investing in it?Retail took center stage this week as second quarter earnings season wraps up.Sign up to get started or log in to see your watchlist.SIGN UPLOG IN"
https://www.stereogum.com/2010150/nicki-minaj-queen-review/franchises/status-aint-hood/,"Back in 2007, around the time she joined Lil Wayne on Young Money Records, Nicki Minaj released the mixtape track “Dreams (2007).” The concept was pretty simple. She was freestyling over the beat from the Notorious BIG’s “Dreams,” the one where he graphically fantasized about having sex with different R&B singers. Over that same beat, Nicki disclosed her plans to fuck various mixtape rappers. It’s a fascinating time capsule, a reminder of a time when anyone, let alone one of the most famous rappers on the planet, would publicly discuss the possibility of having sex with Hell Rell or Mims. And it’s a proof of an old truism: Any rapper who’s trying to drum up attention should just say a bunch of other rappers’ names. It’s the old 50 Cent “How To Rob” playbook in action.The most-discussed track on Nicki Minaj’s new album Queen is “Barbie Dreams,” and it’s pretty much the same thing, over the same beat. This time, though, Nicki’s not wasting her time with New York mixtape-rap footnotes like Red Café. Instead, she is exclusively going after the dudes on rap’s A-list. (This includes her “Fefe” collaborator 6ix9ine, who would’ve been a New York mixtape-rap footnote in a more just world.) And rather than fantasizing about fucking these guys, she’s playfully describing all the reasons why she would not fuck them.The jokes are all pretty obvious: Young Thug steals dresses, Drake cries, Eminem lives in a trailer park, etc. And the idea is stale; it is, after all, a slight mutation of something Nicki already did 11 years ago. But it’s also an example of Nicki Minaj having fun rapping. These days, I wish we had more of those.Things have been rocky for Nicki Minaj lately. This is not entirely the fault of Nicki Minaj. The world has never been an easy place for female rap stars. The world has especially never been an easy place for female rap stars who have been stars for more than a year or two. Nicki has been in the public eye for the better part of a decade. And she has been walking an extremely thin line between pop stardom and rap stardom — flexing over sugary EDM tracks while also doing snarly and intense street records. Her albums have always felt vaguely schizophrenic, and she’s found ways to make that work, largely by introducing her own cast of alter-ego characters. At her best, as on singles like “Super Bass” or “Truffle Butter,” she’s been able to make her pop side and her rap side live in harmony. But that hasn’t always been the case, and it’s not getting any easier.But there’s been other stuff, too. Not all of that has been Nicki’s fault. It’s not her fault, for instance, that the public knows way too many details about her noisy breakup with Meek Mill. It’s only partly her fault that, as I’m writing this, she and another ex have been airing out dirty laundry (including her ex’s allegation that she once cut him badly enough for him to be hospitalized) on Twitter all day. It is her fault that she launched a nasty and one-sided feud against a blog intern who suggested that maybe she should try making some more mature music, sending her fan army into torches-and-pitchforks mode. It’s her fault that she rhymed “Chyna” with “China,” “China,” and “China” on Yo Gotti’s “Rake It Up,” and that she rhymed “face time” with “hate crimes,” “FaceTime,” and “FaceTime” on Playboi Carti’s “Poke It Out.” It’s her fault, mostly, that the advance singles from Queen felt flat and mechanical upon arrival.Queen is a better album than those advance singles suggest, but that doesn’t mean that it’s a good album. It’s the first Nicki Minaj album with no silly EDM tracks, so that’s something. For years, we’ve been wondering how a straight-up rap album from Nicki Minaj album might sound, and Queen is mostly that. As a rapper, she’s still commanding and precise. Her voice still has force and presence, and she’s versatile and technically gifted enough to handle a wide range of circa-now beats. Her sneer still weighs a ton, not just when she’s lightly poking at her male peers but also when she’s tossing out unnamed subliminals at obvious targets (“I ain’t ever have to strip to get the pole position”). “LLC” is hard but playful. “Chun Swae” is playful but hard. The album-closing “Coco Chanel” is a total neck-breaker, and with its guest verse from ’90s Brooklyn OG Foxy Brown, it’s also a too-rare example of Nicki sharing a track with another female rapper. There are signs of life on this album.But that’s not enough. Even when she spends a whole album in rap mode, Nicki devotes way too much real estate to gooey radio-bait fare like the Ariana Grande collab “Bed” or the Weeknd collab “Thought I Knew You.” The mostly-sung “Come See About Me,” which has nothing to do with the Supremes song, is genuinely emotional, but the production is so light and insubstantial that the whole song evaporates upon impact. When Nicki does attack, say, a Metro Boomin beat with Future, everyone involved seems to be on complete cruise control. There’s a sense of lifeless detachment to too much of the album, as if Minaj is simply going through the motions of rap stardom without investing the full force of her personality.That personality used to be the thing. When Minaj showed up on our radar, not that long after “Dreams (2007),” she had technical chops, but that wasn’t all. She also had a level of giddy theater-kid charisma that felt entirely new in rap music. She was hard and showy at the same time, and she used that performing-arts demonstrativeness to help assert her rap bona fides and to run down her adversaries. But she can’t do it if she’s going to make rote, obvious boilerplate rap, and that’s mostly what she’s done on Queen. The summer of 2018 has given us way too many albums from rap A-listers who are increasingly and depressingly getting further away from what everyone loved about them in the first place. With Queen, Nicki Minaj joins that sad parade.1. SOB x RBE & Shoreline Mafia – “Da Move” Sometimes, you can just hear the energy exploding off of a record. This one basically sounds like all of young California coming together and going the fuck off. SOB x RBE have achieved full hero status in the Bay Area, and Shoreline Mafia are well on their way to doing the same thing in LA. On this one song, the two armies converge, and the exhilaration crackles in the air like ozone before a downpour.2. Ghostface Killah – “Saigon Velour” (Feat. LA The Darkman, Snoop Dogg, & E-40) Ghostface’s new album is called The Lost Tapes, but it’s a new album, not a collection of unreleased leftovers (which could be great, if one like it ever comes out). Still, this song had me wondering for a couple of seconds. Ghost hasn’t sounded this vigorous in a while, and this kind of charged-up horns-rolling beat is exactly the type of thing he should be using. It’s hugely heartening to hear a bicoastal squad of veterans coming out with this much fire, even if the sleepwalking Snoop verse doesn’t really need to be here.3. Young Nudy – “Right Now” Young Nudy, from Atlanta, isn’t a terribly distinctive rapper, though I like the back-of-the-throat croak in his delivery. But what he has working for him in an ear. On Slime Ball 3, the impressive mixtape he released last week, Nudy goes in over a long parade of gooey, aqueous beats like this one. I practically chose this track at random; the whole tape sounds like this.4. Lil Durk – “Do The Most” (Feat. Valee) One cool thing about Valee’s ascent is hearing him on tracks with established Chicago drill guys, where the light-dancing impressionism of his delivery can nicely contrast against something like Durk in full hammerhead mode. Also: “I spent $1400 on a yorkie doggie!”5. Young M.A – “Car Confessions” The ecstasy of “Oouuu” is fading further and further into the rearview, and Young M.A is just now getting ready to release her proper debut album. That’s a bad sign. Still, we already know that M.A can flex, and here we get to hear her get intense and introspective in that perfectly grimy mixtape-rapper way. That’s a good sign."
http://positivesource24.com/2018/08/16/global-aircraft-autopilot-systems-market-growth-analysis-2018-2023-garmin/,"If you are the webmaster of this site please log in to Cpanel and check the Error Logs. You will find the exact reason for this error there.Common reasons for this error are:In order files to be processed by the webserver, their permissions have to be equal or below 755. You can update file permissions with a FTP client or through cPanel's File Manager.Make sure you have not specified unsupported directives inside the local .htaccess file. Such include PHP settings and Apache module settings."
https://www.aikenstandard.com/horoscopes-for-aug/article_749cc2e4-981f-11e8-91aa-b338f378275d.html,"It's the 7th annual True To Your Sole back to school drive h…BIRTHDAY GAL: Actress Erika Christensen was born in Seattle on this date in 1982. This birthday gal portrayed Julia Braverman-Graham on ""Parenthood"" and she starred in the short-lived 2017 series ""Ten Days in the Valley."" On the big screen, Christensen's film work includes ""How to Rob a Bank,"" and ""Swimfan,"" and ""Traffic."" She will next appear in the upcoming comedy ""Clover"" in 2019.ARIES (March 21-April 19): Inspiring ideas will fill up your tanks. You can't make headway if you are running on empty. In the upcoming week you may be more comfortable working behind the scenes. You may receive a whiff of true love.TAURUS (April 20-May 20): You might enjoy the center of attention, even if it is only within the confines of your home. If you have developed good habits you can let your daily business routines run on autopilot in the week ahead.GEMINI (May 21-June 20): Be the bandleader who directs your own life. Don't let the passing whims of the world around you dictate how you spend your time this week. Use your charm and sincerity to impress people who wield the most influence.CANCER (June 21-July 22): You can improve your reputation and career standing this week by starting new projects and aligning yourself with key people. When you notice money-making opportunities, you must strike while the iron is hot.LEO (July 23-Aug. 22): In the week ahead, you may question whether your actions are bringing you the happiness you deserve. You may become more competitive at the workplace or more willing to tackle physically challenging projects.VIRGO (Aug. 23-Sept. 22): Go the distance. Some of life's challenges require a mere sprint but you will really showcase your talents if you follow through on a long-term project. In the week ahead your most thoughtful words will receive attention.LIBRA (Sept. 23-Oct. 22): In the week to come you may form ties and alliances that are mutually beneficial. Your lack of adventurousness may seem dull and unexciting to some, but they know they can count on you when the chips are down.SCORPIO (Oct. 23-Nov. 21): Your insights may be valuable especially where money is concerned. You may receive some type of secret knowledge that you can parlay into personal profit. Love can become a priority in the week ahead.SAGITTARIUS (Nov. 22-Dec. 21): Strive to start something meaningful for future success. You may consider making a change on impulse in the week ahead but will be happier with something that you have deliberated upon and prepared for.CAPRICORN (Dec. 22-Jan. 19): Past experiences should refine you not define you. In the week ahead, you may find ways to become more efficient so that you can meet the demands of daily life head-on. Experiment with the latest technology.AQUARIUS (Jan. 20-Feb. 18): Improve your financial standing while the going is good. Take steps to build an emergency fund, improve your job skills or widen your networks in the week ahead. Tact and kindness will produce the best results.PISCES (Feb. 19-March 20): Your aura of inner peace is soothing and attractive to others. You can buy new clothing that will enhance your appearance. Friends or co-workers might be erratic or eccentric and try your patience in the upcoming week.IF AUGUST 19 IS YOUR BIRTHDAY: Good fortune smiles on you during the next two to three weeks and you are blessed with the ability to be generous and charitable. This is a particularly good time for you to make new friendships or join clubs and organizations. Your fun-loving side will be in full bloom in late September and October, making this a good time for a vacation. Your desire to escape the limitations of mundane life may tempt you to waste your time on get-rich schemes or fantasies in early November. Wait until the end of November, when you are more practical and shrewd, to make crucial decisions about investments, business or your career. You can be easily fooled in January, so avoid making key decisions or crucial changes.Get Daily Headlines from Aiken Standard in your inbox.By submitting this form, you are consenting to receive marketing emails from: Aiken Standard. You can revoke your consent to receive emails at any time by using the SafeUnsubscribe® link, found at the bottom of every email. Emails are serviced by Constant Contact."
https://1reddrop.com/2018/08/15/4-weeks-tesla-firmware-v9-0-what-to-expect-timeline-autopilot-hardware-3/,"Tesla EVs regularly get OTA (over-the-air) updates when new firmware versions are available. The current version 8.1 is now expected to be upgraded to version 9.0, which Musk promises will have full self-driving capability for Autopilot. But some Tesla owners aren’t even aware of the full feature-set in the current version. To that end, we’ve shown you what the 8.1 firmware is capable of.Autopilot Features on Tesla Firmware Version 8.1:So, when it first came out (Build 2018.26 3bbd9fd), the Summon feature was in beta. It’s still not a public release, but several builds have come out since then. The latest build installed for a Tesla Model 3 is from yesterday (Aug 13) – Build 2018.28.5 377ec8b – and others have also reported an update. But the release notes simply say “minor improvements.” That likely means no significant bug fixes or additional features for this version.There haven’t been any formal confirmation on 9.0 features other than what Musk has indicated, and the timeline as of Aug 1 was “in four weeks”, so we should see something at the end of August 2018. Model 3 owners have, of course, speculated on what might be coming, but the lines are blurry between that and what might really come with the update. Nevertheless, here’s a non-comprehensive list of what to expect and what Model 3 owners are looking for:Most of the other features talked about in forums are pure wishlist-type features. Still, it’s good to know that quite a bit is being planned for the 9.0 release. Watch out towards the end of August for the OTA rollout.On the AP hardware side of things, there’s some great news as well. About 196,000 of a total of 360,000 deliveries made so far (all models) have Hardware 2+, and Hardware 3 is slated for 4-6 months from now, per Musk.As of now, Tesla claims to have the “world’s most advanced computer for autonomous driving”, thanks to the new chip developed in-house under the guidance of Pete Bannon after Jim Keller, formerly of AMD, left Tesla. Per the tweet thread, it’s been hinted that FSD features will start being rolled out with 9.0, but true FSD will likely need additional hardware support that will only come with Hardware 3.0 early next year. Hardware 2+ owners will get their new computers as a free upgrade, and this is applicable for everyone who already has Enhanced Autopilot and has ordered Full Self-driving.This is all the information we have on firmware v9.0 and Hardware 3 release date for now. We’ll keep updating this page as we hear more. Please feel free to comment if you come across anything that might need to be added to the content here.Save my name, email, and website in this browser for the next time I comment.This site uses Akismet to reduce spam. Learn how your comment data is processed."
https://www.bloomberg.com/news/videos/2018-07-27/ecb-policy-is-on-autopilot-sgh-macro-advisors-ceo-says-video,"Your usage has been flagged as a violation of our terms of service.For inquiries related to this message please contact support. For sales inquiries, please visit http://www.bloomberg.com/professional/request-demo"
https://www.fresnobee.com/sports/outdoors/hunting-fishing/article215435800.html,"By continuing to use this site, you give your consent to our use of cookies for analytics, personalization and ads. Read moreBY ROGER GEORGESpecial to The BeeJuly 24, 2018 11:17 AMMy recent trip to Alaska made it clear that I take for granted all the things that I do in my world that are built around years of repetition. The usual sights, sounds and smells that we experience are all a part of how we feel each time we hit the water, and our fishing decisions are more automatic than I think we realize.My first experience up there was stressful because I felt I was doing downright stupid things only a newbie would do, and I had no regular pattern to rely on. All my regular cues were missing. I think all of us have these kind of thoughts when we’re not confident or comfortable. However, getting out of my normal groove turned out to be a great learning experience. It was also humbling.All my senses were messed up in Alaska because everything was different. I wasn’t used to the environment, the area, how it smelled, the ocean conditions, how we fished, the type of boat and gear. Just about everything needed to be recalibrated for my senses to feel normal. You don’t trust your instincts when you’re out of sync, nothing feels right and your cues don’t work.Getting comfortable meant a lot more than just catching a fish. I needed time to process all the information that was flooding my senses so that I could make sense of what I needed to do – and make it part of my new system. It took three intense fishing days before it began to gel for me.Be the first to know when big news breaksMy trip made it obvious to me that I rely a lot more on my feelings and automatic responses than I would have ever believed possible. I have to consider: When I’m on the water, am I concentrating on what I’m doing right now? or am I actually mentally fishing a past “pet” situation, trying to get it to feel right and fit what I’m doing now? Maybe the answer is that sometimes, it’s a little of both.The “genie” in our minds is incredible. It can take over your decisions – or you can put it to work. You’re the master. Just be careful what you wish for.Never give up!Roger George is The Bee’s fishing expert: rogergeorge8000@sbcglobal.net, Rogergeorgeguideservice on Facebook and @StriperWarsBy Lending Tree — Homeowners could save thousands by refinancing at today's near historic low rates.VIEW MORE VIDEO"
https://theindustryherald.com/2018/08/17/global-uav-autopilot-market-analysis-2018-airware/,"The “Uav Autopilot Market (2018 – 2023): Global Industry Analysis” research publication offers readers with a comprehensive knowledge of the uav autopilot market scenario in forthcoming years. This report guides through various segments of the global uav autopilot market with market size status and forecast 2023. These segments are determined by sizing the market with uav autopilot type, end-use segment, and geography. Furthermore, the report offers strategic perspectives on market growth factors such as drivers, restraints, uav autopilot market demand and supplier opportunities, technological developments and how they will shape the uav autopilot industry.Market Summary: The main objective of the report is to track the market events such as product launches, uav autopilot market ups and downs in terms of volume US$ (mn) and volume (units) from 2013 to 2023, various development activities related to uav autopilot products, latest trends, and technologies used in this field. The first overview section of the report comprised with a definition of the global uav autopilot market, classification and regional outlook of the market. The regional analysis being used in this report that specifies opportunities available and growth prospects of the global uav autopilot market within the specified regions. It additionally provides information related to value chain with a curated list of raw materials suppliers, distributors, uav autopilot manufacturers, technological solutions providers and end users of the uav autopilot.Free Sample of Global Uav Autopilot Market report from https://market.biz/report/global-uav-autopilot-market-2017-mr/177430/#requestforsampleGlobal Uav Autopilot Market: Competitive InsightsThe crucial section of the report describes the vendor landscape of the global uav autopilot market, it includes the profile of leading market players currently operating in the market. The analysis provides information about their market revenues, products manufactured by them, uav autopilot manufacturing process and plants, opportunities that are motivating these players and business strategies followed by them. The uav autopilot report helps businesses compete better using this scale of reference, although planning their future developments to counter the movements of the other players and stay ahead in the competition.List of Market Players Profiled in the ReportSegments Covered in the Global Uav Autopilot Market ReportThe research study examines forecasts revenue growth of uav autopilot market at global, regional & country levels and provides inclusive insight on the market developments and opportunities available in various segments of the uav autopilot market from 2013 to 2023. For the purpose of this study, report segmented the global market based on region, end-user, and uav autopilot type. The market shares contributed by these segments are formulated to give the readers a 360-degree assessment of the global uav autopilot market.Do Inquiry About The Report Here: https://market.biz/report/global-uav-autopilot-market-2017-mr/177430/#inquiryWhat will you discover from uav autopilot report?– A comprehensive analysis of current and future market demand for the uav autopilot, covering six world regions, end-use industries, growing markets for the uav autopilot.– The report employs a combination of primary and secondary research methods for segmenting and estimating quantitative facets of the global uav autopilot market.– Exclusive research on established and emerging market players to get competitive advantage of the global uav autopilot market.– Extensive analysis of the market drivers, restraints, review of latest trends and technologies used, market openings for the uav autopilot.– Details of uav autopilot market sizes and five-year forecasts, segmented by product type, end use segment, and region and country worldwide. "
http://www.ekathimerini.com/231204/article/ekathimerini/business/athex-autopilot-sees-stocks-lose-more-altitude,"StocksA day of losses from start to finish sealed the fate of another week of devaluation on the Greek stock market, with the benchmark only just staying above the 750-point level and trading volume remaining below 20 million euros for yet another session. Barring a major surprise in the upcoming debt sustainability analysis by the International Monetary Fund, the market is set to remain on autopilot for at least the next three weeks.The Athens Exchange (ATHEX) general index ended at 751.43 points, shedding 0.53 percent from Thursday’s 755.41 points. On a weekly basis it declined 0.39 percent.The large-cap FTSE-25 index contracted 0.39 percent to 1,990.49 points, while small-caps expanded 1.14 percent.The banks index gave up 1.35 percent, with Alpha suffering a notable drop of 3.03 percent. National slipped 0.60 percent and Eurobank conceded 0.48 percent, while Piraeus improved 1.35 percent. There was also a notable rise for Jumbo (up 1.93 percent) and Terna Energy (1.82 percent).In total 32 stocks secured gains, 64 sustained losses and 21 remained unchanged.Turnover amounted to 18.3 million euros, down from Thursday’s 19.3 million.In Nicosia the Cyprus Stock Exchange general index edged up 0.05 percent to close at 76.14 points.Comments are not enabled TWITTER @ekathimerini  ©Developed by EWORX S.A. Powered by TOOLIP Web Content Management"
https://mybroadband.co.za/news/software/271735-tesla-to-release-vehicle-security-source-code.html,"Tesla CEO Elon Musk has voiced his intention to release the source code for Tesla’s car security software in an effort to improve the security of future self-driving cars.Following a Q&A session at the DEFCON hacking conference, Musk tweeted that he planned to open-source the carmaker’s security software.He stated that the software would be important for improving the safety of future vehicles.Earlier this year, Tesla open-sourced the buildroot material used to build the system image on its Autopilot platform in addition to the code for the Nvidia-based infotainment systems in the Model S and Model X.The manufacturer has not released the source code for its Autopilot self-driving software or the Nvidia applications it runs on its infotainment system.SELF-DRIVING CARS TESLA VEHICLE SECURITYHave you ever been a victim of SIM-swap fraud?View Results"
https://www.cnbc.com/2018/08/10/autonomous-vehicles-are-creating-jobs-heres-where.html,"When Will Mouat, 41, heard there might be a career opportunity in self-driving cars, he jumped. Even though he did not have an engineering background – a lawyer, Mouat had previously worked on the legal teams at PicsArt, a software company, and Shazam, an app that recognizes music – he was enthralled by the potential of the field.""I would gladly swim across an ocean of thumbtacks to work on this problem with this team,"" Mouat said.The team was made up of Chris Urmson and Sterling Anderson. Urmson had been chief technical officer of Google's self-driving car division, and Anderson was the former head of Autopilot at Tesla. Together, they started Aurora, one of a growing field of start-ups working on self-driving cars.Today, Mouat is vice president and general counsel of Aurora.New technology is often met with fear, and self-driving cars are no different. Americans are hesitant to trust autonomous vehicles, according to the Pew Research Center. Two fatal accidents this year did not improve consumer opinion.There is also worry about the number of jobs the new technology might eliminate.Yet the autonomous vehicle industry is creating jobs, as well, especially as multiple companies race to put the first self-driving car into action. Autonomous driving job listings increased 27 percent year over year in January 2018, according to ZipRecruiter, an online employment marketplace. From the second quarter of 2017 to the second quarter of 2018, the amount of postings boomed 250 percent on the site due to a hiring spree at the beginning of the year.There is anecdotal evidence that start-ups are growing. Aurora has expanded from a team of three in 2016 to more than 150 people across multiple facilities, the company said. Zoox, another start-up, said it has grown from four people in 2014 to more than 520 today. Both companies say they are hiring aggressively and don't expect to slow down in the next few years.Other more established companies are joining in. Tesla has been building an autopilot feature since 2014, and both Apple and Google parent company Alphabet are developing their own self-driving car models.Traditional automotive companies are also investing. Ford recently announced that the automaker plans to spend $4 billion on autonomous vehicles by 2023. General Motors will pour $100 million into self-driving cars, and Toyota launched a $2.8 billion self-driving car company in Tokyo.In 2015, some 15.5 million workers in the U.S. worked in jobs related to driving, according to an August 2017 report from the Department of Commerce's Economics and Statistics Administration.Only 3.8 million of those workers operate motor vehicles such as a truck or taxi. Among those workers, truck drivers are more vulnerable to automation because they drive mainly on highways, and that type of navigation is easier to automate than negotiating city streets. The remaining 11.7 million, who drive as part of job positions such as mail carriers, firefighters and emergency medical technicians, are likely to benefit from new technology.The average motor vehicle operator is male and older, with less education and pay than the typical worker, according to the Economics and Statistics Administration report.Still, it is one of few jobs where a worker can make more than twice the federal minimum wage of $7.25 an hour without a college education. The 2017 median pay for heavy and tractor-trailer truck drivers was $20.42 per hour, which adds up to $42,480 per year, according to the Bureau of Labor Statistics. The median household income for all households in the United States was $57,617 in 2016, according to the American Community Survey.It is estimated that autonomous cars could eliminate 300,000 driving jobs a year, according to a May 2017 report from Goldman Sachs. But that won't happen right away; the report estimated that from 2025 to 2030, autonomous cars will be 20 percent of car sales.How fast new technology disrupts driving jobs is important, said Amitai Bin-Nun, vice president of autonomous vehicles and mobility innovation at Securing America's Future Energy, a nonpartisan nonprofit that advocates for reducing U.S. oil dependence.Jobs will not disappear overnight, Bin-Nun said. There are many steps between zero and full automation. The workforce has shown resilience during gradual transitions in the past, said Bin-Nun.One example is the change in the agriculture industry. A century ago, most Americans worked on farms. Today, few do.""It's not because Americans stopped eating,"" Bin-Nun said.In the short term, Bin-Nun said there will be many things that make driving safer and less stressful.""Autonomous cars are going to largely eliminate jobs seekers weren't interested in and create opportunities in work that people will find more rewarding,"" said Ian Siegel, co-founder and CEO of ZipRecruiter.Indeed, there is already a shortage of truck drivers in the U.S. With the unemployment rate falling to 3.9 percent in July, companies have had difficulty recruiting for the strenuous job.In the future, autonomous cars may contribute very little to unemployment. The projected increase in the unemployment rate by autonomous vehicles is between 0.06 and 0.13 percent during the decade from 2045 to 2055, according to an assessment by economist Erica Groshen published in a June 2018 report by Securing America's Future Energy.The report also notes that new technology has historically had positive impacts on the economy, increasing productivity and lowering costs. Two examples are the internet and the interstate highway system.The internet boosted company profitability 10 percent in the early 2000s, according to a 2011 study by the McKinsey Global Institute. In turn, the interstate highway system had a return on investment of more than 30 percent between 1950 and 1990, according to a recent report from Compass Transportation.Companies are currently hiring engineers, technicians, software developers and designers to build autonomous vehicles.But careers outside of engineering are expanding in the industry. One of the most sought-after jobs, according to ZipRecruiter, is strategic account manager. The role is mostly focused on sales, according to the site.There are also increased opportunities in safety and testing as autonomous vehicle companies race to get cars ready for the road.""There's a huge opportunity to test your software in simulated environments,"" said Bert Kaufman, head of corporate and regulatory affairs at Zoox. Software developers have come from the gaming industry to help build out these testing platforms for Zoox, he said.Car maintenance and logistics positions will also continue to grow, said Kaufman.""Whether it's maintenance technicians, fleet oversight, remote oversight of the fleet, there's still going to be a need for service technicians to maintain and serve the fleet,"" said Kaufman.As self-driving cars become more prevalent, the kinds of jobs available will expand, said Siegel of ZipRecruiter.""In the emergence of any new technology, the preponderance of jobs are more skilled, more technical positions,"" he said. ""People put layers of simplification on top of it, which opens up access for less-trained people to participate into that industry.""The world won't need fewer mechanics, he said. In addition, a focus on skills could open opportunities for those without a college degree.Much like the creation of the interstate highway system or the internet, new autonomous vehicle technology has the potential to have a widespread impact on society.""The benefits outweigh the cost by a large margin,"" said Bin-Nun.Safety is one. Nearly 38,000 people died in car crashes in 2016, according to the National Highway Traffic Safety Administration, and most serious crashes are due to human error.""Autonomous vehicles will never be drunk, distracted or drowsy,"" said Kaufman.Beyond safety, self-driving cars could contribute to major gains in fuel efficiency, lower transportation costs to the consumer and increase access to rural areas.So far, 33 states have introduced legislation about autonomous vehicles, according to the autonomous vehicles legislative database from the National Conference of State Legislatures.Leaders are also pushing for legislation on the federal level. The SELF DRIVE Act was passed with bipartisan support in the House in September 2017. Now, it goes to the Senate.""Here's what we know – they're coming faster than anyone realizes, and they will be a sea change in society,"" said Siegel.More from Personal Finance: Student loan forgiveness less likely under new Trump proposal Here's how much students are saving to pay their own tuition bills At this college, every student gets a full-tuition scholarship and a jobGot a confidential news tip? We want to hear from you.Sign up for free newsletters and get more CNBC delivered to your inboxGet this delivered to your inbox, and more info about our products and services. Privacy Policy.© 2018 CNBC LLC. All Rights Reserved. A Division of NBCUniversalData is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.Data also provided by"
https://economictimes.indiatimes.com/news/politics-and-nation/scientist-vr-lalithambika-will-lead-isros-human-space-flight-programme/articleshow/65450174.cms,"03:59 PM | 17 AUGSENSEX37,947284.32NIFTY 5011,47085.70GOLD (MCX) (Rs/10g.)29,354.0024.00USD/INR70.160.26CHOOSE LANGUAGEENGYour Healthy WeekDaily NewsHealthier PatriotHealthier PatriotMore »GO TO ET PRIME →Copyright © 2018 Bennett, Coleman & Co. Ltd. All rights reserved. For reprint rights: Times Syndication ServiceLoading Please wait..."
https://cleantechnica.com/2018/08/18/nissan-leaf-vs-tesla-model-3-vs-chevy-bolt/,"August 18th, 2018 by Zachary Shahan I drove a 2018 Nissan LEAF a few days ago, a few weeks after driving a Chevy Bolt and a Tesla Model 3. Today, I again drove a Tesla Model 3, this time an all-wheel drive version of the car. Aside from the significantly larger and more expensive Tesla Model S and Model X, the Model 3, LEAF, and Bolt are the three highest selling fully electric cars in the United States, so I figured it would be most useful and interesting to compare the three of them when writing up my 2018 LEAF review.However, when I say that these are the three highest selling semi-affordable electric cars on the US market, I’m perhaps not providing enough perspective. The Model 3 sees something like 10–20 times more sales. Suffice it to say, there are some solid reasons why the Model 3 scores so many more sales. If you don’t want to understand why or think you’ve heard it all before and simply don’t want to read the comparisons again, this may not be the LEAF review for you and you might want to move on. That said, I do think the LEAF is a solid car and should get more love than it gets. I also think it could finally sell in high volumes if Nissan finds a way to make the base version $10,000 cheaper than the base Tesla Model 3. But that’s a discussion for another day.Related: 7 Charts — Tesla Model 3 vs The Competition (US Sales)Dealership experience: This is not really about “the car,” so I didn’t think to mention it until the last minute, but it’s interesting how much this simple, relatively short experience with other human beings frames your opinion of a company. And Lordy, it sure is a world of difference between the experiences!As you may know, GM & Nissan are considered to be fairly good at selling electric cars. They have specialists on staff who know a bit about their electric cars and they typically don’t try to force you into a gasmobile. That said, this is basically how I’d summarize the customer service I’ve received on four visits to GM & Nissan dealerships (not direct quotes):Sales dude: “Oh, you want to drive a car? Okay, I guess it’s my job to help you, hold on a minute.”Me: Semi-excited comments about the car.Sales dude (not semi-excited): “Yeah, these cars are cars we have. Some people buy them, most people don’t. We sell a couple electric cars a month. They’re nice, but not really for me. I like [fill in the blank with adjectives, nouns, cat stories, whatever you want].”Me: Excited comments about the car while driving.Sales dude: “Yeah, sort of a nice car, meh. I’d buy one, but … meh.”Of course, back at the desk, they’re eager to find out if I’m going to buy, happy to get some paperwork started, happy to follow up with me later if I need a reminder to consider buying the car (or, rather than that car, some gasmobile they’re pushing).At a Tesla store, it’s noticeably different. Staff are standing around to answer some questions if I or anyone else has any. On the test drive, the Tesla employee is happy to tell me a bit more about Tesla, ask me about the car I’m currently driving and how I like it (he, of course, doesn’t need to tell me the Model 3 is better), and explain all the features he loves in the Tesla Model 3. Not pushy, but excited. Sort of the opposite of the normal dealer experience, where salespeople are often not excited about the product or the company but are eager to get your paperwork started. The Tesla experience gets you more excited and eager to join the “Tesla family.” The other experience encourages you to stay away from another dealership as long as possible.To be absolutely fair, all of the Nissan and GM salespeople I’ve ever had have been nice to me and have not really badmouthed the electric cars they sold. But I’ve been far more excited about their electric cars than they’ve been. At Tesla, the salespeople seem to feel lucky just to be there and have enthusiasm for the vehicles oozing out of their eyes — and yet, I don’t feel at all that they’re pushing a car on me.By the way, completely aside from the salespeople themselves, in a Tesla store, other potential customers are constantly strolling in and out, seem to have a certain level of amazement or at least joy sparkling on their faces, and tend to share a healthy number of smiles. If you’ve been at a normal car dealership, you know that’s not how things roll there. Something new is afoot.Aesthetics: Aesthetics are hugely subjective. That said, a large number of people think Brad Pitt is attractive. Me? Not so much. In my opinion, the 2018 Nissan LEAF is a good looking car. It also looks quite normal, but “new normal,” not “2010 normal.” I think Nissan has done well with this model and will benefit over time from the attractive, sporty, yet every-person’s-car look of the second-gen LEAF.The Model 3 is just stunning. It’s a beautiful car. It’s a Brad Pitt or Emily Ratajkowski of cars, which probably makes uninitiate people on the side oft he street think it sells at Porsche or Aston Martin prices. I still remember the lady who was just in front of me in line to reserve a Model 3 at 6:00am in Santa Monica. She had simply seen a Model S on the highway, thought it was beautiful, googled “T car” when she got home, discovered the Model S was out of her price range, found out about the Model 3 a few months later on Facebook, and decided to go early on March 31 to reserve one. I’m curious what she thinks of the Model 3’s aesthetics, but I can only assume she immediately fell in love with the car.The Bolt: Well, some people like it. And, to be honest, I think it looks much better in person than in pictures. But it’s sort of a chubby, bubbly car. It’s not as sleek and sporty as a Tesla Model 3 or Nissan LEAF. It’s a fade-into-the-crowd hatchback with a Chevy badge that will definitely turn heads — er, I mean, won’t turn heads. To be frank, though, that’s exactly what some people like. … Right?The doors: The doors on the LEAF and the Bolt are normal. Nice. Normal. The doors on the Model 3 stand out, of course, with the handlebars looking a bit upside down and super sleek. I imagine some people love the door handles and some people hate them, but I have to assume that everyone notices they are different. When I first saw the door handles in pictures and videos online, I wasn’t sure how much I’d fancy them in person, but I’ve ended up very smitten with these little buggers. The handlebars on the LEAF and Bolt? Meh, they’re handlebars. Actually, I had to look at the photos again to remember anything about them.Infotainment & controls: I didn’t have a lot of time to explore the LEAF’s or the Bolt’s infotainment systems, but the screens were tiny compared to the infotainment screen on a Tesla Model 3. They were better than screens put into such cars 5 years ago, but they still felt a generation or two out of date. Having a Tesla for a while can spoil you like that. In fact, of all the features of the Model 3 I’m itching for while we have a BMW i3 as our daily driver, the phenomenally better touchscreen in the Model 3 is perhaps the item that is most pulling me back to Tesla.As far as the other cars, I found the backup camera display on the LEAF to be most disturbingly small. It’s freakin’ tiny! Moments after peering into that minuscule display, though, I noticed the 360° bird’s-eye view display — which is right next to the backup camera display. That feature is totally freakin’ awesome. I only used it once, but it made parking even easier and more fun than a backup camera display. The downside is that it is tiny.All in all, I’d take the big screen of the Model 3 any day. As far as choosing between the Bolt or the LEAF on this front, I don’t currently have a strong preference (I need more time with both cars to decide), but I favor the LEAF at the moment because of that wicked 360° bird’s-eye view feature.Drive quality: Based on reviews I had read, I have to admit that I expected quite a bit more fun out of the 2018 LEAF and Bolt. Perhaps I just developed overly inflated expectations, but there’s no doubt those expectations were related to time with a Tesla Model S in the garage and now a BMW i3 in the parking lot (no garage this time). The LEAF and the Bolt both have a soft kind of floaty feeling. I imagine some people like that — maybe it feels relaxing. It certainly doesn’t ask you to zip around the curves. The drive quality of both is smooth and quiet, but not sporty. The LEAF felt a little more nimble and natural to me — I think it may have had something to do with the dash and the hood, not the drivetrain, but I need more time with both vehicles to firm up an opinion on that — but the two cars were surprisingly similar in drive quality.Neither car comes within a basketball court of the Model 3, which has the best drive quality of any car I’ve ever driven. I love our i3, but after driving a Model 3 again today, my mind keeps wandering over to the idea of switching to a Model 3 in a few months. I even planted the seed into my wife’s head. It would be cool to have both cars (plus a Model X), but our bank account doesn’t permit that. The i3 is a super fun little city car, but the solid skateboard base of the Model 3, the idyllic handling, the thick and sporty steering wheel, and the superbly powerful motors just put the Model 3 into too beautiful of a class, a class of its own.Related: Sorry, Elon — Tesla Model 3 Much Better Than I Expected (#CleanTechnica Review)Regen: The AWD Model 3 I drove today seemed to have better regenerative braking compared to the RWD Model 3 I reviewed previously (a review, by the way, that Elon Musk retweeted). Or perhaps I was just in a different mood today. Either way, I found the regen on the Model 3 to be slightly better than my i3’s superb regen, which I previously felt was the best I had experienced. Like Kyle Field has written, there’s just a kind of smooth, refined feel to the regen in these two cars. The Model 3’s regen adds in that solid Tesla feel that, again, just makes you feel like you’re in a whole ‘nother class of driving.The regen on the LEAF is good, as is the regen on the Bolt. I would like a week with both cars to compare better with the i3, but my overall reaction from a couple of short test drives is that their regen is a generation beyond early electric car regen but not in the same league as the Model 3’s regen. When you consider how big a factor one-pedal driving is in EV ownership — and that it’s one of the top advantages of an electric car — having top-in-class regen makes a daily difference. Nonetheless, I imagine no one with a 2018 LEAF or Bolt feels like they got hoodwinked or snubbed. The regen on both cars is also great, and that means it’s 100× greater than the braking experience of any gasmobile.Semi-autonomous driving: Yet again, my LEAF expectations were a bit too high based on previous content (mostly press releases and Nissan videos) about ProPILOT. My understanding was that it was going to be comparable to Tesla Autopilot. I’d say it is the best semi-autonomous driving suite I’ve experienced outside of Autopilot, but it’s definitely a step down from Autopilot.Interestingly, you have to keep your hands on the wheel of the LEAF at all times or ProPILOT will shut off. It also can’t change lanes. From my brief drive, ProPILOT seemed to stay in the lane fine without ping ponging between the lines, but I admittedly had a hard time evaluating this since I had to keep my hands on the wheel at all times, since it got deactivated a bit too easily, and since I just couldn’t get a feel for the system to let it completely do its thing.Like Autopilot, ProPILOT has several options for the traffic-aware cruise control distance (“traffic-aware cruise control” is cruise control that adapts to the car in front of you). The system seems to work well and I think gives plenty of choice regarding how closely you follow behind the car in front.Charging: Well, I didn’t do any charging, but it’s obvious that the Model 3 wins due to much faster charging than the others when on a road trip. Regarding the LEAF versus Bolt, it depends on your region. In some places the CHAdeMO (Nissan) network is much better for fast charging, whereas in a number of others, CCS shines.But, yeah — there’s nothing like Tesla Supercharging and the convenience it offers for long-distance trips.That’s my overall rundown of these three cars and how they compare. I could go further into infotainment, semi-autonomous tech, and simply life with these cars if I had more time with them, but I don’t think that would substantially change any of my opinions. The LEAF and Bolt are solid electric cars for people who just want a “normal” car but one that has the beauty of an electric drivetrain. The Model 3 is in a totally different arena, and is playing to the big crowds. Spending more time in a Model 3 would probably just make me convince myself to buy one, so I’m going to try to stay away for a while. Wish me luck.Tags: BMW i3, BMW i3 long-term review, Chevy Bolt, Chevy Bolt reviews, EV reviews, Nissan Leaf, Nissan Leaf reviews, Nissan ProPilot, regenerative braking, Tesla, Tesla Model 3, Tesla Model 3 infotainment, Tesla Model 3 long-term review, Tesla Model 3 regen, Tesla Model 3 reviewsZachary Shahan Zach is tryin' to help society help itself (and other species). He spends most of his time here on CleanTechnica as its director and chief editor. He's also the president of Important Media and the director/founder of EV Obsession and Solar Love. Zach is recognized globally as an electric vehicle, solar energy, and energy storage expert. He has presented about cleantech at conferences in India, the UAE, Ukraine, Poland, Germany, the Netherlands, the USA, and Canada. Zach has long-term investments in TSLA, FSLR, SPWR, SEDG, & ABB — after years of covering solar and EVs, he simply has a lot of faith in these particular companies and feels like they are good cleantech companies to invest in. But he offers no professional investment advice and would rather not be responsible for you losing money, so don't jump to conclusions.Advertise with CleanTechnica to get your company in front of our readers.CleanTechnica's main, daily newsletterCleanTechnica's EV newsletterCleanTechnica's wind newsletterCleanTechnica's solar newsletterCleanTechnica's weekly newsletterCleanTechnica is the #1 cleantech-focused news & analysis website in the US & the world, focusing primarily on electric cars, solar energy, wind energy, & energy storage. It is part of Important Media -- a network of 20 progressive blogs working to make the world a better, greener place.The content produced by this site is for entertainment purposes only. Opinions and comments published on this site may not be sanctioned by, and do not necessarily represent the views of Sustainable Enterprises Media, Inc., its owners, sponsors, affiliates, or subsidiaries.© 2018   Sustainable Enterprises Media, Inc."
https://www.businessinsider.com/teslas-autopilot-faces-scrutiny-after-accidents-2018-5,"A feature that was supposed to set Tesla apart from its competition has been doing so for the wrong reasons lately.Tesla's Autopilot system is a semi-autonomous driver assistance feature that, among other things, can keep a car in its lane and adjust its speed based on surrounding traffic. (Tesla considers safety features that were made possible by the Autopilot hardware, like automatic emergency braking, to be part of the Autopilot suite, but those safety features come standard in Tesla vehicles and can activate even if a customer does not buy or use the ""Enhanced Autopilot"" package, which includes the semi-autonomous features. Concerns about Autopilot have focused on the semi-autonomous features, like Autosteer)Since its launch in 2015, Autopilot has been one of Elon Musk's main talking points and has helped the electric carmaker garner a reputation as a leader in automotive tech. But recently, Autopilot has put Tesla in the spotlight for all the wrong reasons.Since Autopilot was released, two fatal accidents have illustrated the concerns some auto companies have about semi-autonomous driver assistance systems and whether enough drivers use them correctly.The first came in 2016, when Joshua Brown was killed after his Model S crashed into a semi truck in Florida while Autopilot was engaged. The vehicle's data logs revealed that Brown had his hands on the wheel for 25 seconds of the 37 minutes Autopilot was activated during the trip, and that Brown had received seven visual and six auditory warnings to return his hands to the wheel. While the National Highway Traffic Safety Administration (NHTSA) said Autopilot was not responsible for the accident and did not identify any defects in the feature, the National Transportation Safety Board (NTSB) said the feature played a role in the crash.""Tesla allowed the driver to use the system outside the environment for which it was designed, and the system gave far too much leeway to the driver to divert his attention to something other than driving,"" NTSB chairman Robert Sumwalt said in 2017.Two months after the accident, Tesla rolled out a feature that disables Autopilot once multiple warnings to apply sufficient torque to the wheel are ignored in a software update.The second fatal accident occurred in March, when a Model X crashed into a highway barrier in California. The driver, Wei Huang, was taken to a hospital and later died. The NTSB has yet to complete its investigation into the accident, but the agency confirmed that Autopilot was engaged during the collision. Tesla said Huang had received multiple warnings to put his hands on the wheel during the drive and indicated that a shortened impact attenuator increased the damage to Huang and the vehicle.The most recent accident involving Autopilot came on May 11, when a Model S hit a fire department vehicle in Utah. The driver had Autopilot engaged at the time of the accident, but also said she was using her phone. She suffered a broken ankle as a result of the incident.In a report Tesla provided to the South Jordan Police Department, the company said the driver took her hands off the wheel over 12 times during the drive, including for the 80 seconds before the collision.While the company has repeatedly said Autopilot is meant to be used with an attentive driver whose hands are on the wheel, analysts have pointed to decisions the company has made when promoting the feature that, in aggregate, have the potential to create false impressions about Autopilot.If Autopilot is misused, it could result in accidents that would be avoided by an attentive driver.This means Tesla has to strike a difficult balance when selling the feature, between highlighting Autopilot's benefits and outlining its limitations. But its name could be getting in the way of that.The word ""autopilot"" is typically associated with systems that steer airplanes, boats, or spacecraft without human assistance. In contrast, the names given to competing driver assistance systems, like Super Cruise or Nissan's Pro Pilot Assist, more clearly create the impression that they're augmenting, rather than replacing, the driver, Autotrader executive editor Brian Moody told Business Insider""Even if they work similarly and even if the admonitions are the same, the name itself I think is the first place that you start in looking at this,"" Moody said. ""The difference is that one name implies it does it by itself and the other one implies that you need to be there as a person because it's giving you an assist.""A Tesla representative refuted that conclusion, citing a 2016 study by a German marketing company that surveyed 675 Tesla owners. The survey found that 98% of respondents answered ""Yes"" when asked if they understood that when using Autopilot, they were expected to maintain control of the vehicle at all times.Tesla's website may also create confusion for some consumers. When you order a Model S sedan or Model X SUV, Tesla uses the following language to describe Autopilot's capabilities:""Your Tesla will match speed to traffic conditions, keep within a lane, automatically change lanes without requiring driver input, transition from one freeway to another, exit the freeway when your destination is near, self-park when near a parking spot and be summoned to and from your garage. That said, Enhanced Autopilot should still be considered a driver's assistance feature with the driver responsible for remaining in control of the car at all times.""In the following paragraph, the company writes, ""Tesla's Enhanced Autopilot software has begun rolling out and features will continue to be introduced as validation is completed, subject to regulatory approval.""A customer could read that description and believe Autopilot can control a significant portion of highway driving. But some of the listed features — like the ability to change lanes without driver input, transition from one freeway to another, and exit the freeway when a destination is near — are not included in Autopilot's current iteration. Instead, they're among that features Tesla plans to introduce in the future.A Tesla representative told Business Insider that its customers have not expressed confusion about the language on its website.Beneath the box that describes Autopilot's capabilities is one that gives customers the ability to purchase what Tesla calls ""Full Self-Driving Capability.""The company makes clear that it is only referring to hardware that will require a future software update to achieve full autonomy, but the fact that the company offers the hardware at all could lead customers to believe its vehicles are closer to the full autonomy than they may be and, by extension, ascribe more functionality to Autopilot than it currently has, Gene Munster, a managing partner at the venture capital firm Loup Ventures, told Business Insider.""It's as if it's almost ready to go, and that, I think, builds a little bit of false confidence in the current product,"" he said.The tension within the company's approach to selling Autopilot is most clear when its employees have demonstrated the feature.Munster said he's seen Tesla employees take their hands off the wheel during test drives, and Musk himself did so on multiple occasions during an appearance on CBS This Morning that aired in April.Early in the segment, Musk takes his hands off the wheel to point out how the vehicle alerts the driver when it senses no hands on the wheel, but Musk leaves his hands off the wheel after that, and can be seen with his hands off the wheel later in the segment.""There's the guy, the owner of the company, on TV driving the car with no hands on the wheel. The two messages don't go together,"" Moody said.As a pioneer of advanced driver assistance systems, Tesla is more likely to receive attention for an accident involving Autopilot than its competitors would be for their semi-autonomous systems. Even if the feature works as planned, a few high-profile incidents have the potential to create concerns about safety.During Tesla's first-quarter earnings call in May, CEO Elon Musk expressed frustration about the media attention Autopilot has received after high-profile accidents and said that it makes drivers less safe.""It's really incredibly irresponsible of any journalists with integrity to write an article that would lead people to believe that autonomy is less safe. Because people might actually turn it off, and then die,"" he said.While Tesla has made clear that Autopilot is not a substitute for an attentive driver, the company has said that the feature makes its vehicles safer. The company often cites two statistics to support that point, but the data may not tell the whole story.The first comes from a 2017 NHTSA report that examined crash rates before and after Autopilot became available, which Tesla has used to claim Autopilot reduced crash rates by as much as 40%. The report distinguishes between Tesla's automatic emergency braking features and Autopilot's semi-autonomous driver assistance features and considers Autopilot to consist of Autosteer, which keeps a car in its lane, and traffic-based speed adjustment.In May, NHTSA told Ars Technica that the study Tesla cited did not necessarily prove Autopilot reduced accident rates. The agency said that, while it compared accident rates before and after Autopilot's Autosteer became available, it didn't evaluate its ability to prevent accidents.Tesla declined to comment on the NHTSA's statement.Tesla has also said that vehicles equipped with Autopilot hardware are 3.7 times less likely to be involved in a fatal accident than other vehicles, implying that Autopilot is a decisive factor in that difference. But it's unclear if the company was able to separate incidents in which Autopilot was engaged from those in which it wasn't.Tesla did not respond when asked about the origins of the data which led to that statistic, but Musk said on Twitter Monday that Tesla vehicles were four times better than average based on automotive fatality data from NHTSA for 2017.Moody, though, said the statistics don't provide a complete picture of Autopilot's effect on vehicle safety.""This is an example of how facts don't really tell the whole story,"" Moody said. ""It is too early to say whether automated features, in general, truly have an impact on passenger safety.""Some of Tesla's competitors, like General Motors, Nissan, and Daimler, have also introduced driver assistance features with similar capabilities, but others are nervous about including semi-autonomous systems in their vehicles because they fear drivers will place too much trust in them and fail to pay attention to the road.In Tesla's case, that trust comes from the company's success in developing effective, semi-autonomous features.""The technology is so good, it's natural that people jump to conclusions or trust it more than they should,"" Munster said.To combat this concern, Cadillac's Super Cruise feature, which was introduced in 2017, can track a driver's eyes to determine if the driver is alert. If the system senses that the driver is not engaged, it will send the driver multiple warnings and, if necessary, pull the car over to the side of the road.Autopilot will also warn the driver — and eventually deactivate until the car is parked — if it doesn't detect a sufficient amount of torque on the wheel, but multiple Tesla owners have demonstrated ways to trick the sensors by placing objects, like an orange, between the wheel's upper and middle sections.Tesla has no trouble selling its cars. They're stylish, win awards, have consistently high customer satisfaction ratings, and are unveiled at events that no other automaker can match. But with debt concerns, a straining relationship with Wall Street analysts, and a history of failing to meet production goals for its mass-market Model 3 sedan, Tesla doesn't need another problem on its plate.The best approach to promoting Autopilot, then, may be a conservative one, Moody said.""There may be wisdom in sometimes taking a cautious approach.""Get the latest Tesla stock price here."
https://www.leiphone.com/news/201808/mKMqPgiiDdEead6Q.html,0经过长时间的努力，特斯拉 Model 3 的生产终于转入正轨。不过，喜欢“折腾”的特斯拉 CEO Elon Musk 可不会消停下来，他还要带领这家“非主流”汽车公司对车辆关键功能进行升级，如将 Autopilot 现在依靠的 GPU 换成自家独立开发的 AI 芯片。也就是说，未来新版本的 Autopilot 需要更为强悍的计算性能。不过，有分析师却认为，老进行跨越式发展且欠了一屁股债的特斯拉会背上巨大的财务和技术风险。据雷锋网了解，特斯拉计划替换现在的英伟达 GPU，用内部开发的 ASIC 神经网络加速器来驱动 Autopilot 算法。业内人士认为，特斯拉在这里下了赌注，相信专用的 AI 芯片比通用 GPU 更为高效。这个所谓的 AI 芯片是 Musk 在 8 月 1 号的财报电话会议上自己透露的。“过去两三年里，我们一直在低调研发。现在我觉得是时候让这款产品曝光了，毕竟它早晚都要问世的。”Musk 说。除了证实了这块 AI 芯片的存在，Musk 还非常严肃的宣称这款芯片有“非常惊人”的性能。Musk 表示，“这是市场上针对自动驾驶最先进的芯片。”市场观察者却表示，Musk 和他的芯片设计团队几乎没公布什么细节，但却敢说这款历时三年研发的 AI 芯片性能是英伟达 GPU 的 10 倍。“硬件升级并不能自动提升 Autopilot 的性能，它还需要相关软件升级来辅助。”VSI Labs 分析师 Phil Magney 解释。“它给特斯拉未来推进软件升级留了充足空间，毕竟超强的计算能力也是一大优势。”Magney 和其它观察者则认为 Musk 又偷换概念了，他拿来和自家 AI 芯片作比较的是老款英伟达 GPU，新款 Xavier SoC 性能早已不可同日而语了。Musk 还指出，“从根本上来讲，GPU 带来的只是个模拟模式，它的瓶颈非常明显。GPU 和 CPU 之间的传输最终会成为系统的紧箍咒。”业内专家则指出，现在的特斯拉架构并没有给英伟达 NVLink Fabric 留位置，而这套全新的高速 GPU 互联系统能让处理期间数据传输速度提升 12 倍。VSL Labs 表示，除了英伟达，Autopilot 2.0 还使用了来自三星（DRAM），Marvell（以太网交换器）和英飞凌（微控器）等供应商的零配件。Ingineerix（专业拆车网站）将 Model 3“大卸八块”后还注意到了一块车身控制器，这块电路板上有许多分立元器件，还有特斯拉自己的 ASIC 和意法半导体的电源架构芯片。“通过一流的设计，特斯拉将车辆前部的保险丝盒与配电装置都换掉了。”Ingineerix 解释。除了备受外界关注的 Autopilot 系统，Model 3 还有许多引人注目的升级。一些升级由内部芯片开发推动，而其他的则是一些标准功能的改进，比如特斯拉独创的气流系统。新的采暖通风与空调系统让特斯拉工程师省掉了机械式的通风口，将车内空间最大化。除了新型气流系统，特斯拉的空气过滤系统也是业内一绝。与此同时，Model 3 上让对手“嫉妒”的电池管理系统也用上了特斯拉自行开发的 ASIC 和其它自主专利。在对 Model 3 的 80kWh 电池组进行分析后，一位工程师惊呼这设计实在是“太牛了”。在内部设计方面，据雷锋网了解：Model 3 也是业界顶尖水平，最近就有消息称沃尔沃已经运了一辆 Model 3 回去拆解研究。林利集团资深分析师 Mike Demler 则认为特斯拉冒着大风险从零开始研发 AI 芯片，从经济角度来看根本是毫无意义。他和一些分析师甚至怀疑这款耗资甚巨的芯片从一开始就没有理由立项，毕竟 Mobileye 和英伟达的产品已经足够强大。Demler 怀疑特斯拉的工程师更倾向于“封闭系统”，而且他们想自己扼住命运的咽喉。“Elon Musk 嫉妒乔布斯。”他补充。Demler 坚持认为，将大量资源投入神经网络加速器的研发肯定是被误导了。在他看来，车载电子领域真正的创新其实在于软件。“传感器、传感器融合和智能确实很重要。”Demler 在 Musk 发推文称要私有化特斯拉后表示。“特斯拉到底能做出什么成绩恐怕过一段时间才会见分晓，但它搞出革命性产品的机会不大。”毕竟与英伟达和 Mobileye 这样的业内翘楚相比，特斯拉还太年轻，而且别忘了老巨头们走的可都是平台化道路。观察者也同意一点，那就是安全的 Autopilot 要为感知和认知提供强大的处理能力，也就是说它要借算法理解道路规则和指令。“我们不该再想自动驾驶汽车了，自动驾驶模式反而更为重要，就先自适应巡航这样的用例。”Demler 解释。据雷锋网(公众号：雷锋网)了解：特斯拉在 ASIC 上的战略还在为人所诟病，特别是在开发费用高企的情况下。虽然 ASIC 会卡住架构升级的空间，但 Phil Magney 认为其架构依然比 GPU 高效。原因之一就是 ASIC“会专为特殊应用做优化。”Model 3 上最典型的应用就是基于 AI 的推理模型。“英伟达的 SoC 确实能出色的服务许多需要大量并行指令的应用。”Magney 说道。Demler 也看好特斯拉对电动车行业的引领作用，特别是它在电池研发上的优势。“这是它的关键创新。”他说道。Ingineerix 对 Model 3 能量转换系统的拆解还显示，这套安装在后座下的 12V 组件其实是车载交流转直流充电器，同时它还是一台直流换流器。整个组件都安装在一块大的 PC 板上，而这块板上用到 Model 3 上唯一的保险丝。这些能量管理部件是特斯拉实现车辆长续航的关键，跨不过 300 英里这个硬性指标，电动车就难以进入主流市场。下面，我们会分享特斯拉 Model 3 中用到的一些关键部件：Autopilot 2.0 硬件架构电池管理系统（BMS）电路板能量转换系统车体前部控制器Model 3 空调系统雷锋网原创文章，未经授权禁止转载。详情见转载须知。编辑Copyright © 2011-2018 www.leiphone.com 雷锋网-移动互联网智能终端第一媒体 All Rights Reserved 粤ICP备11095991号-1    ICP证粤B2-20150332
https://www.golem.de/news/tesla-vor-mercedes-und-bmw-nicht-alle-fahrassistenzsysteme-sind-gleich-gut-1808-135960.html,"Nach tödlichen Unfällen mit Teslas ""Autopilot"" stellt sich manchen die Frage nach der Sicherheit von Assistenzsystemen. In einer US-Studie schneidet vor allem ein Modell gut ab. Doch die Tester haben offenbar etwas Wichtiges übersehen.Wie sicher sind die fortgeschrittenen Fahrassistenzsysteme in Modellen der Oberklasse? Ein Test des unabhängigen Insurance Institute for Highway Safety (IIHS) in den USA hat ergeben, dass nicht alle getesteten Modelle die Erwartungen gleichermaßen erfüllen. Das gelte sowohl für sogenannte Abstandsregeltempomaten als auch für aktive Spurhalteassistenten. Allerdings scheinen die Tester nicht berücksichtigt zu haben, dass beispielsweise die Mercedes-Modelle manche Funktion bewusst einschränken.Das IIHS untersuchte für den Test einen 5er BMW, eine Mercedes E-Klasse, einen Volvo S90 sowie die Tesla-Modelle S und 3. Allerdings verfügte das Model S nur über die Autopilot-Version 7.1, während das neuere Model 3 die verbesserte Version 8.1 nutzte.Recht zuverlässig funktionieren die Abstandregeltempomaten. Hierbei sollten die Autos in vier verschiedenen Situationen sicher zum Stehen kommen, wenn in der eigenen Spur das vorausfahrende Fahrzeug plötzlich bremst oder ein stehendes Auto auftaucht. Lediglich die Tesla-Modelle seien beim Test auf stehende Autos aufgefahren. Der Volvo S90 habe im Gegensatz zu den anderen Modellen deutlich schärfer gebremst. Hier sei kein Unterschied zur Verzögerung beim Notbremssystem festzustellen.Außerhalb der Testumgebung, auf öffentlichen Straßen, stellten die Tester dem Bericht zufolge jedoch mehr Probleme fest. So registrierte eine E-Klasse nur kurzzeitig einen wartenden Pickup vor einer Ampel, verlor das Fahrzeug aber wieder und beschleunigte, anstatt zu bremsen. Lediglich beim Model 3 habe es solche Probleme nicht gegeben. Allerdings sei dieses Fahrzeug durch übervorsichtiges Verhalten aufgefallen. So habe es auf den knapp 290 Testkilometern zwölf Mal unerwartet gebremst. Sieben Mal davon wegen der Schatten von Bäumen auf den Straßen.Mit Abstand am besten schnitt das Model 3 hingegen beim Spurhalteassistenten ab, gefolgt von der Mercedes E-Klasse. Häufig überquerten hingegen der BMW, der Volvo und das Model S die Fahrbahnmarkierungen. Dabei fuhr das Model S sogar einmal in einer Kurve über den inneren Fahrbahnrand.Inwieweit diese Ergebnisse aber vergleichbar sind, geht aus dem Bericht nicht hervor. So schränkt Mercedes beispielsweise den Spurhalteassistenten bei seinen Modellen derzeit auf eine Querbeschleunigung von 3 m/s2 ein. Das schreibt eine entsprechende UN-ECE-Regelung für teilautomatisierte Systeme vor. Je nach Kurvenradius und Geschwindigkeit muss der Fahrer daher eingreifen, weil das Auto nicht genügend lenken kann. Bei einem Test im Oktober 2016 war Golem.de aufgefallen, dass das damalige Model S selbst bei engeren Kurven auf Landstraßen die Spur einhalten kann und sich das System nicht abschaltet.Das IIHS testete zudem das Verhalten der Fahrzeuge auf einer hügeligen Teststrecke. Hierbei wird die Reichweite der Kameras zur Erkennung der Fahrbahnmarkierungen durch Straßenkuppen eingeschränkt. Recht souverän meisterten das Model 3 und die E-Klasse diese Situationen. Der BMW scheiterte den Angaben zufolge hingegen in allen 14 Versuchen. Das Model S hatte ebenfalls große Probleme und eierte nach dem Überschreiten der Kuppe auf der Fahrbahn herum, bis schließlich eine Markierung gefunden wurde. Immerhin 9 von 16 Strecken schaffte der Volvo.Die Ent­schei­dung ist ge­fal­len: Ein neu­es Fahr­zeug muss her. Wäh­rend Sie ge­dank­lich schon mit den Fin­gern über die Le­der­sit­ze strei­fen, war­tet in den meis­ten Fäl­len noch ein Be­such bei der Zu­las­sungs­stel­le auf Sie. » MehrDas IIHS arbeitet nach eigenen Angaben an einem Bewertungssystem, mit dem Verbraucher die Fahrassistenzsysteme einschätzen können. Derzeit will Cheftester David Zuby aber noch kein Urteil darüber abgeben, welches System am sichersten ist. Die Hersteller befänden sich in einem Dilemma. ""Limitieren sie die Funktionen, damit die Fahrer weiter aktiv mitwirken, riskieren sie den Nachteil, dass die Systeme zu primitiv bleiben. Wenn die Systeme hingegen zu gut sind, dann überwachen die Fahrer sie nicht aufmerksam genug, um sie sicher nutzen zu können"", sagte Zuby. Ein wirklich selbstfahrendes Autos werde es aber für etliche Zeit noch nicht beim Händler geben.Tesla will Autobahnen rauf- und runterfahrenWie Studenten autonome Autos schlau machenInvestoren klagen wegen Musks Aussagen zu TeslaTesla will Sicherheitssoftware freigebenTeslas Autopilot beschleunigte vor tödlicher KollisionDas brauche ich nicht. Ich will ja dein Weltbild nicht zerstören, aber so funktioniert...Das ist so, richtig. Ist eine Sicherheitsfunktion - Du als Fahrer gibst den Befehl zum...Blöde Frage: Fährst du die Autos immer im Sport-Setup oder minimaler...Ne, voll ins Schwarze ;)Funktioniert auch auf der Autobahn. Man merkt, ob man 80, 100 oder 120 fährt. Wenn man...KommentierenGolem.de Redakteur Moritz Tremmel erklärt im Interview die Gefahren der Übernahme von Subdomains.Es könnte alles so schön sein abseits vom klassischen Fernsehen. Netflix und Amazon Prime bieten modernes Encoding, 4K-Auflösung, HDR-Farben und -Lichter, flüssige Kamerafahrten wie im Kino - leider nur in der Theorie, denn sie bringen es nicht zum Kunden. Ein IMHO von Michael WieczorekMit den Simpsons ist er selbst Kult geworden, und Nachfolger Futurama hat nicht nur Sci-Fi-Nerds mit einem Auge für verschlüsselte Gags im Bildhintergrund begeistert. Bei Netflix folgt nun Matt Groenings Cartoonserie Disenchantment, die uns trotz liebenswerter Hauptfiguren in Märchenkulissen allerdings nicht ganz zu verzaubern weiß. Eine Rezension von Daniel PookFür Workstations: AMDs Threadripper 2990WX mit 32 Kernen schlägt Intels ähnlich teure 18-Core-CPU klar und der günstigere Threadripper 2950X hält noch mit. Für das Ryzen-Topmodell muss aber die Software angepasst sein und sie darf nicht zu viel Datentransferrate benötigen. Ein Test von Marc Sauter© 1997—2018 Golem.de. Alle Rechte vorbehalten."
https://www.theverge.com/2018/6/5/17431484/tesla-autopilot-free-trial-elon-musk-purchase,"Tesla owners without Autopilot may get an unexpected chance to try out the company’s self-driving system. At a shareholder meeting today, Elon Musk announced plans for a free trial of Autopilot to be released “within the next couple months.” He did not elaborate on terms or length of the trial. Enhanced Autopilot costs an additional $5,000 at purchase in the current generation of Teslas, or an additional $1,000 if it’s purchased after the car itself.Tesla’s Autopilot is still under active development, and Musk promised significant improvements in a new version to be rolled out to drivers this month, with even more significant updates in the months to come. “The reliability and capability of Autopilot will increase exponentially over the next six to twelve months,” Musk predicted. “The improvements are very rapid.”Tesla’s Autopilot has come under fire in recent months after a fatal crash in March, in which a driver crashed headfirst into a safety barrier on Highway 101. Tesla has pledged to regularly release safety data as the Autopilot system develops, moving towards the goal of a fully autonomous fleet by the end of 2019.Command Line delivers daily updates from the near-future."
https://www.wired.com/story/thatcham-autopilot-grading-semi-autonomous/,"YOU CAN'T BUY an autonomous car today. You won't be able to buy one tomorrow, or next month, or next year. Yes, self-driving tech is in development (and in the news), but nobody's close to delivering a product that can take humans anywhere they want to go. Not even Tesla.That may come as a surprise if you’ve browsed websites or glossy marketing materials filled with claims of cars driving themselves, relieving the driver of the mundane tasks of steering and braking. Or if you've heard Tesla CEO Elon Musk promise that with Version 9 of Tesla's software, ""We will begin to enable full self-driving features."" Or if you've seen recent news stories about a spate of crashes among cars using semi-autonomous features, some of them deadly.It's that kind of surprise that's worrying the folks at the UK's Thatcham Research, an influential nonprofit that assesses vehicle safety, similar to the IIHS in the US. With a new paper, “Assisted and Automated Driving Definition and Assessment,” Thatcham is urging carmakers to be more transparent about what their systems can and can’t do. And it's making moves to prod them into doing so.This summer, Thatcham will begin rating driver-assistance features like Tesla's Autopilot. It will study how well they function and which situations give them trouble. But it will also consider how clearly they indicate when they're active, how they monitor their human drivers, and how they are marketed. “It’s the Wild West out there, so we’re saying, let’s get some rules around this, because people’s lives are at stake,” says Matthew Avery, Thatcham's head of research.This is more than just hand-wringing. Thatcham's rankings have teeth, with manufacturers pushing hard to meet its standards and earn the highest safety marks. Ratings influence consumer buying choices and the premiums that insurers charge. A bad rating can make a car much less attractive to buy.Part of the problem, Thatcham says, is that these features come with names that don't make clear what they are or what they do. Tesla calls its system Autopilot. Nissan offers ProPilot Assist, Mercedes has Drive Pilot. Audi is gearing up to launch Traffic Jam Pilot (just not in the US). Cadillac has Super Cruise, BMW has Active Driving Assistant, and Volvo offers Adaptive Cruise Control with Steer Assist.Tesla’s branding may be the catchiest, but Volvo’s is the most accurate, or at least the most understandable. That's why Thatcham will start judging automakers on whether their system names are likely to confuse drivers. Those using “pilot,” which implies control, will get marked down. Those with “assist” will likely get a higher grade. They remind drivers that these systems are a helping hand, not an excuse to browse Instagram.Elon Musk has said that among his customers who crashed while using Autopilot, confusion is less of a problem than complacency: Over time, they put too much trust in a system that needs their supervision—because it can't, for example, spot a stopped fire truck. Avery says that’s probably not the whole picture. “There may also be customers who genuinely think the car is more capable than it actually is, and that’s the scary thing.” He says he wants manufacturers to “come clean” and sell their tech as assisted driving, rather than oversell it as any kind of autonomy.Facing scrutiny of Autopilot, Tesla has always pointed out that its system requires the driver to accept that it’s in beta and agree to stay in control with an onscreen checkbox. It also gives a warning to “keep your hands on the wheel” every time it’s engaged. Over the past week, the company has started rolling out an over-the-air software update, reducing to 30 seconds (from three or four minutes previously) the length of time a driver can take their hands off the wheel before a warning pops up. When a driver complained on Twitter that the change makes the system annoying to use, Musk replied, “This is crux of matter: can’t make system too annoying or people won’t use it, negatively affecting safety, but also can’t allow people to get too complacent or safety again suffers.” (Tesla has long touted Autopilot as a safety feature, but no one has produced independent research showing the system saves lives.)Thatcham says that many of these systems do make driving safer by limiting driver fatigue and reducing rear-end collisions. “We want people to use these systems, because we think they’re a safety benefit,” Avery says. But they need to understand what they’re using, how it works, and when it doesn't.The Human Support Robot from Toyota is an advanced robot that’s been helping a paralyzed war vet at home.CNMN Collection© 2018 Condé Nast. All rights reserved.Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/25/18) and Privacy Policy and Cookie Statement (updated 5/25/18). Your California Privacy Rights. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices."
https://www.reuters.com/article/us-tesla-stocks/teslas-autopilot-to-get-full-self-driving-feature-in-august-idUSKBN1J71YY,"Reuters Staff3 MIN READ(Reuters) - Shares of Tesla Inc (TSLA.O) rose as much as 5 percent on Monday after Chief Executive Officer Elon Musk tweeted that its Autopilot driver assistance system will get full self-driving features following a software upgrade in August.Autopilot, a form of advanced cruise control, handles some driving tasks and warns those behind the wheel they are always responsible for the vehicle’s safe operation. But a spate of recent crashes has brought the system under regulatory scrutiny.""To date, Autopilot resources have rightly focused entirely on safety. With V9, we will begin to enable full self-driving features,"" Musk tweeted here on Sunday, replying to a Twitter user.Musk said the autopilot issue during lane-merging is better in the current software and will be fully fixed in the August update.However, it was not clear what self-driving features would be included in the August update.Tesla has been gradually upgrading its Autopilot features with regular software updates.Tesla’s documentation on its website about the “full self-driving capabilities” package says that it is not possible to know exactly when each element of the functionality will be available, as this is highly dependent on local regulatory approval.A consumer advocacy group on Friday urged Tesla to fix what it termed as “flaws” in Autopilot after a preliminary government report said a Model X driver did not have his hands on the vehicle’s steering wheel in the final six seconds before a fatal crash on March 23.“The software update is good news,” said analyst Chaim Siegel from Elazar Advisors, adding the stock was still benefiting from last week’s prediction by Musk that it would finally hit its production target for its Model 3 sedan.Tesla’s shares were last up 3.3 percent at $327.93 on Monday after touching a high of $333.The company’s future profitability hinges on ramping up Model 3 output, and the company has suffered from a series of failures to hit its weekly target.General Motors Co (GM.N) said last week that its driver assistance feature, Super Cruise, will allow drivers to take their hands off the steering wheel for extended periods, but will stop the vehicle automatically if drivers are not attentive.GM had said it will expand the roll-out of Super Cruise to all its Cadillac models beginning 2020.Reporting by Sonam Rai and Arjun Panchadar in Bengaluru; Editing by Saumyadeb Chakrabarty and Maju SamuelSPONSOREDSPONSOREDAll quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.© 2018 Reuters. All Rights Reserved."
https://www.businessinsider.com/what-its-like-to-try-teslas-autopilot-2018-7,"As the auto industry moves toward self-driving vehicles, it finds itself in an uncomfortable position. Today's consumer cars can't drive themselves — and aren't close. But they can give drivers enough assistance that some become too comfortable and overestimate their car's autonomous driving capabilities.Tesla's Autopilot was a pioneer among semi-autonomous systems. In its current iteration, it can keep a car in its lane and adjust its speed based on surrounding traffic, among other features, but it has attracted controversy due to a series of high-profile accidents.Tesla has pointed to statistics that link Autopilot with lower accident and fatality rates and said it has made clear to customers that they must be alert when using the system. Critics say Tesla's favorite statistics don't isolate Autopilot's effect on safety and argue that, despite Tesla's warnings, the system breeds complacency in drivers who eventually place too much faith in it.In June, I tried Autopilot and drove a Model 3 for the first time on crowded, New York City streets. I spent under 30 minutes with the feature in a single environment, so I wasn't able to come to a definitive conclusion about how effective it is, but in my brief time with the feature, I got a sense of how it can be useful in heavy traffic, and how even limited, semi-autonomous driving systems represent a big shift in automotive technology.Here's what happened when I drove a Model 3 and tried Autopilot for the first time.Regenerative braking is unique to electric vehicles. After the driver's foot is taken off the accelerator, regenerative braking slows a car down more quickly than a gas-powered car would. This means that, in some instances, the driver won't have to switch between the accelerator and brake pedals in heavy traffic. Instead, the driver can just use the accelerator pedal.I had to override all of my driving instincts to let a car handle any driving functions beyond speed regulation. It was difficult to understand how drivers could eventually feel comfortable taking their hands off the wheel or eyes off the road for significant amounts of time, but I also have no sense of how my comfort with the feature would change over time.In my time with Autopilot, I saw it stop, start, and make gentle turns without my input, and I realized how it could ease some of the foot and ankle fatigue driving on crowded streets can cause.While I wasn't able to test Autopilot on a highway to see how it would handle high speeds and long distances, I got a sense of how the first steps toward autonomy can make some of the least complicated and most irritating parts of driving easier.Get the latest Tesla stock price here."
https://www.cnbc.com/2018/06/07/driver-in-fatal-tesla-autopilot-crash-did-not-have-hands-on-wheel-u-s-agency-says.html,"The driver killed while operating a Tesla on Autopilot in March may not have his hands on the steering wheel just before the crash, the National Transportation Safety Board said in a preliminary report Thursday.The report indicates what happened in the minutes and seconds before a 38-year-old man slammed a Tesla Model X into the crash cushion at the end of a freeway median and collided with two other vehicles in Mountain View, California. Up to the time of the accident, the driver was operating the car using Tesla's advanced driver assistance system, Autopilot.The system has been investigated by federal agencies for previous crashes.The vehicle warned the driver with two visual alerts and one sound alert telling him to place his hands on the wheel more than 15 minutes prior to the crash, the NTSB said. The driver placed his hands on the wheel three times in the minute before the accident, for a total of 34 seconds. In the final six seconds, the system did not sense he had his hands at the wheel.At six seconds prior to the crash, the car sped up from 62 miles per hour to 70.8 mph, the agency said.A Tesla spokesperson referred CNBC back to Tesla's blog on the accident, and declined to comment further.""The reason this crash was so severe is because the crash attenuator, a highway safety barrier which is designed to reduce the impact into a concrete lane divider, had been crushed in a prior accident without being replaced,"" the blog said. ""We have never seen this level of damage to a Model X in any other crash.""CORRECTION: This story was revised to correct that the NTSB's preliminary report said Tesla's Autopilot did not detect driver's hands on the steering wheel just before the fatal crash. A previous version misstated the timing.Got a confidential news tip? We want to hear from you.Sign up for free newsletters and get more CNBC delivered to your inboxGet this delivered to your inbox, and more info about our products and services. Privacy Policy.© 2018 CNBC LLC. All Rights Reserved. A Division of NBCUniversalData is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.Data also provided by"
https://www.theguardian.com/technology/2018/mar/31/tesla-car-crash-autopilot-mountain-view,"Guardian staff and agenciesSat 31 Mar 2018 19.40 BST First published on Sat 31 Mar 2018Tesla has said a car that crashed in California last week, killing its driver, was operating on Autopilot.The 23 March crash on highway 101 in Mountain View is the latest accident to involve self-driving technology. Earlier this month, a self-driving Volvo SUV that was being tested by the ride-hailing service Uber struck and killed a pedestrian in Arizona.Federal investigators are looking into the California crash, as well a crash in January of a Tesla Model S that may have been operating under the Autopilot system.In a blogpost, Tesla said the driver of the sport-utility Model X that crashed in Mountain View, 38-year-old Apple software engineer Wei Huang, “had received several visual and one audible hands-on warning earlier in the drive and the driver’s hands were not detected on the wheel for six seconds prior to the collision.“The driver had about five seconds and 150 meters of unobstructed view of the concrete divider … but the vehicle logs show that no action was taken.”Tesla also said the concrete highway divider had previously been damaged, increasing its impact on the car. The vehicle also caught fire, though Tesla said no one was in the vehicle when that happened.The company said its Autopilot feature can keep speed, change lanes and self-park but requires drivers to keep their eyes on the road and hands on the wheel, in order to be able to take control and avoid accidents.Autopilot does not prevent all accidents, Tesla said, but it does make them less likely.“No one knows about the accidents that didn’t happen,” Tesla said, “only the ones that did. The consequences of the public not using Autopilot, because of an inaccurate belief that it is less safe, would be extremely severe.“There are about 1.25 million automotive deaths worldwide. If the current safety level of a Tesla vehicle were to be applied, it would mean about 900,000 lives saved per year.”The company added that it “care[s] deeply for and feel[s] indebted to those who chose to put their trust in us. However, we must also care about people now and in the future whose lives may be saved if they know that Autopilot improves safety.“None of this changes how devastating an event like this is or how much we feel for our customer’s family and friends. We are incredibly sorry for their loss.”… we have a small favour to ask. The Guardian is editorially independent, meaning we set our own agenda. Our journalism is free from commercial bias and not influenced by billionaire owners, politicians or shareholders. No one edits our Editor. No one steers our opinion. This is important because it enables us to give a voice to the voiceless, challenge the powerful and hold them to account. It’s what makes us different to so many others in the media, at a time when factual, honest reporting is critical.More people are reading the Guardian’s independent, investigative journalism than ever but advertising revenues across the media are falling fast. And unlike many news organisations, we haven’t put up a paywall – we want to keep our journalism as open as we can. So you can see why we need to ask for your help.If everyone who reads our reporting, who likes it, helps to support it, our future would be much more secure. For as little as $1, you can support the Guardian – and it only takes a minute. Thank you."
https://electrek.co/2018/06/18/what-tesla-autopilot-see-understand/,"JUNE 18Fred Lambert- Jun. 18th 2018 6:16 am ET@FredericLambertWe previously reported about what Tesla’s Autopilot can see with its suite of 8 cameras around the car, but we rarely got into how the Autopilot understands and interprets what it is looking at through its computer vision system.That’s changing today after a few hackers were able to overlay Autopilot data on top of snapshots of what the system is seeing.As with our previous looks at what Autopilot can see, it’s thanks to our favorite Tesla hacker ‘verygreen’ who has been able to intercept the data that Tesla gathers from his own vehicle.With the help of a few other Tesla hackers, they were able to overlay the data with the snapshots of what the vehicle can see, which results in an interesting visualization of what Autopilot understands when looking through its sensors.It’s not a complete look at what Autopilot can see. For example, it doesn’t include the tracking of the lanes.But it does show how the system is tracking objects in its field of view and a way that we have never seen before.verygreen sent us some pictures and videos along with an interesting explanation of what they managed to do.Here it is in his own words:Would not it be great if Tesla published videos about how their cars see things, in a fashion similar to what Google does? Well, they don’t and so the exercise is left to hackers to try and piece things together.Even though my unicorn car with hacked autopilot board is long lost, I still have a whole bunch of snapshots from those days. I am sure you have seen the picture. But what’s not widely known is that alongside those pictures, radar data was included too. Now TMC user DamianXVI (the same guy that wrote color interpolator for originally black and white images) came up with a way to overlay the radar data on the pictures.It looks like this:Now a bit of an explanation about what the circles mean: circle color represents the type of the object:The circle size represents the distance to the object, the bigger the circle, the closer is the object (so we are not trying to encircle object, or approximate the size – the radar has no way of knowing this).A thick circle means this object has a label and is therefore likely being tracked by the autopilot. Fading in and out is due to the probability of existence changing.Sometimes the circle is in some empty space – this is likely due to radar having some problems with determining object elevation, try to look higher or lower for a relevant object. Also at times, radar cannot determine elevation at all (value of -5 is used in that case). The circle is drawn at elevation 0 in this case.Also keep in mind that the radar reports coordinates in 3D and we need to project them onto a 2D picture. Sometimes there are errors in such conversions as you might expect.Here’s a video with the radar data overlaid:Now for new exciting development. While the unicorn is gone, I came upon a stash of video and picture snapshots that you have not seen before.Here’s a video from sometime in October 2017 with radar data overlaid from that stash:But that’s not all, the stash also includes pretty recent snapshots from March 2018 where Tesla was apparently debugging radar-vision fusion implementation of depth perception.Every one of these pictures (captured by firmware 2018.10.4) below came with a detailed list of objects autopilot sees and tracks. It reports things like the dimensions, relative velocity, confidence that the actual object exists, the probability that the object would be an obstacle and so on.Now this last one is interesting in that the autopilot is clearly recognizing and tracking a stopped work truck, it even assigned a 25% obstacle rating to it (not the poor worker, though). This should put to rest the theory that the stopped vehicles are not seen (now autopilot might see and ignore them – but that’s whole other topic).Another interesting observation you can see is from second and third pictures – they depict the same scene taken with the narrow and main cameras. What’s interesting in there is that apparently only main (more wide-angled) camera is used to detect oncoming traffic.These bounding boxes also validate a lot of the theories about vision NN outputs that TMC user jimmy_d presented in a forum post here.Of course, this does not represent the full autopilot internal state, we don’t see the detected/tracked lanes or information gleaned from maps but it gives us another glimpse behind the curtain.Tesla is a transportation and energy company. It sells vehicles under its 'Tesla Motors' division and stationary battery pack for home, commercial and utility-scale projects under its 'Tesla Energy' division.The Autopilot is Tesla's advanced assisted driving program with features like Autosteer, Autopark, and Trafic-Aware Cruise Control (TACC).@FredericLambertFred is the Editor in Chief and Main Writer at Electrek.You can send tips on Twitter (DMs open) or via email: fred@9to5mac.comIf you want to help Fred and Electrek, you can contribute to our Patreon: https://www.patreon.com/electrekElectrek Podcast: Tesla craziness intensifies, base Mod...Tesla could make a $25,000 electric car in ‘about..."
https://www.bloomberg.com/news/articles/2018-05-03/musk-has-a-plan-to-end-the-autopilot-safety-debate,"Your usage has been flagged as a violation of our terms of service.For inquiries related to this message please contact support. For sales inquiries, please visit http://www.bloomberg.com/professional/request-demo"
https://www.wired.com/story/tesla-autopilot-safety-statistics/,"FOR MORE THAN a year, Tesla has defended its semiautonomous Autopilot as a vital, life-saving feature. CEO Elon Musk has lambasted journalists who write about crashes involving the system. “It's really incredibly irresponsible of any journalists with integrity to write an article that would lead people to believe that autonomy is less safe,” he said during a tumultuous earnings call this week. “Because people might actually turn it off, and then die.”This wasn’t the first time Musk has made this argument about Autopilot, which keeps the car in its lane and a safe distance from other vehicles but requires constant human oversight, and has been involved in two fatal crashes in the US. “Writing an article that’s negative, you’re effectively dissuading people from using autonomous vehicles, you’re killing people,” he said on an October 2016 conference call.Wednesday’s haranguing, however, came a few hours after the National Highway Traffic Safety Administration (NHTSA) indicated that Tesla has been misconstruing the key statistic it uses to defend its technology. Over the past year and a half, Tesla spokespeople have repeatedly said that the agency has found Autopilot to reduce crash rates by 40 percent. They repeated it most recently after the death of a Northern California man whose Model X crashed into a highway safety barrier while in Autopilot mode in March.Now NHTSA says that’s not exactly right—and there’s no clear evidence for how safe the pseudo-self-driving feature actually is.The remarkable stat comes from a January 2017 report that summarized NHTSA’s investigation into the death of Joshua Brown, whose Model S crashed into a truck turning across its path while in Autopilot mode. According to its data, model year 2014 through 2016 Teslas saw 1.3 airbag deployments per million miles, before Tesla made Autopilot available via an over-the-air software update. Afterward, the rate was 0.8 per million miles. “The data show that the Tesla vehicles' crash rate dropped by almost 40 percent after Autosteer installation,” the investigators concluded.Just a few problems. First, as reported by Reuters and confirmed to WIRED, NHTSA has reiterated that its data came from Tesla, and has not been verified by an independent party (as it noted in a footnote in the report). Second, it says its investigators did not consider whether the driver was using Autopilot at the time of each crash. (Reminder: Drivers are only supposed to use Autopilot in very specific contexts.) And third, airbag deployments are an inexact proxy for crashes. Especially considering that in the death that triggered the investigation, the airbags did not deploy.Tesla declined to comment on NHTSA’s clarification.The statistic has been the subject of controversy for some time. The research firm Quality Control Systems Corp. has filed a Freedom of Information Act lawsuit against NHTSA for the underlying data in that 2017 report, which it hopes to use to determine whether the 40 percent figure is valid. NHTSA has thus far denied its FOIA requests, saying it agreed to Tesla’s requests to keep the data confidential, and that its release could threaten the carmakers’ competitiveness.Tesla’s oft-touted figure is flawed for another reason, experts say: With this data set, you can’t separate the role of Autopilot from that of automatic emergency braking, which Tesla began releasing just a few months before Autopilot. According to the Insurance Institute for Highway Safety, vehicles that can detect imminent collisions and hit the brakes on their own suffer half as many rear-end crashes as those that can’t. (More than 99 percent of cars Tesla produced in 2017 came equipped with the feature standard, a higher proportion than any other carmaker.)Which is all to say, determining whether a new feature like Autopilot is safe, especially if you don’t have access to lots of replicable, third-party data, is super, super hard. Tesla’s beloved 40 percent figure comes with so many caveats, it’s unreliable.The Insurance Institute for Highway Safety has tried to come at the question another way, by looking at the frequency of insurance claims. When it tried to separate Model S sedan incidents after Autopilot was released, it observed no changes in the frequency of property damage and bodily injury liability claims. That indicates that Autopilot drivers aren’t more or less less likely to damage their cars or get hurt than others. But it did find a 13 percent reduction in collision claim frequency, indicating sedans with Autopilot enabled got into fewer crashes that resulted in collision claims to insurers.Oh, but it gets more complicated. IIHS couldn’t tell which crashes actually involved the use Autopilot, and not just sedans equipped with Autopilot. And it’s way too early for definitive answers. “Since other safety technologies are layered below Autopilot, it is difficult to tease out results for Autopilot alone at this time,” says Russ Rader, an IIHS spokesperson. “Data on insurance claims for the Model S are still thin.”Over at MIT, researchers frustrated with the dearth of good info on Autopilot and other semiautonomous car features have launched their own lines of inquiry. Human guinea pigs are now driving sensor- and camera-laden Teslas, Volvos, and Range Rovers around the Boston area. The researchers will use the data they generate to understand how safely humans operate those vehicles.The upshot is that Autopilot might, in fact, be saving a ton of lives. Or maybe not. We just don’t know. And Tesla hasn’t been transparent with its own numbers. “You would need a rigorous statistical analysis with clear data indicating what vehicle has it and what vehicle doesn’t and whether it’s enabled or whether it isn’t,” says David Friedman, a former NHTSA official who now directs car policy at Consumers Union. Tesla said this week that it would begin publishing quarterly Autopilot safety statistics, but did not indicate whether its data would be verified by a third party.NHTSA, too, could be doing a better at holding innovative but opaque carmakers like Tesla accountable for proving the safety of their new tech. “To me, they should be more transparent by asking Tesla for disengagements of the system: How often the systems disengaged, how often the humans need to take over,” Friedman says. California’s Department of Motor Vehicles requires companies testing autonomous vehicles in the state to provide annual data on disengagements, to help officials understand the limitations of the tech and its progress.Tesla is not alone among carmakers in trying to shield sensitive info from the public. But today, humans are deeply bewildered about the semiautonomous features that have already made their way into everyday drivers’ garages. Even Transportation Secretary Elaine Chao—you know, the public official charged with overseeing regulation on these things—is confused by the terminology. If there’s a time to get honest about your numbers, this could be it. You might save some lives. You’d definitely save a few headaches.Elon Musk wants you to take your hands off the wheel, foot off the gas, and let him do the driving. Rather, let his cars take over.CNMN Collection© 2018 Condé Nast. All rights reserved.Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/25/18) and Privacy Policy and Cookie Statement (updated 5/25/18). Your California Privacy Rights. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices."
https://www.businessinsider.com/tesla-autopilot-strategy-is-a-mistake-2018-4,"Tesla is in the middle of an unprecedented dispute with the National Transportation Safety Board, the government agency that usually investigates plane crashes and train wrecks but in the past two years has probed four accidents involving Tesla semi-self-driving technology, Autopilot.Two of these accidents have led to fatalities: the first was in Florida in 2016; and the second occurred last month in Northern California.Tesla had issued several statements and written two blog posts providing details about the California crash, stressing that the driver, Walter Huang, had ignored warnings to recover full control of his Model X SUV prior to colliding with a freeway divider in Mountain View.The NTSB rebuked Tesla for revealing information about the crash; Tesla CEO Elon Musk and the agency's chairman, Robert Sumwalt, then came to terms about how the investigation would move forward after a weekend call; but then a few days later Tesla exited from a ""party agreement"" with the NTSB, ending its formal partnership in the investigation while pledging to provide ongoing technical guidance.Bloomberg then reported that a second call between Musk and Sumwalt led to an NTSB decision to remove Tesla from the investigation, which the agency confirmed in a letter. A Tesla spokesperson disputed the Bloomberg source's characterization of the call but didn't comment on the sequence of events, which for the NTSB started on Wednesday and came to a head on Thursday.But Tesla then released a statement revealing that ""on Tuesday, we chose to withdraw from the agreement and issued a statement to correct misleading claims that had been made about Autopilot — claims which made it seem as though Autopilot creates safety problems when the opposite is true.""The carmaker then highlighted statistics about Autopilot's safety record. But the statement suggested that Tesla had intentionally flouted the NTSB's rules to end its party agreement. The company also complained that the NTSB wasn't abiding by it protocols and was releasing its own information to the public, seeking headlines. Tesla said that it was going to complain to Congress.The NTSB declined to comment on Tesla's statement.But for the record, the NTSB is far from an unqualified fan of Autopilot, which is actually two different systems: advanced adaptive cruise control; and Autosteer, the feature that allows drivers to take their hands off the wheel.In Tesla's previous fatal Autopilot crash, NTSB investigators concluded that the driver's ""pattern of use of the Autopilot system indicated an over-reliance on the automation and a lack of understanding of the system limitations.""The NTSB also concluded that if vehicles don't restrict risky operations, the potential for drivers to misuse them remain; and that the way Autopilot ""monitored and responded to the driver's interaction with the steering wheel was not an effective method of ensuring driver engagement.""Autopilot is actually not Tesla's biggest headache at the moment — sluggish production of the Model 3 sedan is. But Autopilot is turning into both a public-relations nightmare and an opportunity, a dynamic driven by the weak overall market performance of electric vehicles, which make up only about 1% of global sales. Self-driving cars are the cool new thing, and Musk isn't going to miss out on that futuristic adventures, even as he has to yet again take to sleeping in Tesla's factory floor in Fremont, CA to fix the Model 3's problems.The battle with the NTSB over the Mountain View crash could ultimately help Tesla.""They're not really running a risk,"" said Kelley Blue Book Executive Publisher Karl Brauer, adding that Tesla has always been ""untraditional.""""They have many people out there in their fan base,"" he said. ""They're scoring points with those people.""It also isn't necessarily a reckless decision for Tesla to oppose an opaque government process, Brauer suggested.""We don't like the lack of disclosure, especially in today's world. So it's not a bad political move.""The fracas has, however, awkwardly highlighted Autopilot capabilities relative to its competition. Tesla's system doesn't use laser-radar (Lidar), as does Waymo and General Motor's Cruise division. Nor does it make use of Lidar-mapping, as does Cadillac's Super Cruise, a hands-free, highway only system that also, unlike Autopilot, monitors a driver's eyes and head to ensure that he or she is engaged.""Their driver monitor system isn't as good as some other systems in terms of assuring that someone is paying attention,"" said David Friedman, Director of Cars and Product Policy and Analysis for Consumers Union, the advocacy division of Consumer Reports.Autopilot prompts the driver to return their hands to the wheel if the systems detects that they haven't been there for a period of time and will deactivate itself if the driver ignores warnings. But according to Friedman, that ""doesn't tell you if driver is paying attention.""After the 2016 Florida crash, Consumers Union and Consumer Reports forcefully objected to Tesla's marketing of Autopilot, but the organization has stopped short of demanding that Tesla recall or deactivate the technology (I have recommended that Tesla do this.)""The key thing is to fix it,"" Friedman said. ""They have the knowledge and the technology. Tesla and Musk have a reputation as innovators, but they're falling behind GM on driver monitoring.""Consumers Union doubled down on that position last week when, after I spoke with Friedman, the organization put out a press release calling on Tesla to improve Autopilot safety and release the data behind its existing safety claims.""After another tragedy involving Autopilot, Tesla should commit to put safety first—and to stop using consumers as beta testers for unproven technology,"" Consumers Union argued.The big question now for Tesla is: ""Is Autopilot really worth remaining committed to?""In my testing of the technology — admittedly subjective, not scientific — I've found it to be basically a very advanced form or cruise control. It's far from a true self-driving system, and Tesla has repeatedly said that. I've also sampled Cadillac Super Cruise and am comfortable saying that it is fully capable of hands-free operation — as long as it's operating in a very precisely defined environment. The system almost seems to want to switch itself off, rather than steer a vehicle into anything even remotely unfamiliar.But in the grand scheme of things, I think that almost all consumer-oriented self-driving tech (i.e., not Waymo or Cruise, which are fleet services) is getting ahead of itself. This is especially true for Tesla, a company that at root is a luxury electric-vehicle manufacturer. It sold 100,000 vehicles last year, most of them Model S sedans and Model X SUVs. It could continue to do that for decades to come.Meanwhile, the self-driving stuff could easily leap into nearly full autonomy — no steering wheel, no driver controls — in a few years, but with vehicles that function only in a ride-hailing framework. This is the Waymo/Cruise business model. Tesla has yet to even begin to layer that on its existing business, and it's unclear that even with Autopiloted car-sharing, sometimes called the ""Tesla Network,"" that owners will be interested in lending out their $100,000 cars.So why is Tesla sticking with Autopilot? It has a lot to do with the stock price.Look no farther than the stock price, which rocketed toward $400 in 2017, giving Tesla a market capitalization that at $50 billion exceeded Ford's, Fiat Chrysler Automobiles' and challenged GM's. Bear in mind that GM, since its 2010 IPO has made over $70 billion in profits; Tesla also staged an IPO in 2010 and has made effectively nothing since them, but has nevertheless returned over 1,000% to early investors.The stock is Tesla's ATM, and although the company recently said that it will need to raise no new capital in 2018, it has issued new equity, raising billions, in the past and doesn't want to have that funding channel closed off. This means that the Tesla story must be more all-encompassing than the operations of a carmaker with one factory, selling three cars, would imply.Electric cars aren't enough. The electric vehicles have to drive themselves, because Waymo's and Cruise's autonomous EVs will. Tesla's business can't be just cars, either. Other players are attacking the freight business with all-electric trucks, so earlier this year, Tesla unveiled a Semi. The world's exotic supercar producers are talking about exotic, very fast EVs, so Tesla revamped its Roadster to be the fastest EV in the world (in fact, the fastest production car, with acceleration that's on par with Formula One racers).That's a lot to keep Tesla watchers (and investors) occupied and optimistic, but overall, Autopilot is the least compelling thing the carmaker is currently doing. For one thing, Autopilot is expensive: If you order a Model S, for example, the technology as it now functions is a $6,000 upgrade; a bump to full self-driving capability, with the hardware in place but the software update to arrive in the future, is another $4,000.If I were buying a Model S, I'd skip it. (My colleague Ben Zhang points out that I'd be damaging the resale value, but I think I rather have the extra six grand.) OK, the additional revenue is certainly helpful for cash-strapped Tesla. But fixating in Autopilot at the expense of other products could actually be pushing off profitability at this point, which is where Tesla has to be aiming the ship if it wants to renounce the endless capital raises and stop larding its balance sheet with debt.I'm under no illusion that Tesla is going to pull back from Autopilot. Its actions toward the NTSB prove that it's bristling for a fight. And it could win the battle. But I just don't think that this is a feud that's worth pursuing. Autopilot simply isn't good enough to be worth the distraction.Get the latest Tesla stock price here.This is an opinion column. The thoughts expressed are those of the author.This column does not necessarily reflect the opinion of Business Insider."
https://www.reuters.com/article/us-tesla-autopilot-lawsuit/tesla-settles-class-action-lawsuit-over-dangerous-autopilot-system-idUSKCN1IQ1SH,"4 MIN READNEW YORK (Reuters) - Tesla Inc on Thursday reached an agreement to settle a class action lawsuit with buyers of its Model S and Model X cars who alleged that the company’s assisted-driving Autopilot system was “essentially unusable and demonstrably dangerous.”The lawsuit said Tesla misrepresented on its website that the cars came with capabilities designed to make highway driving “safer.”The Tesla owners said they paid an extra $5,000 to have their cars equipped with the Autopilot software with additional safety features such as automated emergency braking and side collision warning.The features were “completely inoperable,” according to the complaint.Under the proposed agreement, class members, who paid to get the Autopilot upgrade between 2016 and 2017, will receive between $20 and $280 in compensation. Tesla has agreed to place more than $5 million into a settlement fund, which will also cover attorney fees.The case has been closely watched in the automotive and legal communities, as it was the only known court challenge Tesla has faced with regard to its assisted-driving technology.Tesla’s Autopilot system has come under increased scrutiny in recent months after two Tesla drivers died in crashes in which Autopilot was engaged. The most recent crash, in March, is being investigated by safety regulators.Tesla said in a statement it “wanted to do right” by its customers and, as part of the proposed deal, agreed to compensate car owners who had purchased the 2.0 version of Autopilot and “had to wait longer than we expected” for the driving features to become active.“Since rolling out our second generation of Autopilot hardware in October 2016, we have continued to provide software updates that have led to a major improvement in Autopilot functionality,” the company said. Even though the settlement only covers U.S. customers, Tesla said it would compensate “all customers globally in the same way.”The proposed settlement does not mention the safety allegations but focuses on the delay in making the promised features available to consumers.Steve Berman, a lawyer for the car owners, did not immediately respond to a request for comment.The agreement, announced in a filing in San Jose federal court late Thursday, must be approved by U.S. District Judge Beth Labson Freeman.Autopilot, released in 2015, is an enhanced cruise-control system that partially automates steering and braking. Tesla has said the use of Autopilot results in 40 percent fewer crashes, a claim the U.S. National Highway Traffic Safety Administration repeated in a 2017 report on the first fatality, which occurred in May 2016. Earlier this month, however, the agency said regulators had not assessed the effectiveness of the technology.The 2017 lawsuit in San Jose federal court named six Tesla Model S and Model X owners from Colorado, Florida, New Jersey and California who alleged the company had engaged in fraud by concealment, and had violated various state consumer protection and unfair competition laws.They sought to represent a nationwide class of consumers.Reporting by Tina Bellon; editing by Noeleen Walder and David GregorioSPONSOREDSPONSOREDAll quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.© 2018 Reuters. All Rights Reserved."
https://www.recode.net/2018/4/2/17183860/tesla-crash-autopilot-elon-musk,"Tesla is starting the second quarter in a defensive crouch:By the company’s own admission, this is a critical time for Tesla. The electric vehicle movement the company arguably popularized is seeing momentum from new and existing players, while self-driving competitors like Alphabet’s Waymo strike deals with automakers to develop vehicles that could rival Tesla’s own offerings. As both an automaker and a self-driving tech company, Tesla still has a lot to prove.It’s not yet known whether Autopilot was at fault for 38-year-old Tesla driver Walter Huang’s death, but the simple fact that it was involved has put Tesla’s already fraught future — as well as the self-driving industry — at risk.On March 23, Huang crashed his Model X into a median on a California highway while the SUV was operating in Autopilot mode. Tesla recovered the logs from the vehicle, and upon analyzing them said that the driver had received “several visual and one audible” cue to take back control of the car.“The driver had about five seconds and 150 meters of unobstructed view of the concrete divider with the crushed crash attenuator, but the vehicle logs show that no action was taken,” the company wrote in a blog post.This is the second U.S. crash of a Tesla confirmed to be operating Autopilot that has led to a fatality. The first was in Williston, Fla., in May 2016.The National Transportation Safety Board, which is also investigating the March 23 crash, found that the first Autopilot-related fatality in 2016 was in part a result of the driver overrelying on Tesla’s semiautonomous software, but that Autopilot operated the way it was supposed to.The NTSB’s investigation into this crash is ongoing, but the agency said that it was “unhappy” that Tesla revealed the details of the investigation to the public. The NTSB is also looking into reports that the driver previously complained about the performance of the Autopilot software.Relatives of Huang said that he took his Tesla to the dealership because the software caused the car to swerve toward the highway barrier that his vehicle ultimately crashed into.A Tesla spokesperson declined to comment on the NTSB’s comments but said they found no record of Huang bringing the vehicle into a dealership to service its Autopilot software.“We’ve been doing a thorough search of our service records and we cannot find anything suggesting that the customer ever complained to Tesla about the performance of Autopilot,” a Tesla spokesperson said in a statement. “There was a concern raised once about navigation not working correctly, but Autopilot’s performance is unrelated to navigation.”The tragic death comes as both the industry and Tesla brace for the fallout from a recent fatality that involved an Uber-operated semi-autonomous vehicle in Tempe, Ariz.The NTSB, along with local police and the National Highway Traffic Safety Administration, is also investigating the Uber crash, which resulted in the death of 49-year-old Elaine Herzberg.Both crashes hit at a larger question many in the industry have: Is semi-autonomous technology safe?With Uber and Tesla being two of the most prominent brands in the auto and tech industry working on some version of self-driving, consumer trust in the new technology could take a hit.When it launched Autopilot, Tesla set the benchmark for the most advanced adaptive cruise control available in consumer vehicles. That technology has received multiple updates, and Musk has said he expects the second generation of the software to be capable of a high level of self-driving in about two years.However, as it exists today, Autopilot is not intended to operate in all circumstances, and in fact is limited to highway driving. In other words, drivers need to be alert and ready to take over at all times — which creates an odd situation that is now clearly prone to failure.That was also the case in Uber’s crash: The system relies on a trained operator to take over when the technology doesn’t work, though there are some important distinctions that need to be made between the two. For instance, Uber’s technology, which is still in development, is intended to operate on local roads with variables including pedestrians. Tesla’s Autopilot is only supposed to ease the highway-driving task.Uber’s vehicles, however, are not available to the wider public, and are not being sold direct to consumers. Tesla, which says its technology is also still in beta, is putting its technology in the hands of consumers. Still, if either of the companies’ semiautonomous software is found to be at fault, there could be a resounding impact on consumer trust around self-driving.“The consequences of the public not using Autopilot, because of an inaccurate belief that it is less safe, would be extremely severe,” Tesla wrote in a blog post. “There are about 1.25 million automotive deaths worldwide. If the current safety level of a Tesla vehicle were to be applied, it would mean about 900,000 lives saved per year.”Tesla’s voluntary recall of 123,000 Model S cars punctuated its ongoing struggles with meeting production goals of its mass-market vehicle, the Model 3.The Model 3 is a significant barometer by which investors and the industry are measuring Tesla’s capability as an automaker. Can Tesla make the shift away from being just a luxury player to a mass-market carmaker at scale?By Musk’s own admission, the early years of Tesla — from the Roadster to the Model X — were in service of laying the groundwork for building and selling a mass-market electric vehicle.But the company has gotten off to a rough start in meeting the many ambitious goals Musk has set for the production of the vehicle.In July 2017, Musk said that he aimed to produce 5,000 Model 3 vehicles per week by the end of 2017. The company then shifted that rate goal to 5,000 cars per week by the end of March 2018. But then in January, Musk lowered that goal to 2,500.Today, Tesla is producing 2,000 Model 3s a week, according to emails obtained by Jalopnik.“If things go as planned today, we will comfortably exceed that number over a seven-day period!” Musk wrote, referring to the current rate of production.The company’s head of engineering also tried to rally the troops last week, saying the company needed to prove the “haters” wrong, as Bloomberg first reported.“The world is watching us very closely, to understand one thing: How many Model 3s can Tesla build in a week?” Doug Field wrote. “This is a critical moment in Tesla’s history, and there are a number of reasons it’s so important. You should pick the one that hits you in the gut and makes you want to win.”Sign up for our Recode Daily newsletter to get the top tech and business news stories delivered to your inbox.Sign up for our Recode Daily newsletter to get the top tech and business news stories delivered to your inbox.Plus, Walmart puts Amazon on notice with a big Q2 beat; Tencent sees its first profit drop in decades; is Elon Musk crazy?; a deep dive into ... burritos.The two leaders will join an impressive lineup on September 17 and 18 in New York City.Plus, Twitter CEO Jack Dorsey is rethinking how Twitter works so it won’t help spread hate; how air conditioning helped create the modern city; happy 60th birthday to the ageless Madonna.Digiday Editor in Chief Brian Morrissey says publishers were naïve if they didn’t think Facebook would eventually put its own interests above theirs.A Verge affiliate site"
https://www.reuters.com/article/us-tesla-autopilot/consumer-groups-ask-u-s-agency-to-probe-tesla-autopilot-ads-idUSKCN1IO1IQ,"4 MIN READSAN FRANCISCO (Reuters) - Two U.S. consumer advocacy groups urged the Federal Trade Commission on Wednesday to investigate what they called Tesla Inc’s “deceptive and misleading” use of the name Autopilot for its assisted-driving technology.The Center for Auto Safety and Consumer Watchdog, both non-profit groups, sent a letter to the FTC saying that consumers could be misled into thinking, based on Tesla’s marketing and advertising, that Autopilot makes a Tesla vehicle self-driving.Autopilot, released in 2015, is an enhanced cruise-control system that partially automates steering and braking. Tesla states in its owner’s manual and in disclaimers that when the system is engaged, a driver must keep hands on the wheel at all times while using Autopilot.“The feedback that we get from our customers shows that they have a very clear understanding of what Autopilot is, how to properly use it, and what features it consists of,” a Tesla spokesperson said.But in the letter, the groups said that a series of ads and press releases from Tesla as well as statements by the company’s chief executive, Elon Musk, “mislead and deceive customers into believing that Autopilot is safer and more capable than it is known to be.”“Tesla is the only automaker to market its Level 2 vehicles as ‘self-driving’, and the name of its driver assistance suite of features, Autopilot, connotes full autonomy,” the letter read.“The burden now falls on the FTC to investigate Tesla’s unfair and deceptive practices so that consumers have accurate information, understand the limitations of Autopilot, and conduct themselves appropriately and safely,” it read.Tesla has also faced criticism from an influential magazine, Consumer Reports, over braking flaws in its Model 3 sedan, which is seen as key to the company’s profitability. Musk has promised a quick fix.Meanwhile, the popularity of the Model 3 has led to more registrations in California for the first quarter than class rivals BMW 3-Series and Mercedes C-Class, according to the California New Car Dealers Association (CNCDA).California is a key market for global luxury vehicle brands not just because of its size, but because other markets often follow trends set by wealthy consumers in the state.Several crashes and fire incidents involving a Tesla car this year has been a constant headache for Musk, who boasts that his company’s cars are among the safest in the industry.Two U.S. Tesla drivers have died in crashes in which Autopilot was engaged. The most recent crash, in March, is being investigated by safety regulators.Tesla has said the use of Autopilot results in 40 percent fewer crashes, a claim the U.S. National Highway Traffic Safety Administration repeated in a 2017 report on the first fatality, which occurred in May 2016. Earlier this month, however, the agency said regulators had not assessed the effectiveness of the technology.Last month, another group, Consumers Union, the advocacy division of Consumer Reports, called on Tesla to improve the safety of its Autopilot system.Shares of Tesla rose 0.5 percent to $276.40 on Wednesday.Additional reporting by Sonam Rai in Bengaluru; Editing by Leslie Adler, Bernard OrrAll quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.© 2018 Reuters. All Rights Reserved."
https://www.bbc.com/news/technology-44300952,"A Tesla car has crashed into a parked police car in California.The driver suffered minor injuries and told police she was using the car's driver-assisting Autopilot mode.The crash has similarities to other incidents, including a fatal crash in Florida where the driver's ""over-reliance on vehicle automation"" was determined as a probable cause.Tesla has said customers are reminded they must ""maintain control of the vehicle at all times"".In a statement, it added: ""When using Autopilot, drivers are continuously reminded of their responsibility to keep their hands on the wheel.""As yet, it has still to be confirmed that the Autopilot mode was indeed engaged.The California crash appears to be the latest example of semi-autonomous vehicles struggling to detect stationary objects. A Tesla driving in Autopilot hit a stationary fire engine in Utah in May.According to a police report obtained by the Associated Press, the Tesla accelerated before it hit the vehicle.It has also emerged that a Tesla Model 3 driver has blamed Autopilot for a crash in Greece last Friday, in which the car suddenly veered right ""without warning"".The motorist, You You Xue, voiced his concerns about Autopilot on Facebook.""The vigilance required to use the software, such as keeping both hands on the wheel and constantly monitoring the system for malfunctions or abnormal behaviour, arguably requires significantly more attention than just driving the vehicle normally,"" he wrote.One influential tech industry-watcher has raised concern about Tesla's software, noting that Google's car division has claimed that an all-or-nothing approach is safer.""There is a serious argument that the incremental, 'level 2/3' approach to autonomous cars followed by Tesla, where the human isn't driving but might have to grab the wheel at any time, is actively dangerous and a technical dead end,"" tweeted, a partner at the venture capital firm Andreessen Horowitz.""Waymo decided not to do this at all.""It is not the first time the Autopilot feature has been linked to dangerous behaviour.In England, a driver was banned from driving after putting his Tesla in Autopilot on the M1 and sitting in the passenger seat.The news comes after two US rights groups urged the Federal Trade Commission to investigate Tesla over its marketing of the assisted driving software.The Center for Auto Safety and Consumer Watchdog said it should be ""reasonable"" for Tesla owners to believe that their car should be able to drive itself on Autopilot.It called the naming of the Autopilot ""deceptive and misleading"".The chief executive of Tesla, Elon Musk, has previously complained abut media attention on Tesla crashes. He tweeted: ""It's super messed up that a Tesla crash resulting in a broken ankle is front page news and the ~40,000 people who died in US auto accidents alone in past year get almost no coverage.""His comments received support from prominent academic and psychologist Steven Pinker, who has in the past voiced concerns about Tesla's Autopilot.Leaders honour Kofi Annan, the first black African to become UN secretary-general, who died aged 80.Have you been getting these songs wrong?What happens to your body in extreme heat?"
https://mashable.com/2018/05/30/tesla-autopilot-stationary-crashes/,"Another week, another Tesla crashing into a stationary vehicle that just came out of nowhere.But that's the thing. The electric car's semi-autonomous driving assistance feature, known as Autopilot, has this very situation — parked cars seemingly coming out of nowhere — written into the manual. It's a known limitation of the driver assistance tool.SEE ALSO: Pro-tip: Tesla's autopilot doesn't mean you can sit in the passenger seatThis week it was a Tesla driver in Laguna Beach, Calif., that hit a parked police car. Luckily, no one was seriously hurt (and no one was in the police vehicle), but it was another ding for Tesla's Autopilot reputation. It keeps crashing. The National Transportation Safety Board won't be investigating this crash, but they're still looking into fatal self-driving crashes from earlier this year, including a Tesla Model X that hit a road barrier with Autopilot engaged.This situation in Laguna Beach, while certainly scary, is what Tesla lays out in its manual. Autopilot's cruise control tracks the vehicle in front of the electric vehicle. So if that car suddenly moves out of the way for, say a traffic accident up ahead, the automated guide pretty much ends there and the driver needs to snap to attention and take over. Here's what the manual says about this driving situation:""Traffic-Aware Cruise Control cannot detect all objects and may not brake/decelerate for stationary vehicles, especially in situations when you are driving over 50 mph (80 km/h) and a vehicle you are following moves out of your driving path and a stationary vehicle or object is in front of you instead. Always pay attention to the road ahead and stay prepared to take immediate corrective action. Depending on Traffic-Aware Cruise Control to avoid a collision can result in serious injury or death.""The issue at play here isn't so much that the car is really bad at tracking parked cars and stationary objects out of view (that's a separate shortfall of Autopilot to get into), but that Tesla isn't making it clear to its drivers that the car can't handle or anticipate this fairly typical driving scenario.In an email statement, a Tesla spokesperson defended using Autopilot appropriately and reminded drivers that the onus is always on them, even when using the semi-automated tool. ""When using Autopilot, drivers are continuously reminded of their responsibility to keep their hands on the wheel and maintain control of the vehicle at all times. Tesla has always been clear that Autopilot doesn’t make the car impervious to all accidents, and before a driver can use Autopilot, they must accept a dialogue box which states that ‘Autopilot is designed for use on highways that have a center divider and clear lane markings,’"" the statement read.Autopilot doesn't mean you can just sit back, relax, and take your hands, eyes, and mind off the road and wheel.Some people think Autopilot is ""more sophisticated than it really is"" and some companies (and media outlets) oversell what these semi-autonomous features can do, University of Iowa engineering professor Daniel McGehee, director of the National Advanced Driving Simulator, told me in a conversation about eroding faith in self-driving cars last week. ""So people tend to think this technology is here today,"" he said. It's still very much partial assistance, with lane keeping, automatic braking, and other features that work only in certain environments. The warning system needs to improve if it's going to be a reliable driving tool. ""We’re going to have to build safety measure that do more than shake the wheel"" — or similar warnings about oncoming danger — said corporate strategy lead for transportation Jeremy Bennington from test solutions company Spirent Communications. ""We just can’t have these cars running into stationary emergency vehicles.""Bennington called for more and more autonomous testing so eventually ""we can move where the driver really is out of the loop."" But until then, Autopilot isn't fully autonomous, even if it's treated like it is. That's what happened when a driver was on her phone, had her Tesla in Autopilot, and hit a parked fire department vehicle in Utah earlier this month. Back in January, a Tesla Model S crashed into a parked Culver City fire truck on the freeway in Southern California. Same situation: fast freeway driving with Autopilot on when a truck responding to a traffic incident up ahead was parked and blocking the road. Autopilot couldn't handle the situation quick enough.Consumer groups brought up limitations of Autopilot's capabilities in a letter to the Federal Trade Commission last week. They called Tesla's autonomous feature ""dangerously misleading and deceptive."" Instead of focusing on and educating about its partial capabilities, Tesla makes Autopilot seem like a fully autonomous tool through marketing, advertising, company statements, and online content, consumer advocates say. That's not the first time Tesla's been under fire for pumping up expectations of Autopilot. Back in 2016, Germany called out the company for claiming the cars could drive themselves more than they really could in Autopilot mode.As with most new technology, Washington University in St. Louis engineering professor Sanjoy Baruah says our expectations are too high. ""Users are still trying to get a feel for what it’s supposed to be doing for us,"" he said about Autopilot and other self-driving tools. And while Autopilot may not be able to handle this basic driving scenario with emergency vehicles blocking the road, Baruah sees how automated tech can be a life-saver for sleepy, distracted, or inebriated drivers. It's a balancing act that we'll eventually get the hang of — and the technology will improve, too. ""It's new things we are learning to come to terms with,"" Baruah said.In a more solutions-oriented look at the semi-autonomous problem, Sumanta Chakraborty, product management director for automotive marketing at Nuance Communications, thinks voice warnings could bridge human drivers with the machines. ""Modalities other than voice –- such as visual, auditory and haptic -– are also important in the car, but voice provides an instantaneous way for drivers take over as the supervisor in a smooth way that humans are wired to understand,"" he said in an email.Try as it might to explain that Autopilot is only semi-autonomous and still requires full driver attention, Tesla has more explaining to do until it becomes clear for drivers. Until then, they'll keep crashing into parked cars — or worse. UPDATE: May 31, 2018, 11:53 a.m. PDT Additional commentary included within the article."
https://www.theverge.com/2018/6/19/17479316/tesla-autopilot-buddy-aftermarket-nhtsa,"The National Highway Traffic Safety Administration (NHTSA) issued a cease and desist order on Tuesday to the manufacturer of a $199 aftermarket device that tricks Tesla’s Autopilot system into thinking a driver’s hands are on the steering wheel.The “Autopilot Buddy” is a piece of magnetic plastic that attaches to a Tesla vehicle’s steering wheel in order to create the impression that the driver is keeping his or her hands there. Tesla’s advanced driver assist system Autopilot only works with continued pressure on the steering wheel. If a driver’s hands aren’t detected, the display behind the wheel will begin to flash, followed by audible warnings, and eventually Autopilot will disable itself. Autopilot Buddy appears designed for very foolish people who want to avoid those warnings.“A product intended to circumvent motor vehicle safety and driver attentiveness is unacceptable,” said NHTSA deputy administrator Heidi King in a statement. “By preventing the safety system from warning the driver to return hands to the wheel, this product disables an important safeguard, and could put customers and other road users at risk.”The website for Autopilot Buddy claims the device is manufactured in the US, but notes that it is not presently for sale in the US. The manufacturers claim their device returns Autopilot to its former glory: “‘Autosteer’ was first released to Telsa owners in Oct 2015,” the site reads. “Since that time Tesla’s ‘updates’ have slowly diminished the duration we can enjoy ‘autopilot’ in our cars.”Essentially Autopilot Buddy is being sold as a “hack” that allows Tesla drivers to be more inattentive behind the wheel. And that’s really bad, especially these days when Tesla is under intense scrutiny by traffic regulators about its semi-autonomous Autopilot system. There have been a number of car crashes recently involving Tesla vehicles using Autopilot, three of which resulted in fatalities. Federal investigators recently issued a preliminary report on one fatal crash in Mountain View, California, in which Autopilot was reported to have made a navigational mistake contributing to the incident.Since its launch in 2015, Tesla owners have sought out new and creative ways to trick Autopilot. People couldn’t wait to upload videos sitting in the backseat while their cars drove “autonomously” down the highway. Tesla responded by updating its software to require drivers to keep their hands on the steering wheel — which seemed like a smart fix until one driver figured out all you needed to do to fool the system was wedge an orange against the wheel to simulate the pressure of a human hand. People love tricking technology, even if it could cost them their lives.Autopilot Buddy seems designed to exploit that very human frailty. But even so, the manufacturers appear aware that what they’re trying to sell is highly unethical, and possibly illegal. The website includes a number of disclaimers. The manufacturers claim its “not intended to be a hands-off device” but is intended “for track use only,” which is hilarious because who only drives their Tesla on a closed track?The trademark for Autopilot Buddy is held by an entity called Dolder, Falco, and Reese LLC, which is registered in Valencia, California. State records list the registered agent as Carl Reese, who also owns a construction firm in Valencia. We’ve reached out for comment and will update this story if we hear back.Command Line delivers daily updates from the near-future."
https://bgr.com/2018/05/14/tesla-autopilot-hands-on-wheel-sensors-vs-cadillac-super-cruise/,"Last month, Tesla CEO and part-time rocket enthusiast Elon Musk said that his factory was in “production hell” thanks to issues producing thousands of Model 3 cars every week. But while his factory has been in production hell, the semi-autonomous Autopilot feature installed on Tesla’s Model S and Model X cars has been in PR hell. A handful of fatal accidents involving Autopilot were backed up by scary videos of vehicles following white lines straight into concrete lane dividers, and Tesla didn’t help things out by publicly feuding with one of the safety organizations investigating the incident.Earlier today, the Wall Street Journal put out a story saying that Tesla engineers proposed adding a driver attention feature to Autopilot that would ensure drivers were paying attention to the road when Autosteer was enabled. Tesla has blamed a lack of attention in every fatal Autopilot accident, and Musk has repeatedly pointed out that Autopilot is meant to be a driver assist feature, not a fully autonomous driving solution. But according to the WSJ story, Tesla execs including Musk rejected the idea of adding driver awareness sensors, thanks to increased cost and a perceived lack of benefit.“Tesla Inc.’s engineers repeatedly discussed adding sensors that would ensure drivers look at the road or keep their hands on the wheel both before and after the driver-assistance system was introduced in 2015,” the WSJ‘s sources reported. “Tesla executives including Chief Executive Elon Musk rejected the ideas because of costs and concerns that the technology was ineffective or would annoy drivers with overly sensitive sensors that would beep too often, the people said.”A Tesla spokesperson didn’t deny the story to the WSJ, instead saying that “Everyone at Tesla is not only encouraged, but expected, to provide criticism and feedback to ensure that we’re creating the best, safest cars on the road,” adding that “we make decisions based on what will improve safety and provide the best customer experience, not for any other reason.”Continuing with his recent trend of bluntly addressing issues on Twitter, Musk went much further than his spokespeople:Something worth noting here is that Tesla does have a driver attention system in Autopilot, a feature that was added after the first fatal Autopilot crash in May 2016. In an update rolled out September 2016, Tesla added hands-on-wheel detection using the steering wheel sensors, and added a feature that beeps warnings at the driver if they take their hands off the wheel for too long. Owners weren’t delighted with the update, and the internet is full of “hacks” to trick the sensors, including a custom-made $179 device that clamps on the wheel and removes the “nag” warnings.A better and more robust driver attention system would be a camera looking at the driver, a feature Cadillac uses in its Super Cruise system. The camera monitors the driver to check that their eyes are on the road, and will disable Super Cruise if you take your eyes off the road for too long. Presumably, that was the kind of sensor that Tesla engineers wanted to add to Autopilot, but Musk rejected.Copyright 2018 BGR Media, LLCPowered by WordPress.com VIP | Privacy Policy | Your Privacy Rights | Ad Choices | Privacy Preferences | Terms Of Use"
https://www.wired.com/story/tesla-autopilot-crash-safety/,"WHEN VENETIAN MERCHANTS hauled the first shipments of a popular Ottoman drink called coffee into 17th century Europe, leaders in the Catholic Church did not exult at the prospect of increased productivity at the bottom of a warm cuppa. So they asked Pope Clement VIII to declare coffee “the bitter invention of Satan.” The pontiff, not one to jump to conclusions, had coffee brought before him, sipped, and made the call. “This Satan's drink is so delicious that it would be a pity to let the infidels have exclusive use of it,” he declared, the (perhaps apocryphal) story goes.Which is all to say: Sometimes people are so scared of change that they get things very wrong.Today that metathesiophobia has found a new target in cars that occasionally drive themselves. And the fearful murmuring only got louder this week, when the National Highway Traffic Safety Administration opened an investigation after a driver in Utah crashed into a stopped firetruck at 60 mph, reportedly while Tesla's Autopilot feature was engaged. Every time a Tesla with its semiautonomous Autopilot feature crashes—one hit a stopped firetruck in Southern California in January, another struck a highway barrier in Mountain View, California, in March, killing its driver—it makes headlines. (One could imagine the same thing happening with a car using Cadillac’s Super Cruise or Nissan’s Pro Pilot, but those newer, less popular features have had no reported crashes.)So, many are fearful. The National Transportation Safety Board and the National Highway Transportation Safety Administration have launched investigations into these crashes, while consumer advocates lob criticisms at Tesla.Human factors engineers who study the interactions between humans and machines question the sagacity of features that allow drivers to take their hands off the wheel, but require they remain alert and ready to retake control at any moment. Humans are so bad at that sort of thing, many robocar developers, including Waymo, Ford, and Volvo, are avoiding this kind of feature altogether.Elon Musk, a leader who inspires quasi-religious devotion in his own right, spurns this hand-wringing. “It’s really incredibly irresponsible of any journalist with integrity to write an article that would lead people to believe that autonomy is less safe,” he said on an earnings call earlier this month. “People might turn it off and die.”Musk and Tesla spokespeople have repeatedly said the feature can reduce crashes by 40 percent. But a recent clarification from the National Highway Traffic Safety Administration and a closer look at the number reveals that it doesn’t hold up.Still, it’s plausible that Autopilot and its ilk save lives. More computer control should minimize the fallout when human drivers get distracted, sleepy, or drunk. “Elon’s probably right in that the number of crashes caused by this is going to be less than the ones that are going to be avoided,” says Costa Samaras, a civil engineer who studies electric and autonomous vehicles at Carnegie Mellon University.1 “But that doesn’t change how we interact with, regulate, and buy this technology right now.” In other words: It’s never too early to ask questions.So how can carmakers like Musk’s prove that their tech makes roads safe enough to balance out the downsides? How can Autopilot follow in the path of the airbag, which killed some people, but saved many more, and is now ubiquitous?Experts say it would take some statistics, helped along by a heavy dose of transparency.“The first thing to keep in mind is, while it seems like a straightforward problem to compare the safety of one type of vehicle to another, it’s in fact a complicated process,” says David Zuby, who heads up vehicle research at the Insurance Institute of Highway Safety.The natural starting point is looking at how many people die driving a given car as a function of miles driven, then comparing that rate to other models. Just a few problems. First, it’s hard to separate out semi-autonomous features from other advanced safety features. Is it Super Cruise doing the saving, or Cadillac’s automatic emergency braking, which steps to avoid crashes, even when the driver’s in full control of the car?Second, we don’t have enough fatality data to draw statistically sound conclusions. While the lack of death and injury is nice, it means that independent researchers can’t definitively prove, based on police reports, if cars with these specific features are actually killing fewer people.Then, you have to make sure you’re comparing your apple to another apple. This week, Musk tweeted that Tesla only saw one death per 320 million miles, compared to one death per 86 million miles for the average car. The problem is that latter figure is includes all road deaths involving all vehicles—those killed in motorcycles (which are way more dangerous than cars), clunkers built in the late ‘80s, and tractor trailers, as well as those killed while biking or walking.“A Tesla is not an average car—it’s a luxury car,” says David Friedman, a former NHTSA official who now directs car at Consumers Union. It’s heavier than the average car, and so safer in a crash. (Again, a good thing—but not helpful for evaluating Autopilot.) Tesla owners are likely richer, older, and spend less time on rural roads than the average drivers. That’s important, because research indicates middle-aged people are the best drivers, and rural roads are the most dangerous kind, accounting for more than half of this country’s vehicle fatalities.The Insurance Institute for Highway Safety has tried to track Autopilot safety through insurance claims. According to its very preliminary research, Teslas produced in the years after the company launched Autopilot were no more or less likely to see claims filed for property damage and bodily injury liability than Teslas produced before. But IIHS did find a 13 percent reduction in collision claim frequency, which could indicate that cars equipped with Autopilot are getting into fewer crashes. Still, IIHS doesn’t actually know if Autopilot was engaged during any of those incidents.Which is all to say: It’s very, very difficult to separate out the effects of Autopilot from other variables. At least for folks who don’t work at Tesla.Earlier this month, Musk announced that Tesla would begin to publish quarterly reports on Autopilot safety. That could be great for transparency, experts say, provided Tesla coughs up the right sorts of data. (Tesla did not respond a request for comment.)For one, it would be great if any and all safety data could be verified by a third-party source. “When any company or entity that’s trying to sell something publishes data about their product, you have to worry at the back of your head that they may have taken data out of what they’re publishing,” says Zuby, the IIHS researcher. “So you’d like to have an independent party say, ‘Yeah, we’ve looked at all the data, and Tesla is putting out all the data.’”Beyond that, researchers and regulators would like to get really specific. The ideal would be a GPS-pinned list of all crashes, down to the date and time of the incident. That way, investigators could separate out incidents by weather, lighting conditions, and road type. (Crashes are way less likely on highways, so even the most effective Autopilot-like function would not be able to prevent all road deaths.) Were there other vehicles or pedestrians involved? Maybe semi-autonomous features are great at protecting their own drivers and not great at protecting others.Friedman, with the Consumers Union, says he’d like to see reports of “disengagements”—when drivers see that Autopilot is doing something wrong, like merging into a lane when it shouldn’t, and take over control. This info could give safety researchers valuable clues about how real people are using this tech.Whatever the truth of its tech, Tesla doesn’t have the kind of papal power or persuasion that gave us macchiatos and cafés crème. Neither does General Motors, or Nissan, or any other automaker pushing this sort of feature. But they do have more access to how people are using their nascent technology than your standard public health official—and nothing helps turn doubters into believers like a few words of truth.1Post updated, 5/17/18, 1:45 PM EDT: This story has been updated to clarify the context of Samaras's comments.The teens who hacked Microsoft’s Xbox empire—and went too farKetamine offers hope—and stirs up controversy—as a depression drugPHOTO ESSAY: Want to hunt aliens? Go to West Virginia’s low-tech ‘quiet zone’How red-pill culture jumped the fence and got to Kanye WestWaymo’s self-driving car crash revives hard questionsDaryl Sawchuk, Visual Effects Supervisor for Method Studios and Animation Supervisor for Black Panther, gives WIRED an exclusive look at breakdowns of the digital Black Panther and Kilmonger suits, and the final fight scene of Marvel's mega-blockbuster. Black Panther is available on Blu-Ray and DVD May 15, 2018.CNMN Collection© 2018 Condé Nast. All rights reserved.Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/25/18) and Privacy Policy and Cookie Statement (updated 5/25/18). Your California Privacy Rights. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices."
https://bgr.com/2018/06/18/tesla-autopilot-video-real-time-analysis/,"Tesla over the past few years has steadily rolled out a number of enhancements and updates to its Autopilot feature that, taken together, have helped improve overall performance and reliability. And while we’re still a ways away from a Tesla driving itself from LA to New York with zero driver interaction — something Elon Musk promised would go down in 2017 — there’s no denying that Tesla’s Autopilot feature, when used as intended, can truly help reduce the incidence of accidents and deaths on the road.With all of the hype surrounding self-driving car technologies, not to mention the accompanying controversies that inevitably ensue whenever a Tesla on Autopilot gets into an accident, it’s somewhat easy to overlook the immense amount of advanced technology that forms the foundation of self-driving automotive software.That said, a pair of new YouTube videos from greentheonly provides us with an arguably unprecedented and somewhat stunning look at what Tesla’s Autopilot software “sees” in real-time as it drives itself to and fro. By looking at the data used by the Autopilot feature and overlaying it on top of photos and video footage, we’re able to get a clearer sense of just what exactly is happening behind the scenes when the Autopilot feature is engaged.Though not an all-encompassing snapshot of Autopilot’s capabilities, the videos below are incredibly illustrative. Before diving in, note that the colors in the videos represent the following:Green = a moving objectYellow = a stopped objectOrange = a stationary objectRed = unknownWhat’s more, the YouTube description notes that the size of the circles in the videos below do not represent the size of the object being tracked, but is rather an indication of how far away it is. Specifically, the closer the object is, the bigger the accompanying circle is.Interestingly, Tesla back in 2016 posted its own video which details what its Autopilot system at the time “saw” on the open road.Copyright 2018 BGR Media, LLCPowered by WordPress.com VIP | Privacy Policy | Your Privacy Rights | Ad Choices | Privacy Preferences | Terms Of Use"
https://www.bbc.com/news/av/business-44460980/this-car-is-on-autopilot-what-happens-next,"Semi-autonomous vehicles, which can partly drive themselves, are already on our roads. But industry experts are worried that drivers don't understand what they can do... and what they can't.And that could be putting road users in danger.Video journalist: Peter Page"
https://www.businessinsider.com/tesla-autopilot-worth-questioned-2018-5,"Sometimes, all you need to do is follow the money.This week, Japan's SoftBank announced a total investment of $2.25 billion in GM's Cruise self-driving car division. GM said that it would add another $1.1 billion to the deal, taking the full deal to $3.35 billion and making Cruise worth $11.5 billion on its own.The San Francisco-based startup was acquired by GM in 2016 for $581 million and has been operated by the automaker as a semi-stand-along entity, with its own CEO — founder Kyle Vogt — a home-office in the Bay Area, and supervision from GM's President, Dan Ammann.By any reckoning, it now looks like a tremendously foresighted investment for GM. So good, in fact, that SoftBank is matching GM's own funding two-for-one. In exchange, SoftBank gets a nearly 20% stake, so if you're following along at home, GM effectively sold a fifth of Cruise and revealed over $10 billion in value in GM itself that was sort of trapped in the carmaker's $51-billion market cap.What we're starting to see now in the gestational self-driving-car world is that some business models assigned to technological innovation. Last week, Waymo deepened its partnership with Fiat Chrysler Automobiles. SoftBank has also bought into Uber (obviously, a clear link now exists between GM and the biggest ride-hailing service in the world).But what about Tesla and its Autopilot semi-autonomous system and Self-In this context, Autopilot looks malnourished. SoftBank's Cruise investment represents nearly as much money as Tesla has in the bank — $2.7 billion, as of the end of the first quarter. But Tesla will need that capital (and likely more) simply to operate its reliably unprofitable business for the next year.GM, by contrast, has made over $70 billion since its 2010 IPO (Tesla also IPO'd in 2010 and has never posted an annual profit). It has plenty of cash on hand and can deploy it ambitiously, given that its main business is taking care of itself.In the two years since the Cruise acquisition, GM has moved aggressively to get it to market. The master plan is to have fully self-driving all-electric Chevy Bolts with Cruise's laser-radar-based technology forming urban fleets to serve up rides by next year.Tesla's Autopilot, on the other hand, is more of an expensive option for retail customers. If you buy or lease a Tesla, you can get the tech, which isn't fully autonomous (far from it) and uses a computing system based on sensors and cameras. Autopilot has been involved in a number of accidents of late — accidents that are being investigated by the National Transportation Safety Board — but Tesla and CEO Elon Musk have continued to sell it as a safety enhancement.Even when Tesla has talked about Autopilot as a way for owners to make money off their vehicles when those cars would otherwise be sitting idle in driveways, the idea has been contingent on the retail channel. Yes, Tesla could keep some vehicles itself and create a self-driving fleet at some point, but those would be lost sales — and right now, Tesla needs every sale it can get.With this logic, if Cruise is worth $11.5 billion, then Autopilot as an independent business is currently worth zero. But what about Tesla's $50-billion market cap? Well, on paper that's made up of automaking, energy storage, and solar, if you think of Tesla as a holding company.But in that framework, Autopilot is simply a feature that can be added to a Tesla vehicle. And even a Tesla car could drive from coast to coast in fully autonomous mode — Musk has promised this event, but it hasn't happened yet — I'm still not sure that would mean Autopilot has any meaningful spinoff value.The challenge for Tesla is that while Musk was wise to recognize, about three years ago, a pivot away from electric cars as the new cool thing to self-driving as the exciting new opportunity, he failed to realize that companies such as GM and Google (Waymo came into existence in 2016, before which it was the Google Car project) would think of full autonomy as a distinct business opportunity and direct their design-build-investment strategies accordingly.This isn't a disaster for Tesla. Far from it. The company will hold an annual investor meeting next week, and if any of those folks bought in around the time of the IPO, they'd be looking at a nearly 1,ooo% return. With electric cars making up only about 1% of global sales, Tesla has monumentally outperformed any reasonable expectations.But that doesn't mean it can be everything. And trying to move the needle big-time of EVs while also being a player in the still-evolving autonomous space might be too much to ask. The bottom line is that although GM's Cruise and Tesla's Autopilot might be seen as competitors, they're actually quite different.And the biggest difference is that Cruise is now a valuable business in its own right.Get the latest Tesla stock price here."
https://bgr.com/2018/06/03/tesla-autopilot-saves-life-for-a-change/,"Tesla’s Autopilot gets into the headlines every time an Autopiloted vehicle crashes, and given Autopilot’s seeming love for stationary emergency vehicles, those headlines have been coming thick and fast lately. The negative coverage has irked billionaire CEO and actually-it’s-about-ethics-in-automotive-journalism truther Elon Musk, who says that because Autopilot is reportedly better than human drivers (who, in fairness, do suck), Autopilot doesn’t warrant all this media attention.Well, today Elon can rest happy, because it’s his sort of Autopilot story making waves. Music producer and proud Tesla owner Anton Zaslavski, better known as Zedd, shared his Autopilot story on Twitter last night.“There’s lots of “bad” news about Teslas w/ autopilot crashing,” Zedd wrote. “Just to show the other side too: I once fell asleep driving home late at night on the highway (w/ autopilot on) and got woken up by it beeping + turning off music to wake me up. Would have prob been dead without it.”Obviously, Autopilot isn’t designed to be used by sleepy drivers, since according to Tesla’s manual, a driver has to be behind the wheel, attentive, and ready to take over at any moment. But like any other driver-assist technology, many of Autopilot’s safety features help mitigate problems if the human screws up, in this case by driving when exhausted.Audible and visual alerts when the car senses the driver is inattentive isn’t a Tesla-only thing, and in this case, Autopilot’s intervention was limited to turning itself off. This story could have taken place in a Volvo, or a Toyota, or a GM equipped with Super Cruise, but that’s not the important thing. The message here is that autonomous technology isn’t just a matter of convenience; in some cases, it can also save lives. Of course, in order to measure how effective it is, we need more data, and if Musk is really concerned about making sure people understand Autopilot, some more facts on its use and safety record would be good. Copyright 2018 BGR Media, LLCPowered by WordPress.com VIP | Privacy Policy | Your Privacy Rights | Ad Choices | Privacy Preferences | Terms Of Use"
https://www.businessinsider.com/elon-musk-teases-mad-max-mode-for-tesla-autopilot-2018-6,"Tesla CEO Elon Musk teased a ""Mad Max"" mode for the company's semi-autonomous Autopilot feature on Sunday.After a Twitter user posted an image of Tesla's upcoming semi truck, the Semi, Photoshopped into a still from the 2015 film ""Mad Max: Fury Road"" — which features car chases in which vehicles collide and drive in close proximity to each other — Musk replied, ""Tesla Semi Truck in Mad Max Mode.""In another tweet, Musk said, ""It's real,"" and included an image of a Tesla vehicle's touchscreen with a ""Mad Max"" option for Autopilot's ""blind spot threshold"" setting, which instructs the system on how to perform actions such as changing lanes when prompted by the driver.In the photo, the ""Mad Max"" option is placed to the right of the ""Aggressive"" option, which indicates that the option might instruct the vehicle to make more aggressive lane changes than current options allow.Tesla declined to comment on how the option would work or when it might become available.Musk was later asked about Autopilot options Tesla customers will have in the future and said the company will have to keep self-driving cars in mind when developing future versions of Autopilot.""It's a tough call. Reality is that it will be pretty easy to bully a self-driving car, as it will always yield. Will prob have a manual override that requires continuous press for hardcore lane changes,"" he said.On June 10, Musk said Autopilot will receive ""full, self-driving features"" in an update planned for August. Musk didn't say which self-driving features would be included, though he indicated the update would allow Tesla vehicles to perform better in areas where lanes merge on highways.In its current iteration, Autopilot can keep a car in its lane and adjust its speed based on surrounding traffic, among other features. Recent accidents involving the feature have raised questions about whether drivers place too much trust in it and fail to pay attention to the road.Tesla has repeatedly said that Autopilot is meant to be used with an attentive driver whose hands are on the wheel, but the most visible accidents involving Autopilot have included reports of distracted drivers.Tesla has received criticism for how it has promoted the feature. In May, Consumer Watchdog and the Center for Auto Safety sent a letter to the Federal Trade Commission asking the agency to investigate the strategies the company has used to sell Autopilot.Get the latest Tesla stock price here."
https://www.forbes.com/sites/ellevate/2018/06/07/reprogram-your-autopilot-and-take-your-leadership-to-a-new-level/,"By: Kimberle SealeReprogram Your Autopilot And Take Your Leadership To A New LevelUNSPLASHEveryone has an autopilot. You have been preprogrammed to behave the way you do. We've all grown up with different experiences. However, we are preprogrammed by our parents, peers, teachers, and community to act, behave, and think in specific ways. How many of you were told:Our autopilot system is system of beliefs and behaviors that is created one of two ways. In some cases, there is a sudden emotional impact that anchors a certain way of thinking. A good example is the impact 9/11 had on both our country's sense of security and how some individuals behaved towards specific cultures, nationalities, and skin color. Alternatively, behaviors can be taught through repeated exposure to our unconscious mind. A notable example here is the child who is physically abused by their parent and grows up to either do the same to their own children or marry someone who behaves that same way. Regardless of their origin, these beliefs and behaviors run through our unconscious mind, also known as our autopilot system.In both preprogramming scenarios described above, our behaviors and actions are set for life. Or are they?Let’s first examine a less emotional example, such as driving a car. How many of you think back after your drive home and ask yourself, “Did I stop at that stop sign?” or “Were the dogs out sleeping in the yard today?” or ""Were the llamas out eating in the pasture?"" (that last one might be from personal experience) and find you are not sure? Your autopilot is turned on to operate your drive home. What if you turned your autopilot off and opened the window to hear, smell, and see everything around you? Look at the road and notice every pothole, see the leaves growing on the trees, and notice where the llamas are today?Now, let’s look inward. Think about where you are in life today. Have you achieved what you want to achieve by now? Do you have the things you desire? Are you the parent, spouse, friend, employee, and leader you want to be? If not, why? Take a look at what you are consciously and unconsciously doing. When you’re in a meeting, do you hold yourself back from answering a question for fear of being wrong? Are you afraid to sound stupid, or worry that you will be ridiculed? Are you overly-critical of yourself? Do you greet the people who pass you, or do you look down and away? Take note of what you do, and then ask yourself why.Recently, I had the opportunity to attend a John Maxwell event in Orlando. Going into this event, I thought I knew what was holding me back. Paul Martinelli proved me wrong. I'd thought it was from my high school experience. But what was actually holding me back was much older than that. It started when I was five years old, when I was repeatedly told, “Children should be seen and not heard.” The most impactful source came in grades 4-9. I had suppressed memories throughout those years. But they were so long ago - why should I care?I care because those experiences still hold me back today. They impact my relationships and success in my career. And until you really get to the root cause of your beliefs and behaviors, you can’t effectively start to reprogram your autopilot.For me, 4th grade began a multi-year experience with bullies. Bullies have an unbelievable impact on a child’s mind, and the victim's associated subconscious behavior can last a lifetime. These bullies generally crave attention and significance to fill a void they have within their own lives. When they find someone they can make fun of and make others laugh, they get the attention and significance they crave.So, I started holding myself back from asking or answering questions, hoping instead someone else would. I would sit in the back of a room so all eyes wouldn’t be on me. I would avoid speaking in front of groups. I knew I did these things and I wanted to change them. I just struggled with why. Now I understand.My question is now for you: What do you need to reprogram or unlearn to become the person you desire and achieve more from your career?Take a look at your behaviors and actions, and then ask yourself:Once you have answered these questions, do you find you have the passion to change? If so, with a little persistence and a plan of action, I am confident you can begin to reprogram your autopilot.--Kimberle Seale is a strategic leadership coach and business consultant. She works with individual leaders and business owners to unleash their limitless potential. Learn more at www.vincerem.com.Ellevate Network is a global network of professional women committed to elevating each other through education, inspiration, and opportunity. Our mission is to close the gender achievement gap in business by providing women with a community to lean on and learn from. Ellevat..."
https://www.cnbc.com/2018/03/27/tesla-defends-autopilot-record-after-feds-launch-investigation-into-fatal-crash.html,"Tesla is defending its Autopilot driver-assist technology as federal investigators probe a fatal crash involving a Tesla Model X SUV. The accident happened Friday afternoon on a stretch of highway in Mountain View, California.The National Transportation Safety Board announced Tuesday it is investigating the accident, including how the Model X caught fire after the crash and steps to make the vehicle safe before removing it from the accident scene.While the NTSB said it's unclear if the Model X Autopilot system was engaged prior to the accident, Tesla is defending the technology and its track record in the area where Friday's crash took place.In a blog post, the company said: ""Our data shows that Tesla owners have driven this same stretch of highway with Autopilot engaged roughly 85,000 times since Autopilot was first rolled out in 2015 and roughly 20,000 times since just the beginning of the year, and there has never been an accident that we know of.""Tesla also says the accident was so severe in part because a collision barrier on the highway had either been removed or restricted.""We have never seen this level of damage to a Model X in any other crash,"" Tesla wrote in its post.The National Transportation Safety Board said two investigators are looking into the accident. It is unclear how long it will take them to conduct their probe, though NTSB investigations typically take 12 to 18 months.Since rolling out Autopilot in 2015, Tesla has faced criticism the technology may be providing drivers with a false sense of security about taking their hands off the steering wheel.Following a deadly crash in Florida in 2016 where a Tesla Model S owner died after his car hit a truck while in autopilot mode, Tesla modified the technology to ensure driver's stay engaged periodically while using Autopilot.An NTSB investigation of that accident concluded the Tesla Autopilot system functioned properly prior to the accident including issuing repeated warnings to the driver to take control of the steering wheel.Got a confidential news tip? We want to hear from you.Sign up for free newsletters and get more CNBC delivered to your inboxGet this delivered to your inbox, and more info about our products and services. Privacy Policy.© 2018 CNBC LLC. All Rights Reserved. A Division of NBCUniversalData is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.Data also provided by"
https://brandequity.economictimes.indiatimes.com/be-blogs/are-brands-buying-or-investing-in-marketing-tech/3201,"In 2018, this thought is still relevant, but with a slight twist. With digital marketing taking centre stage to a gamut of innovative advertising technologies entering the market every day, to the ROI efficiencies which these “tech” can enrich the brands with, it's highly essential for marketers to understand and start buying or investing in Marketing Tech.MarTech is the apt mix of data, technology, insights, real-time analytics and intelligence. MarTech helps to scale up, spend less time in efficient activities and help brands reach customers more accurately than ever.John Koetsier defines Marketing Technology as – “Every piece of technology a marketer uses to reach a potential consumer.”One of the top-most priorities of brands, and the marketers who handle them, is to map the needs of the consumers, establish focus areas, and utilise these insights to connect with them. In the past decade, as digital presence of brands gained a lot of importance they readily invested in AdTech but ignored the vital role of MarTech in their plan. However, this behaviour is gradually observing a shift, and more brands are leaning towards companies that offer MarTech enabled solutions. By actively reimagining how the virtual space can be revolutionised by leveraging data and technology, new doors have opened for marketers.Eventually, the consumer is a principal element in the circle of marketing. If you can navigate your way through the layers and communicate with your consumers one-on-one, your job is half done. Understanding how a consumer behaviour changes, which platforms are evolving and how a brand can benefit from this change forms a part of a routine day of a marketer. Blurry research and vague insights are close to dangerous when an important campaign is built. The only way a creative team can now curate impactful marketing campaigns, keep their consumers happy, and craft branding strategies are by collaborating with marketing technologists. This is possible when brands shall start talking less and listening more.With its ability to be agile and be accurate at the same time, many companies have found themselves associating with mar-tech enabled/mar-tech first digital firms to help them make informed decisions about the industry for their brands. One of the most common marketing technology services is a Marketing Cloud. It is made up of a suite of cloud-based marketing tools, that covers analytics, targeting, social media management, customer experience and much more. It reduces the time spent on basic work and allows you to put that time in doing skill work. Eventually, it offers you standardised access to quality insights and other important data. It primarily allows you to build and manage your campaigns, and let your brand evolve into that space.That being said, it is right to believe that MarTech has just crossed the nascent stage and is undergoing constant evolution for a larger reach. Many traditional marketers have raised their concerns and named it as an experimental process. In contrast to these opinions, many digitally mature brands like Ola, Swiggy, OYO Rooms etc. have been working closely with companies that offer MarTech solutions and are benefitting from their services.With every passing year, month, day and minute, the consumers are getting smart; MarTech is a trick/short cut to understand them better and get smarter than them before they blink. It is not an off-shelf product, it is an enabler which grows with the brand and it shouldn’t be a commodity which can be bought and left on autopilot, but a strategy platform to be invested in.DISCLAIMER: The views expressed are solely of the author and ETBrandEquity.com does not necessarily subscribe to it. ETBrandEquity.com shall not be responsible for any damage caused to any person/organisation directly or indirectly.Shrenik Gandhi, CEO and co-founder - White Rivers Media, is an entrepreneurpassionate about solving business problems withinsightful digital marketingShrenik Gandhi, CEO and co-founder - White Rivers Media, is an entrepreneurpassionate about solving business problems withinsightful digital marketingTom Rettig Vice President of Product, Music, GracenoteShiv Shivakumar Group executive president - corporate strategy & business development, Aditya Birla GroupRana Bawa President, Healthcare and PR, OgilvyMariellen Ward digital storyteller, BreathedreamgoBalaji Srinivasan Traveller, Traveholics.comFrom the newsroom of The Economic Times"
https://mashable.com/2018/04/29/tesla-autopilot-passenger-seat/,"Teslas can do some pretty amazing things. From self-parking abilities to its semiautonomous Autopilot mode, the cars can definitely feel like the future. And yet, that doesn't mean you can just kick back in the passenger seat while Autopilot is engaged.SEE ALSO: 9 companies trying to be the 'Tesla of China'A British Tesla owner has found himself in hot water for doing just that, though. Bhavesh Patel, has been banned from driving for 18 months after a court found him guilty of dangerous driving for sitting in the passenger seat while his Tesla drove through traffic, according to The New York Times.Patel was also ordered to pay an £1,800 fine and complete 100 hours of community service for the stunt, which was captured on video by another driver. It should really go without saying, but what Patel did was incredibly dangerous. Just because Tesla's Autopilot feature may seem foolproof, doesn't mean it is. ""Every driver is responsible for remaining alert and active when using Autopilot, and must be prepared to take action at any time,"" Tesla says.In the United States, there have been at least two fatal crashed associated with the feature, including one in 2016 caused by the ""driver’s inattention due to overreliance on vehicle automation,"" according to the National Transportation Safety Board. More recently, a fatal crash in California last month happened while Autopilot was engaged. The driver's hands were not on the steering wheel in the seconds leading up to the crash according to Tesla."
https://electrek.co/2018/07/17/tesla-autopilot-miles-shadow-mode-report/,"JULY 17Fred Lambert- Jul. 17th 2018 2:32 pm ET@FredericLambertAutomakers and tech companies are rushing to bring autonomous driving systems to market and accumulating mileage with their test vehicles.Tesla is taking a different approach by accumulating mileage with its customer fleet through its Autopilot driver assist program.A new report now estimates that Tesla has accumulated over 1.2 billion miles on Autopilot and more than twice that when accounting for mileage in ‘shadow mode’.The report was produced and is being updated by a MIT Human-Centered AI team led by Lex Fridman.We reported on the team’s work with Tesla Autopilot in the past after they launched a study on driver interaction with Tesla Autopilot features last year by adding driver-facing cameras to Model S vehicles.They released some interesting preliminary results and Fridman, the postdoctoral associate at the MIT Agelab responsible for the study, said that he had been in contact with Tesla about his research and he believes the technology is required to enable more advanced autonomous features.As part of their continuous work with Autopilot, they have been trying to track Tesla’s total miles accumulated using the driver assist system.In a new report, they claim that Tesla has now accumulated over 1.2 billion Autopilot miles:To be clear, that’s the mileage driven with Autopilot activated. Back in 2016, Tesla already had 1.3 billion miles driven with vehicles equipped with Autopilot. Tesla can still use data from those miles, but it’s not the same has mileage driven with Autopilot on.That data is often referred to as “shadow mode” mileage because the autonomous driving system runs in the background of the vehicle without being able to have any input on the driving.The MIT team has also tried to estimate the total of shadow mode miles:In both cases, they plotted the data based on the few occasions when Tesla actually released some of the data.It can be difficult to do that since the growth is exponential but not necessarily stable since Tesla said that it can detect dips in Autopilot usage by its fleet when there’s negative media coverage, which has been quite common over the last year.What would be particularly interesting about Tesla crossing 1 billion miles of Autopilot use is that CEO Elon Musk has previously mentioned the milestone as the minimum they would need to move Autosteer from ‘beta’ to a regular feature.Musk recently said that Autopilot is going to get some significant updates this summer and he says that progress could lead to the promised fully autonomous software being ready for the end of next year. Though he also said that Tesla’s version 9 software update is coming in August with the first ‘full self-driving features’.As for the kind of data that Tesla collects from Autopilot, we recently got a rare great look at what Tesla Autopilot can see and interpret – pictured above.Tesla is a transportation and energy company. It sells vehicles under its 'Tesla Motors' division and stationary battery pack for home, commercial and utility-scale projects under its 'Tesla Energy' division.The Autopilot is Tesla's advanced assisted driving program with features like Autosteer, Autopark, and Trafic-Aware Cruise Control (TACC).@FredericLambertFred is the Editor in Chief and Main Writer at Electrek.You can send tips on Twitter (DMs open) or via email: fred@9to5mac.comIf you want to help Fred and Electrek, you can contribute to our Patreon: https://www.patreon.com/electrekElectrek Podcast: Tesla craziness intensifies, base Mod...Tesla could make a $25,000 electric car in ‘about..."
https://fox5sandiego.com/2018/08/11/can-this-thing-do-a-backflip-hear-the-audio-from-seattle-plane-theft-crash/,"SEATTLE — Before he crashed and died, the airline worker who authorities said stole and flew a passenger plane in the Seattle area Friday had a wide-ranging discussion with air traffic control — at one point expressing confidence in his flying ability because “I’ve played some video games.”In audio recordings posted on Broadcastify, the man can be heard both resisting and seeking help as a controller and others tried to guide the otherwise unoccupied Horizon Air plane to a landing.The Pierce County Sheriff’s Department described the man as suicidal but did not elaborate. At times he was apologetic, expressed his desire to fly toward the nearby Olympic Mountains, worried about lightheadedness and expressed shock at his fuel level’s rapid decrease.Here are portions of Friday evening’s recordings in the order they occurred. The conversations took place before the 76-seat, twin-engine turboprop plane crashed on Ketron Island, about 25 miles southwest of where he took off at Seattle-Tacoma International Airport, also known as Sea-Tac:Early in the flight, a controller apparently is giving instructions to the man flying the plane.Man flying plane: “Yeah, that’s all mumbo ju… — I have no idea what all that means. I wouldn’t know how to punch it in. I’m off autopilot.”The man wonders aloud whether a controller is trying to direct the plane toward “jets.”Controller: “No, I’m not taking you to any jets. I’m actually keeping you away from aircraft that are trying to land at Sea-Tac.”Man: “Oh, OK, yeah, yeah, I don’t want to want to screw with that. I’m glad you’re not … screwing up everyone else’s day on account of me.”The man starts commenting on fuel.Man: “I’m down to 2,100. I started at like 30-something.”Controller: “You said you had 2,100 pounds of fuel left?”Man: “Yeah, I don’t know what the burn … burnout is like on takeoff, but yeah, it’s burned quite a bit faster than I expected.”Multiple times, a controller tried to persuade the man to land at the Air Force’s nearby McChord Field.Man: “Oh man, those guys would rough me up if I tried landing there. I think I might mess something up there, too. I wouldn’t want to do that. Oh, they’ve probably got anti-aircraft!”Controller: “No, they don’t have any of that stuff. We’re just trying to find a place for you to land safely.”Man: “Yeah, not quite ready to bring it down just yet. But holy smokes, I’ve got to stop looking at the fuel, because it’s going down quick.”As a controller tries to relay instructions, the man wonders about jail time.Controller: If you could, could you start a left-hand turn, and we’ll take you down to the southeast, please?Man: “This is probably like jail time for life, huh? I mean, I would hope it is, for a guy like me.”Controller: “Well … we’re not going to worry or think about that. But could you start a left-hand turn, please?A controller brings on the radio a pilot who will try to relay instructions.Controller: “… Apparently a grounds crewman with Horizon, I guess. And uh, right now he’s just flying around, and just he needs some help controlling his aircraft.”Man: “Nah, I mean, I don’t need that much help. I’ve played some video games before.”Immediately after that, the man implies he’s feeling lightheaded.Man: “I would like to figure out how to get this cabin altitude, like, I know where the box is. I would like to get some, uh, make it pressurized or something, so I’m not so lightheaded.”Controller: “… What’s your altitude?”There is no immediate answer on the recording.About a minute later, in response to an apparently unrecorded question from a controller about autopilot, the man speaks again.Man: “Yeah, I don’t know anything about the autopilot. I’m just kind of hand-flying right now.”The recording later picks up a snippet in which the man says he doesn’t want to hurt anyone.Man: “Damn it … people’s lives are at stake here.”Controller: “Now … don’t say stuff like that.”Man: “No, I told you. I don’t want to hurt no one. I just want you to whisper sweet nothings in my ear.”As mentioned, controllers brought a pilot into the conversation to help the man. The pilot appears to be trying to teach him how to use autopilot.Later, the controller again tries to persuade him to land at McChord.Controller: “If you wanted to land, probably the best bet is that runway just ahead and to your left. Again, that’s McChord Field. If you wanted to try, that might be the best way to set up and see if you can land there. Or just like the pilot suggests, another option would be over Puget Sound into the water.”Man: “Dang. You talked to McChord yet? ‘Cause I don’t think I’d be happy with you telling me I could land like that, ’cause I could mess some stuff up.”Controller: “… I already talked to them. Just like me, what we want to see is you not get hurt or anybody else get hurt. So like I said, if you want to try to land, that’s probably the best place to go.”The man asks for the pilot who has been giving advice.Man: “I wanna know what this weather’s going to be like in the Olympics (mountains).”Helping pilot: “If you can see the Olympics, the weather’s good. I can see the Olympics from my window, and it looks pretty good over there.”Man: “All right. ‘Cause I hit some, it felt like turbulence, around (Mount) Rainier. But there was no clouds, hardly.”Helping pilot: “That’s just the wind blowing over all the … surfaces there.”Controller: “If you could, maybe start a left-hand turn, start turning back around, because if you get too close to the Olympics, you won’t be able to hear us anymore.”Controller: “Turn back around here. Like I said, I just want to keep talking to you, and if you keep going toward the Olympic Mountains, we won’t be able to hear each other.”An airline employee stole an otherwise unoccupied passenger plane Friday from the Seattle-Tacoma International Airport and flew it for an hour with military jets chasing him before crashing in a wooded area 40 miles away.Soon after that, the man apologizes and says he is a “broken guy” with “a few screws loose.”Man: “I’ve got a lot of people that care about me, and it’s going to disappoint them to hear that I did this. I would like to apologize to each and every one of them. Just a broken guy, got a few screws loose, I guess. Never really knew it until now.”Man: “Man, have you been to the Olympics? These guys are gorgeous! Holy smokes.”Controller: “Yeah, I have been out there. It’s always a nice drive.”The man says something that isn’t heard well on the recording.Controller: Yeah, I bet you do. I haven’t done much hiking over there. But if you could, if you could start a left turn and turn back toward (unintelligible). I know you’re getting a good view there, but if you go too much further in that direction, I won’t be able to hear you anymore.”The man responds by talking about doing a roll.Man: “Alrighty. Uh, hey, pilot guy. Can this thing do a backflip, you think?”Man: “… I’m gonna land it. Like, in a safe kind of manner. I think I’m going to try to do a barrel roll, and if that goes good, I’m just gonna go nose down and call it a night.”Controller: “Well … before you do that, let’s think about this. I’ve got another pilot coming … in just a minute or two, and we’ll be able to give you advice on what to do next.”About six minutes later, a controller asks the man how much fuel he has left.Man: “Oh man, not enough. Not enough to get by. Like 760 pounds.”Once again, he starts talking about a roll.Man: “I’m gonna do this barrel roll real quick.”Controller: “Well, no need to do that. If you could just start a turn to the right. And then I’ll tell you when to stop turning, and then you can keep it level from there.”About two minutes go by.Man: “I feel like I need to be, what do you think, like, 5,000 feet at least to be able to pull this barrel roll off?”Eventually, chatter appears to reference a maneuver the stolen plane has just done.(Video from a witness on the ground shows the plane at one point doing a loop, putting the aircraft upside-down, then pulling up just feet above a body of water. It’s unclear if this roll is what the radio chatter is referring to.)Helping pilot: “Congratulations. You did that. Now let’s land that airplane safely and don’t hurt anybody on the ground.”Man: “Awwww-right. Ah, damn it. I don’t know, man! I don’t know! I don’t want to. I was kinda hoping that was going to be it. You know?”A minute later, the man mentions engine trouble.Man: “Not for long. I feel like one of my engines is going out or something.”Controller: “OK … if you could, you just want to keep that plane right over the water, maybe keep the aircraft nice and low.”TRADEMARK AND COPYRIGHT 2018 CABLE NEWS NETWORK, INC., A TIME WARNER COMPANY. ALL RIGHTS RESERVED.FILED IN: NEWSTOPICS: IN CASE YOU MISSED IT, PLANE, PLANE CRASH, SEATTLE PLANE CRASHGet the latest news and streaming video from FOX 5 San Diego while on the go.ONLINE PUBLIC FILE • TERMS OF SERVICE • PRIVACY POLICY • 7191 ENGINEER RD. SAN DIEGO, CA 92111 • COPYRIGHT © 2018, KSWB • A TRIBUNE BROADCASTING STATION • POWERED BY WORDPRESS.COM VIP"
https://www.reuters.com/article/us-tesla-autopilot/u-s-safety-agency-says-did-not-assess-tesla-autopilot-effectiveness-idUSKBN1I334A,"4 MIN READWASHINGTON (Reuters) - A U.S. traffic safety regulator on Wednesday contradicted Tesla Inc’s claim that the agency had found that its Autopilot technology significantly reduced crashes, saying that regulators “did not assess” the system’s effectiveness in a 2017 report.Autopilot, a form of advanced cruise control, handles some driving tasks and warns those behind the wheel they are always responsible for the vehicle’s safe operation, Tesla has said.The U.S. National Highway Traffic Safety Administration, which issued the statement, and National Transportation Safety Board are investigating a fatal crash in March in which the driver was using Autopilot.Following that fatality, Tesla pointed to a 2017 NHTSA report on a May 2016 fatality involving a driver using Autopilot. The report said crash rates fell by 40 percent after installation of Autopilot’s Autosteer function, and noted that this number was derived from Tesla airbag deployment data.The agency said on Wednesday its crash rate comparison “did not evaluate whether Autosteer was engaged” and “did not assess the effectiveness of this technology.”The agency described the Autopilot analysis in the 2017 report as a “cursory comparison” of airbag deployment rates before and after installation of the feature to determine whether models with Autosteer had higher crash rates. Such a finding “could have indicated that further investigation was necessary,” the agency said.Tesla declined to comment.In March, Tesla said that over a year ago, the U.S. government found that its first iteration of Autopilot reduced crash rates by as much as 40 percent. “Internal data confirms that recent updates to Autopilot have improved system reliability,” it added.On Jan. 19, 2017, Musk tweeted: “The data show that the Tesla vehicles crash rate dropped by almost 40 percent after Autosteer installation.” Autosteer, a system that automatically keeps the vehicle in the center of a lane, is part of the Autopilot technology package.The 2017 NHTSA probe found no evidence of a defect. Investigations into the death of Walter Huang, the driver in the March 23 Tesla car crash, are ongoing.The NTSB confirmed last month it had two other pending investigations of incidents involving Tesla vehicles, including an August 2017 Tesla battery fire in Lake Forest, California, after an owner lost control and ran the vehicle into his garage.The NTSB previously faulted Tesla in a 2016 fatal crash in Florida in which Autopilot was engaged. NTSB Chairman Robert Sumwalt said in 2017 that “system safeguards were lacking.”He also noted that “Tesla allowed the driver to use the system outside of the environment for which it was designed and the system gave far too much leeway to the driver to divert his attention.”Tesla said it had improved the system since the crash.Tesla on Wednesday told investors in its quarterly financial report that on March 15 it released a “significant Autopilot update” that has been well received by its customers.Reporting by David Shepardson and Alexandria Sage; Editing by Joseph White and Richard ChangSPONSOREDSPONSOREDAll quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.© 2018 Reuters. All Rights Reserved."
https://www.forbes.com/sites/sebastianblanco/2018/04/30/tesla-autopilot-stunt-loses-driver-license/,"Tesla Model S in RedTESLADespite the name, there's no question that Tesla doesn't want you to think of its Autopilot technology as a diving assistant and specifically not something that makes your electric car self-driving. But don't tell that to Bhavesh Patel who was recently fined for dangerous driving in the UK after turning on Autopilot and then, you know, hopping into the passenger seat. This was at 40 miles an hour and there were enough people around that, you know, someone shot a video of Patel in inaction.When the police came calling, Patel said he thought of his little maneuver as ""silly"" instead of dangerous, according to Autoblog. But, of course, relying on a not-quite-autonomous car to drive you is dangerous, as Tesla makes clear in the way it describes the technology:Autopilot is an increasingly capable suite of safety and convenience features that make personal transportation safer and more enjoyable. ... When used properly, drivers supported by Autopilot are safer than those operating without assistance. Eventually, full autonomy will enable a Tesla to be substantially safer than a human driver.In its current form, Autopilot is an advanced driver assistance system (ADAS) that classifies as a Level 2 automated system by the National Highway Transportation Safety Administration (NHTSA). It is designed as a hands-on experience to give drivers more confidence behind the wheel, increase their safety on the road, and make highway driving more enjoyable by reducing the driver's workload.As Autopilot technology continues to be developed, more advanced functionality will be made available to Tesla owners over time nearing full self-driving capabilities; however, until truly driverless cars are developed and approved by regulators, the driver is responsible for and must remain in control of their car at all times.So, yeah, that's what Autopilot is all about. Not as a way to leave the driver's seat, as Patel did (and, unfortunately, others on YouTube have done). Patel's driver's license was suspended for 18 months, so he now has time to think about actually driving while, you know, driving.I have been writing about electric vehicles, hybrids, and hydrogen since 2006. My articles and reviews have appeared on most of the big green car blogs, Automotive News, The New York Times, Car Talk, and other places. I believe the shift away from gasoline-powered vehicles i..."
https://edition.cnn.com/2018/06/26/motorsport/tesla-testing-mad-max-autopilot-mode/index.html,"By Motez Bishara, CNNUpdated 1018 GMT (1818 HKT) June 26, 2018(CNN)The futuristic film ""Mad Max"" is having a real-life moment, and those who drive in heavy traffic will understand why.We use cookies to understand how you use our site and to improve your experience. This includes personalizing content and advertising. To learn more, click here. By continuing to use our site, you accept our use of cookies, revised Privacy Policy and Terms of Use."
https://www.techradar.com/news/tesla-plans-autopilot-update-to-clarify-hold-steering-wheel-alert,"By Michelle Fitzsimmons June 14, 2018 Car tech  Tesla drivers are coming to grips with new alerts designed to ensure they stay engaged with their vehicle while it's in Autopilot mode, but one alert seems to be causing some confusion, to the point that CEO Elon Musk has promised a fix.The latest update to Autopilot includes a ""Hold Steering Wheel"" alert that pops up in 15 to 20 second intervals if it doesn't detect driver hands on the wheel, reports Electrek. Seems like a sensible safety measure, but it's how the wheel is detecting driver grips that's frustrating Tesla owners. According to at least one driver, he now needs to ""white knuckle death grip the wheel to keep away the nags."" Replying to this driver's tweet, Musk said: ""Will be adjusting alert to clarify that we mean 'slight up or downward force on the wheel', not really 'hold the wheel'"".@elonmusk 2018.21.9 is a pain. I now need to white knuckle death grip the wheel to keep away the nags. Don’t need to keep my foot on the peddles with old school cruise control!June 13, 2018So, whenever the next Autopilot update is released, drivers should only need to apply slight pressure to let the vehicle know they're engaged with the steering wheel. Tesla's Autopilot has come under scrutiny after a number of accidents that occurred when the self-driving feature was engaged, including a crash in March that resulted in the death of a Tesla driver who ignored warnings from his Model X.Tesla has maintained Autopilot is an assistance feature, not a full replacement for human drivers, though drivers have discovered hacks to trick the system into thinking they are holding the wheel when they really aren't.The new nag alerts may be annoying and in need of tweaking, but Tesla is in a position where it needs to keep drivers engaged with their vehicles and paying attention to the road, and not become overly reliant on the system. Via CNETGet the best tech deals, reviews, product advice, competitions, unmissable tech news and more!TechRadar is part of Future plc, an international media group and leading digital publisher. Visit our corporate site.© Future Publishing Limited Quay House, The Ambury, Bath BA1 1UA. All rights reserved. England and Wales company registration number 2008885."
https://www.digitaltrends.com/cars/tesla-autopilot-full-package-august/,"Tesla will start turning on fully autonomous features in the electric car manufacturer’s self-driving Autopilot software this August, according to CEO Elon Musk.Musk mentioned the next major Autopilot rollout when he addressed a comment in his Twitter feed from Twitter user Anand Krishnamurthy (@anandrajk). Krishnamurthy wrote, “Speaking of merging and autopilot the biggest issue i have noticed is when two lanes merge and it is rush hour traffic. The autopilot is not able to decide to let the car slightly ahead on the neighboring lane go ahead and I invariably find myself cornered !”Musk replied to Krishnamurthy’s comment with news about the next Autopilot update. “That issue is better in latest Autopilot software rolling out now & fully fixed in August update as part of our long-awaited Tesla Version 9. To date, Autopilot resources have rightly focused entirely on safety. With V9, we will begin to enable full self-driving features.”The last major Autopilot upgrade, Tesla Version 8.0, was in July 2016. Tesla updates vehicle software automatically via wireless connectivity; the company’s over-the-air (OTA) technology means owners don’t have to take their vehicles to a Tesla service center for new software.Between major program versions, Tesla tweaks the software with updates and fixes as necessary. The most recent minor update started rolling out June 10 with Autopilot version 2018.21.9, which attempts to increase driver attention when the Autopilot system is engaged. Tesla shortened the time from about two minutes to approximately 30 seconds before issuing visible and audible warnings when it detects the driver’s hands are not on the steering wheel.The latest update did not please Tesla owners. With the recent change, drivers placing their hands on the wheel isn’t enough to deter alerts. In answer to a Twitter comment, Musk wrote, “Will be adjusting screen alert to clarify that we mean ‘slight up or downward force on the wheel’, not really ‘hold the wheel.'”In an earlier Tweet, Musk expressed the frustration in achieving the optimal balance between driver complacency and driver annoyance in a system designed to improve safety. “Sigh. This is crux of matter: can’t make system too annoying or people won’t use it, negatively affecting safety, but also can’t allow people to get too complacent or safety again suffers. Latest update should have a positive effect on latter issue especially,” Musk wrote.With more vehicle autonomy coming in August, Tesla owners may yet again need to learn the safest way to use Autopilot."
https://bgr.com/2018/03/17/tesla-autopilot-update-winding-twisty-roads-video-improved/,"Tesla for some time has been teasing a huge Autopilot update that promises to deliver some huge improvements in performance and reliability. This past December, for example, Musk took to Twitter and said that Tesla has “the most advanced AI neural net of any consumer product by far” and that early testing on a revamped iteration of Autopilot has been mind-blowing. More recently, Musk a few weeks ago said that an impending update was already in its final testing phase.While Tesla boasting about the capabilities of Autopilot is nothing new, the company’s self-driving technology has been under the microscope in recent years. For one, there have been a number of high-profile accidents that have allegedly happened with Autopilot engaged. Most recently, a Model S on Autopilot crashed into a stationary fire truck on a California freeway. Second, Tesla in 2016 completely cut ties with Mobileye, the company that provided Tesla with Autopilot’s underlying sensors. Following that, Tesla introduced new Autopilot hardware based on sensors it built in-house.All that said, Tesla this week introduced a new update (2018.10.4) with some minor Autopilot enhancements, and Tesla owners, in predictable fashion, have been busy taking videos of the latest Autopilot features in action. While the release notes don’t mention any specific improvements, Electrek reports that users are “seeing a significant improvement in lane detection, a reduction of ‘ping-ponging’ within a lane, and a generally better experience when Autosteer is activated.”A few of the new videos can be seen below, with the first one showcasing a Model X crossing over a narrow bridge.The next video shows a Model S easily handling a winding and somewhat narrow road.Below is another video of a Tesla handling a windy road, this one located in the Santa Cruz Mountains.And one more video, just for good measure.Copyright 2018 BGR Media, LLCPowered by WordPress.com VIP | Privacy Policy | Your Privacy Rights | Ad Choices | Privacy Preferences | Terms Of Use"
https://mashable.com/2018/04/30/tesla-autopilot-save-truck-crash/,"Tesla's semi-autonomous driving mode, Autopilot, did what it's supposed to do — move the car out of harm's way.In a video from last week, a driver in a Tesla Model X was traveling on I-95 in North Carolina when a swerving semi-truck suddenly came into the Tesla's lane. The electric car automatically moves over onto the empty shoulder to avoid the oncoming traffic, and the driver then proceeds to move into the fast lane behind the truck.YouTuber Jeremy Visnesky seems to document the live-saving moments in the semi-autonomous vehicle. Visnesky shared another Tesla safety feature coming in handy over the weekend when the car slowed down and beeped to warn about a truck merging into a freeway lane. The video comes about a month after a fatal crash involving Autopilot, which killed a Tesla driver near San Francisco. Another Tesla driver managed to recreate the accident, showing the terrifying moment when Autopilot steered into danger instead of away.Ariana Grande tears up discussing her song about anxiety and the Manchester attackThe 'Star Wars: Resistance' trailer is here with plenty of Poe DameronDude has the worst day ever, documents it all on SnapchatTiffany Haddish says she 'would thrive in space'"
https://www.theverge.com/2018/5/2/17313324/tesla-autopilot-safety-statistics-elon-musk-q1-earnings,"Tesla will publish quarterly reports about the safety of its Autopilot driver assistance feature, CEO Elon Musk announced on a call with analysts Wednesday. Musk didn’t elaborate on exactly what the reports will entail, and a representative for Tesla declined to add any further detail. But the move could represent a major change in how the company treats data related to Autopilot, which is typically closely guarded.Musk argued on the call that there is “no question” that Autopilot reduces the chance of a driver getting in an accident, something both he and his company have often claimed in the past. “The statistics are unequivocal that Autopilot improves safety,” he said. Publishing these statistics about Autopilot’s performance will let the public know “exactly what Autopilot’s safety [level] is,” Musk said. “Is it getting better, is it getting worse?”It has not been easy to determine exactly how much Autopilot improves the safety of drivers, or even how to measure that in the first place. The most common figure Tesla and Musk use when making claims about Autopilot’s safety is that it was “found by the U.S. government to reduce crash rates by as much as 40%.” This statistic comes from the report that was filed at the conclusion of the National Highway Traffic Safety Administration’s investigation into the 2016 death of Joshua Brown, who was using Autopilot when his Tesla Model S crashed into a tractor trailer. But the veracity of the statistic has recently come under fire, and today NHTSA distanced itself from the claim. Tesla declined to comment on the news.Musk announced the plan to increase transparency around Autopilot after repeatedly criticizing press coverage of the company’s driver assistance feature, something he’s done on analyst calls in the past. Autopilot has faced increased scrutiny after a driver of a Tesla Model X died while using the driver assistance feature on a California highway in March.“I think theres 1.2 million automotive deaths per year, and how many do you read about? Basically none of them,” Musk said, referring to global statistics. “But if it’s an autonomous situation, it’s headline news. And the media fails to mention that, actually, they shouldn’t really be writing this story, they should be writing a story about how autonomous cars are really safe. But that’s not the story that people want to click on. So they write inflammatory headlines that are fundamentally misleading to the readers.” Musk didn’t clarify which reports he takes umbrage with, or whether he’s including local news coverage of vehicle fatalities in his criticism.The problem, Musk says, isn’t just that these “inflammatory headlines” are “misleading” to readers. He also argued that it’s affecting public policy. “Regulators respond to public pressure, and the press,” Musk said. “So if the press is hounding the regulators and the public is laboring on misapprehension that autonomy is less safe because of misleading press, then this is where I find things, the challenge for predicting it to be very difficult.”The “it” that Musk was referring to was the timeframe for the launch of the shared, autonomous fleet of Teslas that he referenced in the second company “master plan” that was released in 2016. Despite the difficulty in guessing how fast (or slow) regulations will move around self-driving cars in the coming years, Musk did say that on the technical side, he thinks a shared fleet of autonomous Teslas — one that he said would be like a mix of “Uber Lyft and AirBnB,” will “probably be ready by the end of next year.”Before Tesla gets there, though, it still needs to roll out full self-driving capability to the cars it is and has been making. While Tesla currently offers customers the ability to pre-pay for full self driving capability, the current version of Autopilot still more closely resembles advanced driver assistance systems like Cadillac’s Super Cruise.Meanwhile, a coast-to-coast demonstration of Tesla’s full self-driving capabilities has been delayed. Musk recently promised that the cross country drive is coming this year, though, and that the same capability will be made available to paying customers soon. Cars currently being made by Tesla should be able to handle full autonomy, Musk said, though he reiterated that the company may need to swap in more powerful computers to handle the processing power required.While Tesla is often cagey about the number of miles driven using Autopilot, Musk did say on the call that overall usage is increasing. For cars equipped with the feature, a third or “maybe half” of highway miles in “some regions” are now driven using Autopilot, he said.“But then of course when there’s negative news in the press, then that dips,” he added. “And then I was like, okay, this is not good, because people are reading things in the press that cause them to use Autopilot less, and then that makes it dangerous for our customers. And that’s not cool, that’s why I get upset.”RELATEDMusk has made this argument in the past — that “negative” press coverage about Autopilot could scare people into using the feature less, which in turn could put more people in harm’s way. But the Tesla CEO made a new argument about something he says the press gets wrong near the end of the call. Journalists often claim that a lack of understanding is to blame for Autopilot accidents, Musk said, but he believes the opposite is the case.“When there is a serious accident it is almost always, in fact maybe always, the case that it is an experienced user, and the issue is more one of complacency,” Musk said. “They just get too used to it. That tends to be more of an issue. It’s not a lack of understanding of what Autopilot can do. It’s [drivers] thinking they know more about Autopilot than they do.”Overconfidence in the system does seem to be a problem, whether it’s in the form of drivers hopping into the passenger seat of a Tesla or, as the company says happened in the fatal crash in March, when it appears that the driver received and ignored numerous prompts to retake control of the car.Some experts think problems like these could be mitigated with driver monitoring systems, like how Super Cruise watches drivers’ eyes to make sure they’re paying attention. In the Model S, X, and 3, Tesla only monitors driver attention by measuring resistance in the steering wheel. While it’s thought that a small camera in the Model 3 might someday used for driver monitoring, it has not yet been activated. A lack of robust driver monitoring systems was one of the criticisms laid out in the National Transportation Safety Board’s investigation into Brown’s death. Back then, the NTSB recommended that Tesla — along with other automakers — find ways to monitor driver attention that go beyond detecting steering-wheel engagement.Command Line delivers daily updates from the near-future."
https://www.entrepreneur.com/article/312709,"Tesla will be one of the first to tell you not to put too much faith in Autopilot. It's currently more of an advanced driver assist than a full self-driving system. However, one driver recently ignored that advice in dramatic fashion.Nottingham, U.K. resident Bhavesh Patel has received an 18-month driving ban after he was caught sitting in the passenger seat of his Model S on the M1 in May 2017. The man said he invoked Autopilot and was betting that its ""amazing"" semi-autonomous guidance would keep the car rolling at the estimated 40 MPH of surrounding traffic.He didn't crash, but that obviously didn't matter. Police noted that what he did was ""grossly irresponsible"" and was risking not just his life, but those of ""other innocent people."" On top of the ban, Patel has to work 100 unpaid hours, conduct 10 days of rehabilitation and pay £1,800 (about $2,480) in prosecution costs.It almost goes without saying why doing this would be dangerous: Autopilot can keep your car in its lane and maintain a traffic-appropriate speed, but it won't perform evasive maneuvers or otherwise react well in emergencies. There is a question about how long Patel managed to keep Autopilot going, though. The system requires that you keep your hands on the wheel. Ignore warnings for a minute and Autopilot will not only switch off for the rest of the drive, but (if you continue to ignore it) bring the car to a complete halt. Patel most likely stayed in the passenger's seat for just a brief period, but it's slightly disconcerting that he had any time to crawl around the Model S without Autopilot bringing his experiment to a premature end. "
https://www.washingtonpost.com/news/innovations/wp/2018/04/30/tesla-driver-turns-on-autopilot-and-climbs-into-the-passenger-seat-on-british-highway/,"A man appeared to want to test the limits of Tesla’s Autopilot feature, and a British court has made an example of him.The St. Albans Crown Court recently banned Bhavesh Patel, 39, from driving for 18 months for climbing into the passenger seat of his Model S after turning on its semiautonomous feature. Tesla instructs drivers to keep their hands on the steering wheel while Autopilot is activated.The police, citing witness accounts, said Patel’s Model S was traveling about 40 mph in heavy traffic last year. According to a video taken by a witness, no one was sitting in the driver’s seat, and Patel appeared to have his hands behind his head. Patel was later interviewed by officers at a police station, law enforcement officials said, where he admitted that he knew his actions were “silly” but the car was capable of something “amazing.”He told police he was just the “unlucky one who got caught.”Patel pleaded guilty to dangerous driving, law enforcement officials said Friday.Attempts to contact Patel were unsuccessful.The incident highlights the risks and disregard for safety precautions of such technology. Patel’s use of Autopilot underscores how up-and-coming self-driving technology might tempt users to abuse it without fully understanding its limitations. Researchers and other technology developers say human behavior makes it easy to become overly reliant on autonomous technology. In March, a Tesla owner in California died after his electric SUV crashed into a median while the vehicle was in Autopilot mode on Highway 101 near Mountain View. The company and the National Transportation Safety Board have publicly clashed in recent weeks over the disclosure of information related to the crash as a federal investigation of the collision continues.Tesla referred The Washington Post to prior statements that said its Autopilot feature is intended for use only by a fully attentive driver. Drivers receive an escalating series of audio and visual warnings if the car detects that the driver’s hands are not on the steering wheel. If a driver ignores those warnings, the car will disengage the Autopilot system for the remainder of the drive.“What Patel did was grossly irresponsible and could have easily ended in tragedy,” investigating officer Kirk Caldicutt of the Bedfordshire, Cambridgeshire and Hertfordshire Road Policing Unit said in a statement last week. “This case should serve as an example to all drivers who have access to autopilot controls and have thought about attempting something similar. I want to stress that they are in no way a substitute for a competent motorist in the driving seat who can react appropriately to the road ahead.”On top of the 18-month ban, Patel was ordered to perform 100 hours of community service. He is also slated to carry out 10 days of rehabilitation and was fined 1,800 pounds (about $2,500) to offset the costs of the Crown Prosecution Service."
https://www.theinquirer.net/inquirer/news/3032649/tesla-open-sources-some-of-its-autopilot-source-code,"ELECTRIC CAR MAKER Tesla tends to keep the details of its work under lock and key, but now Elon Musk's company is plonking some of its automotive tech source code into the open source community.Tesla dumped some of its code used to build the foundations of its Autopilot semi-autonomous driving tech and the infotainment system found on the Model S and Model X cars, which makes uses of Nvidia's Tegra chipset, on GitHub.Even if you're code-savvy, don't go expecting to build your own autonomous driving platform on top of this source code, as Tesla has still kept the complete Autopilot framework under wraps, as well as deeper details of the infotainment system found in its cars. But it could give code wranglers a better look into how Tesla approaches building infotainment systems and giving its cars a dose of self-driving smarts.You might think Tesla is being generous in open sourcing some of its code, given the stringent competition in the car world. But the move looks to be motivated by the company's violation of the General Public License (GPL).Tesla builds Autopilot on top of open platforms such as Linux and BusyBox which, under GPL rules, requires users to share their source code, something Tesla has failed to do until now.Tesla may have dragged its feet, but by open sourcing some of its source code, it has won the approval of the Software Freedom Conservancy.""While Tesla acknowledges that they still have more work to do, their recent actions show progress toward compliance and a commitment to getting all the way there,"" the open source loving organisation said.""We know many of you, particularly those Linux-savvy folks who bought Tesla vehicles, have reached high levels of frustration with the lengthy time this GPL compliance effort is taking. Nevertheless, this situation shows precisely why patience is essential for successful enforcement work; it gives us the opportunity to welcome violators to become contributors to the copyleft software community.""While getting a peek inside Tesla's Autopilot system sounds pretty interesting for people with a head for code, we'd be keen to see open source schematics to make our own Boring company-style flamethrower, because some people just want to watch the world burn. µA surprisingly busy week in a quiet monthMeasures just 15.75mm at its thickest point#sorrynotsorryFirm expects GPU sales to start drying up© Incisive Business Media (IP) Limited, Published by Incisive Business Media Limited, New London House, 172 Drury Lane, London WC2B 5QR, registered in England and Wales with company registration numbers 09177174 & 09178013We use cookies so that we can improve your experience of our site. Read our privacy and cookies policy to find out more."
https://electrek.co/2018/06/11/tesla-ai-director-insights-autopilot-computer-vision-neural-net/,"JUNE 11Fred Lambert- Jun. 11th 2018 6:43 am ET@FredericLambertAndrej Karpathy, Tesla’s director of AI and computer vision, is currently hard at work trying to improve Autopilot by training Tesla’s neural net with incredible amounts of data from Tesla’s fleet.He took a break from it to give some interesting insights into the development at a conference last month.At Train AI last month, Karpathy gave a quick talk about the history of computer vision software and the transition to what he now calls “software 2.0” where engineers are stepping back from designing software and instead utilizing machine learning to create the programs.He explained how it applies to Tesla and specifically the company’s autonomous driving effort.The engineer refers to Tesla’s vehicles as “robots” and therefore, he says that Tesla has the largest deployment of robots in the world with a fleet of over 250,000 vehicles.Now he needs to train those robots to drive themselves.Karpathy says that since joining Tesla 11 months ago, he has pushed for more “software 2.0” in Tesla’s Autopilot stack, which he illustrated with those images:He is likely referring to the rewrite of Tesla’s neural net that was pushed in the Autopilot software update back in March, which featured a significant improvement in Autopilot capabilities.Now that the neural net is slowly taking over the code of Tesla’s Autopilot, Karpathy says that the team is focusing on labeling and creating the dataset infrastructure.Karpathy explained that since he joined Tesla, the reason for the amount of sleep that he is losing has shifted from the actual modeling and algorithms to handling the datasets:As an example, he describes how labeling different types of road lines can be quite complex due to the variety of lanes across different regions.He gave another example of Tesla’s dataset with traffic lights, which he says can “get crazy really fast”:Karpathy explained that it takes “time and attention” to build a dataset and it is “painful,” which is why they are trying to build new tools at Tesla to help them create “software 2.0” code.The presentation is really interesting and if you have half an hour, I suggest you take a look:Here’s the PDF of his presentation:Tesla is a transportation and energy company. It sells vehicles under its 'Tesla Motors' division and stationary battery pack for home, commercial and utility-scale projects under its 'Tesla Energy' division.The Autopilot is Tesla's advanced assisted driving program with features like Autosteer, Autopark, and Trafic-Aware Cruise Control (TACC).@FredericLambertFred is the Editor in Chief and Main Writer at Electrek.You can send tips on Twitter (DMs open) or via email: fred@9to5mac.comIf you want to help Fred and Electrek, you can contribute to our Patreon: https://www.patreon.com/electrekElectrek Podcast: Tesla craziness intensifies, base Mod...Tesla could make a $25,000 electric car in ‘about..."
https://www.bloomberg.com/news/articles/2018-04-26/tesla-says-autopilot-vice-president-keller-is-leaving-carmaker,"Your usage has been flagged as a violation of our terms of service.For inquiries related to this message please contact support. For sales inquiries, please visit http://www.bloomberg.com/professional/request-demo"
https://markets.businessinsider.com/news/stocks/global-luxury-yacht-market-2018-2022-key-vendors-are-amels-azimut-benetti-feadship-isa-yachts-overmarine-group-1027467983,"DUBLIN, Aug 17, 2018 /PRNewswire/ --The ""Global Luxury Yacht Market 2018-2022"" report has been added to ResearchAndMarkets.com's offering.The global luxury yacht market to register a CAGR of 11.63% during the period 2018-2022.Global Luxury Yacht Market 2018-2022, has been prepared based on an in-depth market analysis with inputs from industry experts. The report covers the market landscape and its growth prospects over the coming years. The report also includes a discussion of the key vendors operating in this market.According to the report, one driver in the market is increase in recreational tourism. Tourism is a major economic activity across the globe and is a significant contributor to economic growth, employment, and social development of numerous countries. It also plays a key role in the global luxury yacht market, where commercial yacht operators or fleet operators form a significant part of business.One trend in the market is focus of yacht makers on emerging markets. As the European yacht market is witnessing a slowdown due to postponed purchases and declining economic situation, yacht makers are shifting their focus toward emerging markets, such as China and Latin America.Further, the report states that one challenge in the market is high cost of operations. Motor luxury yachts have every modern convenience installed onboard, such as ACs, television, navigation aids, radar, echo-sounding, and autopilot. In order to power all these amenities, luxury yachts require a reliable power generating system.Key questions answered in this reportKey vendorsKey Topics Covered:  PART 01: EXECUTIVE SUMMARY  PART 02: SCOPE OF THE REPORT  PART 03: RESEARCH METHODOLOGY  PART 04: MARKET LANDSCAPEPART 05: MARKET SIZINGPART 06: FIVE FORCES ANALYSISPART 07: MARKET SEGMENTATION BY PROPULSIONPART 08: CUSTOMER LANDSCAPE  PART 09: REGIONAL LANDSCAPEPART 10: DECISION FRAMEWORK  PART 11: DRIVERS AND CHALLENGESPART 12: MARKET TRENDSPART 13: VENDOR LANDSCAPEPART 14: VENDOR ANALYSISFor more information about this report visit https://www.researchandmarkets.com/research/psxl69/global_luxury?w=5Media Contact:Research and Markets Laura Wood, Senior Manager press@researchandmarkets.com     For E.S.T Office Hours Call +1-917-300-0470 For U.S./CAN Toll Free Call +1-800-526-8630 For GMT Office Hours Call +353-1-416-8900  U.S. Fax: 646-607-1907 Fax (outside U.S.): +353-1-481-1716View original content:http://www.prnewswire.com/news-releases/global-luxury-yacht-market-2018-2022---key-vendors-are-amels-azimut-benetti-feadship-isa-yachts--overmarine-group-300698870.htmlSOURCE Research and Markets"
https://www.sfchronicle.com/business/article/Tesla-s-Autopilot-suspected-in-fatal-accident-12889035.php,"Alex Holmes was heading home in his Tesla Model X one June night last year, using Autopilot to let the vehicle steer itself on Interstate 5 in the Los Angeles area, when it abruptly veered to the right.He snapped the Model X back into its lane, and his startled wife asked if he or the SUV were responsible for the sudden shift. He told her it wasn’t him.“I’ve got to send that to Tesla,” Holmes said.Since Tesla first introduced Autopilot in 2015, drivers have sometimes noted unexplained swerves and lane changes, discussing them with each other online or, in several cases, complaining about them to the federal government. Holmes posted a dashcam video of his June 2017 incident in a forum for Tesla owners.Autopilot’s performance has come under increased scrutiny since a Tesla Model X, steering itself, slammed into a freeway median on Highway 101 in Mountain View in March, killing its owner.Relatives of the man, Apple engineer Walter Huang, said he had complained of the vehicle veering toward that same median before. The family is now preparing to sue Tesla, arguing that Autopilot is defective. Tesla has argued that the crash could not have happened if Huang had been paying attention, as Tesla advises all drivers using Autopilot to do. The National Transportation Safety Board is investigating.When Tesla CEO Elon Musk unveiled Autopilot in October 2015, he emphasized that the system would constantly learn from all the cars running it, pooling their data and gaining experience, much like a human driver would.“The whole Tesla fleet operates as a network — when one car learns something, they all learn it,” he told reporters at the time. “People should see the car actually improve with each passing week, even without a software upgrade, because the data is continually improving.”Autopilot has now gone through two major iterations, with an expanded hardware suite introduced in October 2016, and numerous software upgrades. The most recent upgrade, issued in mid-March, has received positive reviews for improved performance.And yet, the issue of unexpected veering, drifting and lane-shifting has popped up repeatedly. The most recent driver complaint to the National Highway Traffic Safety Administration concerning Autopilot, filed April 22 by an unidentified Los Angeles driver, said the driver’s Tesla had abruptly veered toward a bridge abutment in August, and added that similar problems had happened multiple times.“The way Autopilot suddenly swerves out of the lane should not be considered normal,” the driver wrote.After the recent Mountain View crash, another driver posted video online showing his Tesla, on Autopilot, veering toward the same median where Huang died. Teslas are a common sight on that stretch of Highway 101, at the junction of Highway 85, so cars running on Autopilot should have plenty of experience with it.“I see the same things: The car makes the same mistake in the same place, and it’s not learning,” said Dave Sullivan, manager of product analysis at automotive market research firm AutoPacific. “The car doesn’t necessarily know what’s right from what’s wrong yet.”The company's Autopilot program has also been hit by executive turnover. Last month, Tesla's top Autopilot executive, Jim Keller, left the automaker for a position at Intel, becoming the third senior Autopilot leader to depart in the last two years.Tesla insists that Autopilot makes its cars substantially safer, although the company does warn buyers at length about the system’s limitations.During a conference call last week to discuss the Palo Alto company’s latest quarterly earnings, Musk bristled at recent news coverage questioning Autopilot’s safety, saying such reports mislead drivers and could even put lives at risk. Tesla, he said, would start publishing quarterly reports on Autopilot safety, although he did not discuss what data would be included.“It’s really incredibly irresponsible of any journalist with integrity to write an article that would lead people to believe that Tesla autonomy is less safe, because then people might actually turn it off and then die,” he said.He also emphasized a point that researchers and entrepreneurs in the fast-growing field of self-driving cars have often made: Even fully autonomous vehicles will not completely eliminate accidents. Autopilot is not full autonomy, although it has been viewed as an important step in that direction.“The thing that’s tricky with autonomous vehicles is that autonomy doesn’t reduce the accident rate or fatality rate to zero,” Musk said. “It improves it substantially.”While Autopilot can handle many of the tasks of freeway driving — keeping in lane, switching lanes, adapting speed to surrounding traffic — Tesla insists that drivers pay attention while using it.The system monitors whether drivers have their hands on the wheel and warns them when they don’t. That hasn’t stopped some drivers from abusing Autopilot, including a British man who lost his license after he engaged Autopilot on the M1 highway and climbed into the passenger seat to relax.Tesla owner manuals list, in detail, situations in which Autopilot may not work properly.Faded lane markings can throw it off, as can direct sunlight interfering with the car’s cameras. Sharp curves in the road, hills, construction zones, toll booths, seams in the pavement and weather conditions that cut visibility all can hamper Autopilot’s performance.While a sudden swerve or lane shift may seem unexplained to the driver, it may represent the car reacting to one or more of those conditions.In the dashcam video posted by Holmes, the car starts to shift lanes as it approaches an overpass that appears to be undergoing renovation or construction. Broad lines of what may be dust cut from his lane to the right, and Autopilot, which relies heavily on cameras to interpret its surroundings, may have been following them.“It was, in fact, in a construction zone, and the reason for the car swerving was valid,” said Holmes, a former tight end for the Miami Dolphins and now co-CEO of Wild Hair Media.While most companies developing self-driving technology use lidar — a laser version of radar — to scan a car’s surroundings, Tesla doesn’t. Musk argues that expensive lidar systems won’t be needed once the systems that interpret visual information from cameras become sufficiently refined. Autopilot relies on a suite of cameras, radar and ultrasonic sensors.On another drive, Holmes’ Model X in Autopilot almost clipped another vehicle. And yet Holmes, who describes himself as “the biggest Tesla fan ever,” uses Autopilot almost every day. Despite those two incidents, he’s come to trust it, even though he still pays attention.“Driving in L.A. is tough in traffic,” he said. “It’s a lot easier to not worry about it.”David R. Baker is a San Francisco Chronicle staff writer. Email: dbaker@sfchronicle.com Twitter: @DavidBakerSFDavid Baker covers energy, clean tech, electric vehicles and self-driving cars for the San Francisco Chronicle. He joined the paper in 2000 after spending five years in Southern California reporting for the Los Angeles Times and the Daily News of Los Angeles. He has reported from wind farms, geothermal fields, solar power plants, oil fields and an offshore drilling rig in the Gulf of Mexico. He also visited Baghdad and Basra in 2003 to write about Iraq's reconstruction. He graduated from Amherst College and the Columbia University Graduate School of Journalism. He lives in San Francisco with his wife. You must be signed in to commentABOUTCONTACTSERVICES©2018 Hearst"
https://www.reuters.com/article/tesla-autopilot/us-safety-agency-prior-probe-did-not-assess-effectiveness-of-tesla-autopilot-idUSL1N1S91XY,"Reuters Staff1 MIN READWASHINGTON, May 2 (Reuters) - The U.S. National Highway Traffic Safety said Wednesday that a prior investigation into Tesla Inc’s semi-autonomous “Autopilot” self-driving system did not assess the “effectiveness” of the technology.In 2017, NHTSA closed a probe into a May 2016 fatal crash involving a driver using the system and cited data from the automaker that crash rates fell by 40 percent after installation of Autopilot’s Autosteer function. Tesla has repeatedly cited the statistic in defending the system. NHTSA said Wednesday that its crash rate comparison “did not evaluate whether Autosteer was engaged.” The agency added that it “performed this cursory comparison of the rates before and after installation of the feature to determine whether models equipped with Autosteer were associated with higher crash rates, which could have indicated that further investigation was necessary.” Tesla did not immediately comment Wednesday. (Reporting by David Shepardson; Editing by Lisa Shumaker)All quotes delayed a minimum of 15 minutes. See here for a complete list of exchanges and delays.© 2018 Reuters. All Rights Reserved."
https://mashable.com/2018/05/15/tesla-crash-autopilot-elon-musk/,"A woman rear-ended a fire truck in Utah last week and broke her ankle in the crash. That in and of itself doesn't seem like the typical story that would trigger national coverage, but because a Tesla electric car with semi-autonomous features was involved, everyone's talking about it. SEE ALSO: Pro-tip: Tesla's autopilot doesn't mean you can sit in the passenger seatThis week, Tesla CEO Elon Musk doubled (tripled? quadrupled?) down on the safety of Tesla's Autopilot feature — a semi-automated driver assistance mode Tesla introduced to its cars in 2014 and now comes with every vehicle. The stat Musk and the company repeated (and will continue to repeat) about Autopilot reducing crash rates by 40 percent came under some scrutiny earlier this month. Wired found that the National Highway Transportation Safety Administration-backed stat is likely based on flawed, unreliable data.Because this sensor- and camera-heavy technology is still relatively new and constantly under development it warrants a closer look. Most drivers don't consider Autopilot and other semi-autonomous features commonplace even if Musk does. His stance may show how out of touch he is with the regular motorist.It's still unclear if the crash in South Jordan, Utah, was the fault of the Autopilot program gone awry. The woman told police she was on her phone while Autopilot was engaged in her Model S, which is the exact situation Tesla warns about. If you're not paying attention crashes can happen. Tesla told Jalopnik that it hasn't received any data about the incident and can't definitively say whether or not Autopilot was engaged. We reached out Tesla for more about the crash, but have yet to hear back.Police went out of their way to reiterate Tesla's warnings about automated features: ""It is the driver’s responsibility to stay alert, drive safely, and be in control of the vehicle at all times. Tesla makes it clear that drivers should always watch the road in front of them and be prepared to take corrective actions."" Earlier this year Tesla introduced event data recorder tools, or EDR, for crashes, so the woman could ostensibly log in and get more info about her car and what happened. As Tesla explains about the resource, ""The recorded data may help Tesla and other interested parties better understand the circumstances which lead to crashes and the potential for injury."" However, no Autopilot data will be logged through the black-box system.No matter what went down in Utah, the kinks of a self-driving system (even if it's only Level 2 automation and requires full attention of the driver, as Tesla repeatedly stresses) need to be highlighted, examined, and tracked. After March's fatal crash south of San Francisco in which a man driving a Model X in Autopilot mode hit the median, Tesla needs to examine its ""safety"" feature with more scrutiny.""Someone gets used to having an autonomous driver, then they disengage. That's natural human behavior,"" Paul Hightower, CEO of video-recording tech company Instrumentation Technology Systems, said in a phone call Tuesday. Tesla, in his estimation, shouldn't expect its drivers to be able to switch from passive rider to attentive motorist.Autopilot certainly has its moments that Musk will quickly tell you don't get attention because it's saving lives like it's NBD. After moments like this one caught on camera show Autopilot narrowly avoiding a swerving truck, Musk must've beamed from his factory office couch — finally people see what the safety feature can do.Even if no one was killed or seriously injured, Friday's incident shows Autopilot has its work cut out for it. While Autopilot includes auto-steering, adaptive cruise control, lane-changing, automatic braking, auto lighting adjustments, side warnings, and front collision warnings, this isn't a perfect or fully autonomous system.The company warns that the car cannot detect everything and may not brake or slow down for stationary vehicles — especially if you're going faster than 50 MPH and the car ahead moves out of the way for a stationary object. That sounds beyond similar to what happened Friday in Utah.Tesla's owner manuals and built-in warning systems try to educate and persuade drivers to use the autonomous features safely and cautiously. Staying alert and present is a huge part of Tesla's messaging and education. If hands aren't detected on the wheel enough drivers get locked out of Autopilot. Other alerts are set off based on speed, road markings, and traffic. But in an instant, the Autopilot feature's flaws are exposed.In that situation where the vehicle ahead suddenly moves out of the way for a parked or non-moving vehicle, Autopilot needs to be able to respond — and quickly. ""if Autopilot isn’t capable of dealing with that you shouldn’t be able to use it,"" Hightower said.From the outside it was just another rear-ender, but with the possibility of Autopilot controlling the wheel most Tesla accidents will continue making headlines not matter how much Musk protests.UPDATE: May 16, 2018, 3:57 p.m. PDT Police confirmed Wednesday that the Tesla crash in Utah last week happened with Autopilot engaged. The National Highway Traffic Safety Administration also announced it was looking into the crash that injured the driver, who told police she was looking at her phone when she hit a fire department vehicle while driving 60 MPH. "
http://fortune.com/2018/05/08/uber-autopilot-death-reason/,"When an Uber car in self-driving mode struck and killed Arizona pedestrian Elaine Herzberg in March, what caused the accident? According to a new report, Uber now thinks it was a fault in the software its cars use to decide whether or not to avoid objects in their path.The Information reported Monday evening that the car’s self-driving system detected the person and her bicycle in its path but decided that “it didn’t need to react right away.”The issue seems to have been one of tuning. The car’s cameras will regularly see objects in front of the car, but it must constantly decide whether or not the object requires sudden action. After all, you don’t want the car swerving because of something inconsequential lying on or floating over the road.The Uber executives who spoke to The Information indicated that the car’s self-driving system was overly inclined to dismiss objects in its path, leading to Herzberg’s death.Uber told TechCrunch that it couldn’t “comment on the specifics of the incident” as it is currently cooperating with the National Transportation Safety Board (NTSB) on its investigation into the incident.“In the meantime, we have initiated a top-to-bottom safety review of our self-driving vehicles program, and we have brought on former NTSB Chair Christopher Hart to advise us on our overall safety culture,” the company said. “Our review is looking at everything from the safety of our system to our training processes for vehicle operators, and we hope to have more to say soon.”Uber isn’t the only company in this field to have seen such an accident in recent months. Within days of the Uber incident, a Tesla Model X driver died near San Francisco when his car crashed into a divider.Following that incident, Tesla publicly said the driver was at fault because he knew Tesla’s Autopilot system was imperfect and particularly unreliable at that location, yet he relied on it there anyway.The NTSB had warned Tesla (TSLA, -8.94%) not to make statements about the cause of the crash, and when chairman Robert Sumwalt called Tesla CEO Elon Musk to inform his that the agency was removing Tesla from the investigation, Musk hung up on him.Correction: This story originally referred to Uber’s self-driving technology as Autopilot. Autopilot is a marketing name used by Tesla for its driver assistance systems."
